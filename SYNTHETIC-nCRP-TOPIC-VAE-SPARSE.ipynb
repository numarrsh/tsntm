{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from six.moves import zip_longest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import distributions as tfd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from data_structure import get_batches, get_test_batches\n",
    "from components import tf_log, sample_latents, compute_kl_loss, dynamic_rnn, dynamic_bi_rnn\n",
    "\n",
    "from topic_beam_search_decoder import BeamSearchDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNK = '<unk>' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "BOS = '<p>' # This has a vocab id, which is used at the beginning of every decoder input sequence\n",
    "EOS = '</p>' # This has a vocab id, which is used at the end of untruncated target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('gpu', '2', 'visible gpu')\n",
    "\n",
    "flags.DEFINE_string('mode', 'train', 'set train or eval')\n",
    "\n",
    "flags.DEFINE_string('data_path', 'data/synthetic/instances.pkl', 'path of data')\n",
    "flags.DEFINE_string('modeldir', 'model/topic_vae', 'directory of model')\n",
    "flags.DEFINE_string('modelname', 'bags', 'name of model')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 50, 'epochs')\n",
    "flags.DEFINE_integer('batch_size', 64, 'number of sentences in each batch')\n",
    "flags.DEFINE_integer('log_period', 1000, 'valid period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.01, 'lr')\n",
    "flags.DEFINE_float('reg', 1., 'regularization term')\n",
    "flags.DEFINE_float('grad_clip', 5., 'grad_clip')\n",
    "\n",
    "flags.DEFINE_float('keep_prob', 0.8, 'dropout rate')\n",
    "flags.DEFINE_float('word_keep_prob', 0.75, 'word dropout rate')\n",
    "\n",
    "flags.DEFINE_bool('warmup', True, 'flg of warming up')\n",
    "flags.DEFINE_integer('epochs_cycle', 5, 'number of epochs within a cycle')\n",
    "flags.DEFINE_float('r_cycle', 0.5, 'proportion used to increase beta within a cycle')\n",
    "flags.DEFINE_integer('warmup_topic', 0, 'warmup period for KL of topic')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 2, 'beam_width')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('n_topic', 20, 'number of topic')\n",
    "flags.DEFINE_integer('tree_depth', 4, 'number of topic')\n",
    "flags.DEFINE_integer('dim_hidden_bow', 256, 'dim of hidden bow')\n",
    "flags.DEFINE_integer('dim_latent_bow', 32, 'dim of latent topic')\n",
    "flags.DEFINE_integer('dim_emb', 256, 'dim_emb')\n",
    "flags.DEFINE_integer('dim_hidden', 512, 'dim_hidden')\n",
    "flags.DEFINE_integer('dim_hidden_topic', 512, 'dim_hidden_topic')\n",
    "flags.DEFINE_integer('dim_latent', 32, 'dim_latent')\n",
    "flags.DEFINE_bool('bidirectional', True, 'flg of bidirectional encoding')\n",
    "\n",
    "# for evaluation\n",
    "flags.DEFINE_string('refdir', 'ref', 'refdir')\n",
    "flags.DEFINE_string('outdir', 'out', 'outdir')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_bool('logtostderr', True, 'kernel')\n",
    "flags.DEFINE_bool('showprefixforinfo', False, '')\n",
    "flags.DEFINE_bool('verbosity', False, '')\n",
    "# flags.DEFINE_integer('stderrthreshold', 20, 'kernel')\n",
    "\n",
    "config = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('modelpath', os.path.join(config.modeldir, config.modelname), 'path of model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.data_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(instances, batch_size, iterator=False):\n",
    "    iter_instances = iter(instances)\n",
    "    n_batch = len(instances)//batch_size\n",
    "    \n",
    "    batches = [(i_batch, [next(iter_instances) for i_doc in range(batch_size)]) for i_batch in range(n_batch)]\n",
    "    \n",
    "    if iterator: batches = iter(batches)\n",
    "    return batches\n",
    "\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_integer('n_vocab', len(word_to_idx), 'n_vocab')\n",
    "flags.DEFINE_integer('dim_bow', len(bow_idxs), 'dim_bow')\n",
    "\n",
    "flags.DEFINE_integer('cycle_steps', len(train_batches)*config.epochs_cycle, 'number of steps for each cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0,
     10,
     18,
     24,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables):\n",
    "    sample_batch = dev_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    if return_value: \n",
    "        return _variables\n",
    "    else:\n",
    "        for _variable, variable in zip(_variables, variables):\n",
    "            if hasattr(variable, 'name'):\n",
    "                print(variable.name, ':', _variable)\n",
    "            else:\n",
    "                print(_variable)\n",
    "                \n",
    "def check_shape(variables):\n",
    "    if 'sess' in globals(): raise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "def check_value(variables):\n",
    "    if 'sess' in globals(): raise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    sess.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_feed_dict(batch, mode='train'):\n",
    "    bow = np.array([instance.bow for instance in batch]).astype(np.float32)\n",
    "    keep_prob = config.keep_prob if mode == 'train' else 1.0\n",
    "    feed_dict = {\n",
    "                t_variables['bow']: bow, \n",
    "                t_variables['keep_prob']: keep_prob\n",
    "    }\n",
    "    return  feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "t_variables = {}\n",
    "t_variables['bow'] = tf.placeholder(tf.float32, [None, config.dim_bow])\n",
    "t_variables['keep_prob'] = tf.placeholder(tf.float32)\n",
    "\n",
    "# tree_idxs = {0:[1, 2], \n",
    "#              1:[10, 11], 2:[20, 21, 22], \n",
    "#              10: [100, 101], 11: [110, 111, 112], 20: [200, 201], 21: [210, 211], 22:[220, 221, 222]\n",
    "#              }\n",
    "\n",
    "# tree_idxs = {0:[1, 2, 3], \n",
    "#                       1:[10, 11], 2:[20, 21], 3:[30, 31]}\n",
    "\n",
    "tree_idxs = {0:[1, 2, 3], \n",
    "              1:[10, 11, 12], 2:[20, 21, 22], 3:[30, 31, 32]}\n",
    "\n",
    "\n",
    "# tree_idxs = {0:[1, 2, 3], \n",
    "#                       1:[10, 11], 2:[20, 21], 3:[30, 31],\n",
    "#                       10: [100, 101], 11: [110, 111], 20: [200, 201], 21: [210, 211], 30:[300, 301], 31:[310, 311]}\n",
    "\n",
    "topic_idxs = [0] + [idx for child_idxs in tree_idxs.values() for idx in child_idxs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doubly rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublyRNNCell:\n",
    "    def __init__(self, dim_hidden, output_layer=None):\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.ancestral_layer=tf.layers.Dense(units=dim_hidden, activation=tf.nn.tanh, name='ancestral')\n",
    "        self.fraternal_layer=tf.layers.Dense(units=dim_hidden, activation=tf.nn.tanh, name='fraternal')\n",
    "        self.hidden_layer = tf.layers.Dense(units=dim_hidden, activation=tf.nn.tanh, name='hidden')\n",
    "        \n",
    "        self.output_layer=output_layer\n",
    "        \n",
    "    def __call__(self, state_ancestral, state_fraternal, reuse=True):\n",
    "        with tf.variable_scope('input', reuse=reuse):\n",
    "            state_ancestral = self.ancestral_layer(state_ancestral)\n",
    "            state_fraternal = self.fraternal_layer(state_fraternal)\n",
    "\n",
    "        with tf.variable_scope('output', reuse=reuse):\n",
    "            state_hidden = self.hidden_layer(state_ancestral + state_fraternal)\n",
    "            if self.output_layer is not None: \n",
    "                output = self.output_layer(state_hidden)\n",
    "            else:\n",
    "                output = state_hidden\n",
    "            \n",
    "        return output, state_hidden\n",
    "    \n",
    "    def get_initial_state(self, name):\n",
    "        initial_state = tf.get_variable(name, [1, self.dim_hidden], dtype=tf.float32)\n",
    "        return initial_state\n",
    "    \n",
    "    def get_zero_state(self, name):\n",
    "        zero_state = tf.zeros([1, self.dim_hidden], dtype=tf.float32, name=name)\n",
    "        return zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_rnn(dim_hidden, tree_idxs, initial_state_parent=None, initial_state_sibling=None, output_layer=None, name=''):\n",
    "    outputs, states_parent = {}, {}\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=False):\n",
    "        doubly_rnn_cell = DoublyRNNCell(dim_hidden, output_layer)\n",
    "\n",
    "        if initial_state_parent is None: initial_state_parent = doubly_rnn_cell.get_initial_state('init_state_parent')\n",
    "        if initial_state_sibling is None: \n",
    "#             initial_state_sibling = doubly_rnn_cell.get_initial_state('init_state_sibling')\n",
    "            initial_state_sibling = doubly_rnn_cell.get_zero_state('init_state_sibling')\n",
    "        output, state_sibling = doubly_rnn_cell(initial_state_parent, initial_state_sibling, reuse=False)\n",
    "        outputs[0], states_parent[0] = output, state_sibling\n",
    "\n",
    "        for parent_idx, child_idxs in tree_idxs.items():\n",
    "            state_parent = states_parent[parent_idx]\n",
    "            state_sibling = initial_state_sibling\n",
    "            for child_idx in child_idxs:\n",
    "                output, state_sibling = doubly_rnn_cell(state_parent, state_sibling)\n",
    "                outputs[child_idx], states_parent[child_idx] = output, state_sibling\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stick break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCRP(tree_sticks_topic):\n",
    "    tree_prob_topic = {}\n",
    "    tree_prob_leaf = {}\n",
    "    # calculate topic probability and save\n",
    "    tree_prob_topic[0] = 1.\n",
    "    \n",
    "    for parent_idx, child_idxs in tree_idxs.items():\n",
    "        rest_prob_topic = tree_prob_topic[parent_idx]\n",
    "        for child_idx in child_idxs:\n",
    "            stick_topic = tree_sticks_topic[child_idx]\n",
    "            if child_idx == child_idxs[-1]:\n",
    "                prob_topic = rest_prob_topic\n",
    "            else:\n",
    "                prob_topic = rest_prob_topic * stick_topic\n",
    "            \n",
    "            if not child_idx in tree_idxs: # leaf childs\n",
    "                tree_prob_leaf[child_idx] = prob_topic\n",
    "            else:\n",
    "                tree_prob_topic[child_idx] = prob_topic\n",
    "                \n",
    "            rest_prob_topic -= prob_topic\n",
    "            \n",
    "    return tree_prob_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestor_idxs(leaf_idx, ancestor_idxs = None):\n",
    "    if ancestor_idxs is None: ancestor_idxs = [leaf_idx]\n",
    "    \n",
    "    parent_idx = child_to_parent_idxs[leaf_idx]\n",
    "    ancestor_idxs += [parent_idx]\n",
    "    if parent_idx in child_to_parent_idxs: get_ancestor_idxs(parent_idx, ancestor_idxs)\n",
    "    return ancestor_idxs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_topic(tree_prob_leaf, prob_depth):\n",
    "    tree_prob_topic = defaultdict(float)\n",
    "    \n",
    "    leaf_ancestor_idxs = {leaf_idx: get_ancestor_idxs(leaf_idx) for leaf_idx in tree_prob_leaf}\n",
    "    for leaf_idx, ancestor_idxs in leaf_ancestor_idxs.items():\n",
    "        prob_leaf = tree_prob_leaf[leaf_idx]\n",
    "        for i, ancestor_idx in enumerate(ancestor_idxs):\n",
    "            prob_ancestor = prob_leaf * tf.expand_dims(prob_depth[:, i], -1)\n",
    "            tree_prob_topic[ancestor_idx] += prob_ancestor\n",
    "    prob_topic = tf.concat([tree_prob_topic[topic_idx] for topic_idx in topic_idxs], -1)\n",
    "    return prob_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_topic_bow(tree_topic_embeddings):\n",
    "    def get_depth(parent_idx=0, tree_depth = None, depth=1):\n",
    "        if tree_depth is None: tree_depth={0: depth}\n",
    "\n",
    "        child_idxs = tree_idxs[parent_idx]\n",
    "        depth +=1\n",
    "        for child_idx in child_idxs:\n",
    "            tree_depth[child_idx] = depth\n",
    "            if child_idx in tree_idxs: get_depth(child_idx, tree_depth, depth)\n",
    "        return tree_depth\n",
    "       \n",
    "    def softmax_with_temperature(logits, axis=None, name=None, temperature=1.):\n",
    "        if axis is None:\n",
    "            axis = -1\n",
    "        return tf.exp(logits / temperature) / tf.reduce_sum(tf.exp(logits / temperature), axis=axis)\n",
    "    \n",
    "    tree_depth = get_depth()\n",
    "\n",
    "    tree_topic_bow = {}\n",
    "    for topic_idx, depth in tree_depth.items():\n",
    "        topic_embedding = tree_topic_embeddings[topic_idx]\n",
    "        temperature = tf.constant(10. ** (1./depth), dtype=tf.float32)\n",
    "        logits = tf.matmul(topic_embedding, bow_embeddings, transpose_b=True)\n",
    "        tree_topic_bow[topic_idx] = softmax_with_temperature(logits, axis=-1, temperature=temperature)\n",
    "    \n",
    "    return tree_topic_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode bow\n",
    "with tf.variable_scope('topic/enc', reuse=False):\n",
    "    hidden_bow_ = tf.layers.Dense(units=config.dim_hidden_bow, activation=tf.nn.relu, name='hidden_bow')(t_variables['bow'])\n",
    "    hidden_bow = tf.layers.Dropout(t_variables['keep_prob'])(hidden_bow_)\n",
    "    means_bow = tf.layers.Dense(units=config.dim_latent_bow, name='mean_bow')(hidden_bow)\n",
    "    logvars_bow = tf.layers.Dense(units=config.dim_latent_bow, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0), name='logvar_bow')(hidden_bow)\n",
    "    latents_bow = sample_latents(means_bow, logvars_bow) # sample latent vectors\n",
    "    prob_layer = lambda h: tf.nn.sigmoid(tf.matmul(latents_bow, h, transpose_b=True))\n",
    "    \n",
    "    tree_sticks_topic = doubly_rnn(config.dim_latent_bow, tree_idxs, output_layer=prob_layer, name='sticks_topic')\n",
    "    tree_prob_leaf = nCRP(tree_sticks_topic)\n",
    "    prob_depth = tf.layers.Dense(units=config.tree_depth, activation=tf.nn.softmax, name='prob_topic')(latents_bow) # inference of topic probabilities\n",
    "    \n",
    "    prob_topic = get_prob_topic(tree_prob_leaf, prob_depth)\n",
    "\n",
    "# decode bow\n",
    "with tf.variable_scope('shared', reuse=False):\n",
    "    embeddings = tf.get_variable('emb', [config.n_vocab, config.dim_emb], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of vocab\n",
    "\n",
    "bow_embeddings = tf.nn.embedding_lookup(embeddings, bow_idxs) # embeddings of each bow features\n",
    "\n",
    "with tf.variable_scope('topic/dec', reuse=False):\n",
    "    tree_topic_embeddings = doubly_rnn(config.dim_emb, tree_idxs, name='emb_topic')\n",
    "    tree_topic_bow = get_tree_topic_bow(tree_topic_embeddings) # bow vectors for each topic\n",
    "    \n",
    "    topic_bow = tf.concat([tree_topic_bow[topic_idx] for topic_idx in topic_idxs], 0)\n",
    "    logits_bow = tf_log(tf.matmul(prob_topic, topic_bow)) # predicted bow distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_mask_reg(tree_idxs):\n",
    "    tree_mask_reg = np.ones([len(topic_idxs), len(topic_idxs)], dtype=np.float32)\n",
    "    parent_to_descendant_idxs = {parent_idx: get_descendant_idxs(parent_idx) for parent_idx in tree_idxs}\n",
    "    \n",
    "    for parent_idx, descendant_idxs in parent_to_descendant_idxs.items():\n",
    "        for descendant_idx in descendant_idxs:\n",
    "            tree_mask_reg[topic_idxs.index(parent_idx), topic_idxs.index(descendant_idx)] = tree_mask_reg[topic_idxs.index(descendant_idx), topic_idxs.index(parent_idx)] = 0.\n",
    "            \n",
    "    return tree_mask_reg\n",
    "\n",
    "def get_descendant_idxs(parent_idx, descendant_idxs = None):\n",
    "    if descendant_idxs is None: descendant_idxs = []\n",
    "    \n",
    "    child_idxs = tree_idxs[parent_idx]\n",
    "    descendant_idxs += child_idxs\n",
    "    for child_idx in child_idxs:\n",
    "        if child_idx in tree_idxs: get_descendant_idxs(child_idx, descendant_idxs)\n",
    "    return descendant_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define losses\n",
    "topic_losses_recon = -tf.reduce_sum(tf.multiply(t_variables['bow'], logits_bow), 1)\n",
    "topic_loss_recon = tf.reduce_mean(topic_losses_recon) # negative log likelihood of each words\n",
    "\n",
    "topic_loss_kl = compute_kl_loss(means_bow, logvars_bow) # KL divergence b/w latent dist & gaussian std\n",
    "\n",
    "topic_bow_norm = topic_bow / tf.norm(topic_bow, axis=1, keepdims=True)\n",
    "topic_dots = tf.clip_by_value(tf.matmul(topic_bow_norm, tf.transpose(topic_bow_norm)), -1., 1.)\n",
    "# topic_loss_reg = tf.reduce_mean(tf.square(topic_dots - tf.eye(len(topic_idxs))))\n",
    "tree_mask_reg = get_tree_mask_reg(tree_idxs)\n",
    "topic_loss_reg = tf.reduce_mean(tf.square(topic_dots - tf.eye(len(topic_idxs))) * tree_mask_reg)\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "\n",
    "loss = topic_loss_recon + topic_loss_kl + config.reg * topic_loss_reg\n",
    "# loss = topic_loss_recon + topic_loss_kl\n",
    "\n",
    "# define optimizer\n",
    "if config.opt == 'Adam':\n",
    "    optimizer = tf.train.AdamOptimizer(config.lr)\n",
    "elif config.opt == 'Adagrad':\n",
    "    optimizer = tf.train.AdagradOptimizer(config.lr)\n",
    "\n",
    "grad_vars = optimizer.compute_gradients(loss)\n",
    "clipped_grad_vars = [(tf.clip_by_value(grad, -config.grad_clip, config.grad_clip), var) for grad, var in grad_vars]\n",
    "opt = optimizer.apply_gradients(clipped_grad_vars, global_step=global_step)\n",
    "\n",
    "# monitor\n",
    "n_bow = tf.reduce_sum(t_variables['bow'], 1)\n",
    "topic_ppls = tf.divide(topic_losses_recon, tf.maximum(1e-5, n_bow))\n",
    "topics_freq_bow_indices = tf.nn.top_k(topic_bow, 10, name='topic_freq_bow').indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_loss(sess, batches):\n",
    "    losses = []\n",
    "    ppl_list = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch \\\n",
    "            = sess.run([loss, topic_loss_recon, topic_loss_kl, topic_loss_reg, topic_ppls], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppl_list += list(ppls_batch)\n",
    "    loss_mean, topic_loss_recon_mean, topic_loss_kl_mean, topic_loss_reg_mean = np.mean(losses, 0)\n",
    "    ppl_mean = np.exp(np.mean(ppl_list))\n",
    "    return loss_mean, topic_loss_recon_mean, topic_loss_kl_mean, topic_loss_reg_mean, ppl_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize # Normalizeã‚’import\n",
    "\n",
    "def print_topic_sample():\n",
    "    _topics_bow = sess.run(topic_bow)\n",
    "    plt.figure(figsize=(3, 4))\n",
    "    \n",
    "    _topic_bow = _topics_bow[0]\n",
    "    plt.subplot(5,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(_topic_bow.reshape(30,30), cmap='Wistia', norm=Normalize(vmin=0., vmax=np.max(_topics_bow)))\n",
    "    \n",
    "    for i in range(1, len(topic_idxs)):\n",
    "        _topic_bow = _topics_bow[i]\n",
    "        plt.subplot(5,3,i+3)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(_topic_bow.reshape(30,30), cmap='Wistia', norm=Normalize(vmin=0., vmax=np.max(_topics_bow)))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "loss_min = np.inf\n",
    "beta_eval = 1.\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','TM','','','','VALID:','TM','','',''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG']]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th>TM</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th>TM</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720.92</td>\n",
       "      <td>1309</td>\n",
       "      <td>717.72</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>709.40</td>\n",
       "      <td>900</td>\n",
       "      <td>680.25</td>\n",
       "      <td>28.48</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>683.65</td>\n",
       "      <td>889</td>\n",
       "      <td>679.05</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>680.54</td>\n",
       "      <td>867</td>\n",
       "      <td>676.46</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>681.57</td>\n",
       "      <td>873</td>\n",
       "      <td>677.19</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>679.36</td>\n",
       "      <td>860</td>\n",
       "      <td>675.64</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>680.63</td>\n",
       "      <td>866</td>\n",
       "      <td>676.40</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.58</td>\n",
       "      <td>678.38</td>\n",
       "      <td>851</td>\n",
       "      <td>674.63</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>680.00</td>\n",
       "      <td>862</td>\n",
       "      <td>675.90</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.53</td>\n",
       "      <td>677.83</td>\n",
       "      <td>847</td>\n",
       "      <td>674.17</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>679.53</td>\n",
       "      <td>859</td>\n",
       "      <td>675.52</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>677.58</td>\n",
       "      <td>846</td>\n",
       "      <td>674.08</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>679.15</td>\n",
       "      <td>856</td>\n",
       "      <td>675.22</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>677.15</td>\n",
       "      <td>840</td>\n",
       "      <td>673.35</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>678.83</td>\n",
       "      <td>854</td>\n",
       "      <td>674.96</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>676.88</td>\n",
       "      <td>840</td>\n",
       "      <td>673.37</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>678.57</td>\n",
       "      <td>852</td>\n",
       "      <td>674.74</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>676.69</td>\n",
       "      <td>838</td>\n",
       "      <td>673.12</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>678.34</td>\n",
       "      <td>850</td>\n",
       "      <td>674.56</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.43</td>\n",
       "      <td>676.73</td>\n",
       "      <td>840</td>\n",
       "      <td>673.35</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TRAIN:    TM                      VALID:   TM                 \\\n",
       "     Time Ep Ct    LOSS   PPL     NLL    KL   REG    LOSS  PPL     NLL     KL   \n",
       "1       1  0  0  720.92  1309  717.72  2.53  0.67  709.40  900  680.25  28.48   \n",
       "157     1  1  0  683.65   889  679.05  3.94  0.65  680.54  867  676.46   3.46   \n",
       "313     1  2  0  681.57   873  677.19  3.76  0.62  679.36  860  675.64   3.16   \n",
       "469     1  3  0  680.63   866  676.40  3.65  0.58  678.38  851  674.63   3.34   \n",
       "625     1  4  0  680.00   862  675.90  3.57  0.53  677.83  847  674.17   3.29   \n",
       "781     1  5  0  679.53   859  675.52  3.51  0.50  677.58  846  674.08   3.14   \n",
       "937     1  6  0  679.15   856  675.22  3.46  0.47  677.15  840  673.35   3.47   \n",
       "1093    1  7  0  678.83   854  674.96  3.42  0.45  676.88  840  673.37   3.18   \n",
       "1249    1  8  0  678.57   852  674.74  3.39  0.44  676.69  838  673.12   3.24   \n",
       "1405    1  9  0  678.34   850  674.56  3.35  0.43  676.73  840  673.35   3.06   \n",
       "\n",
       "            \n",
       "       REG  \n",
       "1     0.67  \n",
       "157   0.62  \n",
       "313   0.56  \n",
       "469   0.41  \n",
       "625   0.37  \n",
       "781   0.35  \n",
       "937   0.34  \n",
       "1093  0.33  \n",
       "1249  0.33  \n",
       "1405  0.32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x288 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-0bdbc287aeec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_recon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_kl_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_reg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppls_batch\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_kl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_ppls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlosses_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_recon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_kl_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_reg_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if len(log_df) == 0:\n",
    "    cmd_rm = 'rm -r %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_rm.split())\n",
    "\n",
    "    cmd_mk = 'mkdir %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "time_start = time.time()\n",
    "while epoch < config.epochs:\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = get_feed_dict(batch)\n",
    "\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch = \\\n",
    "        sess.run([opt, loss, topic_loss_recon, topic_loss_kl, topic_loss_reg, topic_ppls], feed_dict = feed_dict)\n",
    "            \n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if ct%config.log_period==0:\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev = get_loss(sess, dev_batches)\n",
    "            global_step_log = sess.run(tf.train.get_global_step())\n",
    "            \n",
    "#             if loss_dev < loss_min:\n",
    "#                 loss_min = loss_dev\n",
    "#                 saver.save(sess, config.modelpath, global_step=global_step_log)\n",
    "\n",
    "            clear_output()\n",
    "    \n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            \n",
    "            # visualize topicu\n",
    "            print_topic_sample()\n",
    "\n",
    "            time_start = time.time()\n",
    "            \n",
    "    epoch += 1\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    \n",
    "    \n",
    "display(log_df)\n",
    "print_topic_sample()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confirm variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strided_slice:0 : [5.2841981e-03 3.6565879e-01 6.2899369e-01 6.3372136e-05]\n"
     ]
    }
   ],
   "source": [
    "debug_value([prob_depth[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c525be7ebc7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdebug_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'topic_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "debug_value([topic_embeddings[:, :5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_topic_bow, = debug_value([topic_bow], return_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(bow_idxs, topic_bow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(bow_idxs, topic_bow[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(bow_idxs, topic_bow[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(bow_idxs, topic_bow[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_value([prob_topic[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_value([tf.exp(-tf.divide(topic_losses_recon, n_bow))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_shape([bow, hidden_bow, latents_bow, prob_topic, bow_embeddings, topic_embeddings, topic_bow, prob_bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_shape([topic_losses_recon, topic_loss_recon, n_bow, ppls, topic_embeddings_norm, tf.expand_dims(topic_angles_mean, -1), topic_angles_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_value([tf.reduce_sum(tf.square(topic_embeddings_norm), 1)], return_value=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_value([tf.reduce_sum(prob_topic, -1), tf.reduce_sum(topic_bow, -1), tf.reduce_sum(tf.exp(prob_bow), 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_bow = tf.exp(0.5 * logvars_bow)\n",
    "dist_bow = tfd.Normal(means_bow, sigma_bow)\n",
    "dist_std = tfd.Normal(0., 1.)\n",
    "topic_loss_kl_tmp = tf.reduce_mean(tf.reduce_sum(tfd.kl_divergence(dist_bow, dist_std), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_value([topic_loss_recon, topic_loss_kl, topic_loss_kl_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logvars, _means, _kl_losses, _latents, _output_logits = sess.run([logvars, means, kl_losses, latents, output_logits], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logvars.shape, _means.shape, _kl_losses.shape, _latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_logits, _dec_target_idxs_do, _dec_mask_tokens_do, _recon_loss, _kl_losses, _ = sess.run([output_logits, dec_target_idxs_do, dec_mask_tokens_do, recon_loss, kl_losses, opt], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_max(output_logits, 2).eval(session=sess, feed_dict=feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_logits.shape, _dec_target_idxs_do.shape, _dec_mask_tokens_do.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logits = np.exp(_output_logits) / np.sum(np.exp(_output_logits), 2)[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idxs = _dec_target_idxs_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_losses = np.array([[-np.log(_logits[i, j, _idxs[i, j]]) for j in range(_idxs.shape[1])] for i in range(_idxs.shape[0])]) * _dec_mask_tokens_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(_losses)/np.sum(_dec_mask_tokens_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_kl_losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
