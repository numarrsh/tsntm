{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import h5py\n",
    "from six.moves import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import _pickle as cPickle\n",
    "import random\n",
    "\n",
    "from data_structure import load_data\n",
    "from preprocess_text import Indexer\n",
    "from components import dynamic_rnn, dynamic_bi_rnn, DiagonalGaussian\n",
    "from data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNK = '<unk>' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "BOS = '<p>' # This has a vocab id, which is used at the beginning of every decoder input sequence\n",
    "EOS = '</p>' # This has a vocab id, which is used at the end of untruncated target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('gpu', '1', 'visible gpu')\n",
    "\n",
    "flags.DEFINE_string('mode', 'train', 'set train or eval')\n",
    "\n",
    "flags.DEFINE_string('datadir', 'data', 'directory of input data')\n",
    "flags.DEFINE_string('dataname', 'sports_sents.pkl', 'name of data')\n",
    "flags.DEFINE_string('modeldir', 'NAS/model', 'directory of model')\n",
    "flags.DEFINE_string('modelname', 'sports', 'name of model')\n",
    "\n",
    "flags.DEFINE_string('train_file', 'data/yahoo/yahoo32-train.hdf5', 'name of model')\n",
    "flags.DEFINE_string('val_file', 'data/yahoo/yahoo32-val.hdf5', 'name of model')\n",
    "flags.DEFINE_string('test_file', 'data/yahoo/yahoo32-test.hdf5', 'name of model')\n",
    "flags.DEFINE_string('vocab_file', 'data/yahoo/yahoo32.dict', 'name of model')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 10, 'epochs')\n",
    "flags.DEFINE_integer('batch_size', 32, 'batch size')\n",
    "flags.DEFINE_integer('log_period', 100, 'valid period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.1, 'lr')\n",
    "flags.DEFINE_float('grad_clip', 5., 'grad_clip')\n",
    "\n",
    "flags.DEFINE_float('keep_prob', 1.0, 'dropout rate')\n",
    "flags.DEFINE_float('word_keep_prob', 0.75, 'word dropout rate')\n",
    "\n",
    "flags.DEFINE_integer('warmup', 10, 'warmup period for KL')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 10, 'beam_width')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('dim_emb', 256, 'dim_latent')\n",
    "flags.DEFINE_integer('dim_hidden', 256, 'dim_output')\n",
    "flags.DEFINE_integer('dim_latent', 16, 'dim_latent')\n",
    "\n",
    "# for evaluation\n",
    "flags.DEFINE_string('refdir', 'ref', 'refdir')\n",
    "flags.DEFINE_string('outdir', 'out', 'outdir')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "config = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 3211 batches\n",
      "Val data: 398 batches\n",
      "Test data: 392 batches\n"
     ]
    }
   ],
   "source": [
    "train_data = Dataset(config.train_file)\n",
    "val_data = Dataset(config.val_file)\n",
    "test_data = Dataset(config.test_file)\n",
    "\n",
    "print('Train data: %d batches' % len(train_data))\n",
    "print('Val data: %d batches' % len(val_data))\n",
    "print('Test data: %d batches' % len(test_data))\n",
    "\n",
    "batch_size = train_data.batch_size[0]\n",
    "n_vocab = int(train_data.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "indexer.load_vocab(config.vocab_file)\n",
    "word_to_idx = indexer.d\n",
    "idx_to_word = indexer.idx2word\n",
    "\n",
    "assert len(word_to_idx) == n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = [train_data[i][0].data.numpy()[:, 1:-1] for i in range(len(train_data))]\n",
    "val_batches = [val_data[i][0].data.numpy()[:, 1:-1] for i in range(len(val_data))]\n",
    "test_batches = [test_data[i][0].data.numpy()[:, 1:-1] for i in range(len(test_data))]\n",
    "num_train_batches = len(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_integer('PAD_IDX', word_to_idx[PAD], 'PAD_IDX')\n",
    "flags.DEFINE_integer('UNK_IDX', word_to_idx[UNK], 'UNK_IDX')\n",
    "flags.DEFINE_integer('BOS_IDX', word_to_idx[BOS], 'BOS_IDX')\n",
    "flags.DEFINE_integer('EOS_IDX', word_to_idx[EOS], 'EOS_IDX')\n",
    "\n",
    "flags.DEFINE_integer('n_vocab', len(word_to_idx), 'n_vocab')\n",
    "\n",
    "maximum_iterations = val_data.sents.numpy().shape[1]\n",
    "flags.DEFINE_integer('maximum_iterations', maximum_iterations, 'maximum_iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(batch, mode='train'):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    sent_l = [len(sent_idxs) for sent_idxs in batch]\n",
    "    dec_sent_l = [len(sent_idxs)+1 for sent_idxs in batch]\n",
    "    max_sent_l = max(sent_l)\n",
    "\n",
    "    token_idxs_matrix = np.zeros([batch_size, max_sent_l], np.int32)\n",
    "    dec_input_idxs_matrix = np.zeros([batch_size, max_sent_l+1], np.int32)\n",
    "    dec_target_idxs_matrix = np.zeros([batch_size, max_sent_l+1], np.int32)\n",
    "    \n",
    "    for i, sent_idxs in enumerate(batch):\n",
    "        token_idxs_matrix[i, :len(sent_idxs)] = np.asarray(sent_idxs)\n",
    "\n",
    "        sent_idxs_dropout = np.asarray(sent_idxs)\n",
    "        sent_idxs_dropout[np.random.rand(len(sent_idxs)) > config.word_keep_prob] = config.UNK_IDX\n",
    "        dec_input_idxs_matrix[i, :len(sent_idxs)+1] = np.concatenate([[config.BOS_IDX], sent_idxs_dropout])\n",
    "\n",
    "        dec_target_idxs_matrix[i, :len(sent_idxs)+1] = np.concatenate([np.asarray(sent_idxs), [config.EOS_IDX]])\n",
    "\n",
    "    keep_prob = config.keep_prob if mode == 'train' else 1.0\n",
    "\n",
    "    feed_dict = {\n",
    "                t_variables['token_idxs']: token_idxs_matrix,\n",
    "                t_variables['dec_input_idxs']: dec_input_idxs_matrix, t_variables['dec_target_idxs']: dec_target_idxs_matrix, \n",
    "                t_variables['batch_l']: batch_size, t_variables['sent_l']: sent_l, t_variables['dec_sent_l']: dec_sent_l,\n",
    "                t_variables['keep_prob']: keep_prob}\n",
    "    return  feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_shape(variables):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        sample_batch = test_batches[0]\n",
    "        feed_dict = get_feed_dict(sample_batch)\n",
    "        _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "        for _variable, variable in zip(_variables, variables):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "            \n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "t_variables = {}\n",
    "t_variables['keep_prob'] = tf.placeholder(tf.float32)\n",
    "t_variables['batch_l'] = tf.placeholder(tf.int32, [])\n",
    "t_variables['token_idxs'] = tf.placeholder(tf.int32, [None, None])\n",
    "t_variables['dec_input_idxs'] = tf.placeholder(tf.int32, [None, None])\n",
    "t_variables['dec_target_idxs'] = tf.placeholder(tf.int32, [None, None])\n",
    "t_variables['sent_l'] = tf.placeholder(tf.int32, [None])\n",
    "t_variables['dec_sent_l'] = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trained variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = tf.float32\n",
    "\n",
    "dim_hidden = config.dim_hidden\n",
    "dim_latent = config.dim_latent\n",
    "\n",
    "# with tf.variable_scope('emb', reuse=tf.AUTO_REUSE):\n",
    "#     embeddings = tf.get_variable('emb', [config.n_vocab, config.dim_emb], dtype=dtype, initializer=tf.random_uniform_initializer(-1., 1.))\n",
    "    \n",
    "# with tf.variable_scope('enc', reuse=tf.AUTO_REUSE):\n",
    "#     w_enc = tf.get_variable('w', [dim_hidden, 2 * dim_latent], dtype=dtype, initializer=tf.random_uniform_initializer(-1., 1.))\n",
    "#     b_enc = tf.get_variable('b', [2 * dim_latent], dtype=dtype, initializer=tf.constant_initializer())\n",
    "    \n",
    "# with tf.variable_scope('dec', reuse=tf.AUTO_REUSE):\n",
    "#     w_dec = tf.get_variable('w', [dim_latent, dim_hidden], dtype=dtype, initializer=tf.random_uniform_initializer(-1., 1.))\n",
    "#     b_dec = tf.get_variable('b', [dim_hidden], dtype=dtype, initializer=tf.constant_initializer())\n",
    "\n",
    "if config.warmup > 0:\n",
    "    beta = tf.Variable(0.1, name='beta', trainable=False)    \n",
    "    \n",
    "with tf.variable_scope('emb'):\n",
    "    embeddings = tf.get_variable('emb', [config.n_vocab, config.dim_emb], dtype=dtype, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "with tf.variable_scope('enc'):\n",
    "    w_enc = tf.get_variable('w_enc', [dim_hidden, 2 * dim_latent], dtype=dtype)\n",
    "    b_enc = tf.get_variable('b_enc', [2 * dim_latent], dtype=dtype)\n",
    "    \n",
    "with tf.variable_scope('dec'):\n",
    "    w_dec = tf.get_variable('w_dec', [dim_latent, dim_hidden], dtype=dtype)\n",
    "    b_dec = tf.get_variable('b_dec', [dim_hidden], dtype=dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "batch_l = t_variables['batch_l']\n",
    "sent_l = t_variables['sent_l']\n",
    "max_sent_l = tf.reduce_max(sent_l)\n",
    "token_idxs = t_variables['token_idxs']\n",
    "\n",
    "# get sentence embedding\n",
    "enc_input = tf.nn.embedding_lookup(embeddings, token_idxs)\n",
    "_, enc_state = dynamic_rnn(enc_input, sent_l, dim_hidden, t_variables['keep_prob'], cell_name='Model/sent')\n",
    "\n",
    "# encode to parameter \n",
    "means_logvars = tf.nn.relu(tf.matmul(enc_state, w_enc) + b_enc)\n",
    "means, logvars = tf.split(means_logvars, 2, 1)\n",
    "\n",
    "# reparameterize\n",
    "noises = tf.random_normal(tf.shape(means))\n",
    "latents = means + tf.exp(0.5 * logvars) * noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder_2:0 : (32, 20)\n",
      "embedding_lookup:0 : (32, 20, 256)\n",
      "Model/sent/rnn/while/Exit_3:0 : (32, 256)\n",
      "split:0 : (32, 16)\n",
      "split:1 : (32, 16)\n",
      "add_1:0 : (32, 16)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([token_idxs, enc_input, enc_state, means, logvars, latents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for decoding\n",
    "dec_input_idxs = t_variables['dec_input_idxs']\n",
    "dec_input = tf.nn.embedding_lookup(embeddings, dec_input_idxs)\n",
    "\n",
    "dec_latent_input = tf.tile(tf.expand_dims(latents, 1), [1, tf.shape(dec_input_idxs)[1], 1])\n",
    "dec_concat_input = tf.concat([dec_input, dec_latent_input], 2)\n",
    "\n",
    "# decode for training\n",
    "dec_sent_l = t_variables['dec_sent_l']\n",
    "\n",
    "with tf.variable_scope('Model/sent/dec', initializer=tf.contrib.layers.xavier_initializer(), dtype = tf.float32, reuse=tf.AUTO_REUSE):\n",
    "    dec_cell = tf.contrib.rnn.GRUCell(dim_hidden)\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, output_keep_prob = t_variables['keep_prob'])\n",
    "\n",
    "    dec_initial_state = tf.nn.relu(tf.matmul(latents, w_dec) + b_dec)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_concat_input, sequence_length=dec_sent_l)\n",
    "\n",
    "    train_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        cell=dec_cell,\n",
    "        helper=helper,\n",
    "        initial_state=dec_initial_state)\n",
    "\n",
    "    dec_outputs, _, output_sent_l = tf.contrib.seq2seq.dynamic_decode(train_decoder)\n",
    "    \n",
    "    output_layer = tf.layers.Dense(config.n_vocab, use_bias=False, name=\"output_projection\")\n",
    "    output_logits = output_layer(dec_outputs.rnn_output)\n",
    "    \n",
    "    output_token_idxs = tf.argmax(output_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat:0 : (32, 21, 272)\n",
      "Model/sent/dec/output_projection/Tensordot:0 : (32, 21, 20001)\n",
      "Model/sent/dec/ArgMax:0 : (32, 21)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([dec_concat_input, output_logits, output_token_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define cost & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and mask\n",
    "dec_target_idxs = t_variables['dec_target_idxs']\n",
    "max_dec_sent_l = tf.reduce_max(dec_sent_l)\n",
    "dec_mask_tokens = tf.sequence_mask(dec_sent_l, maxlen=max_dec_sent_l, dtype=tf.float32)\n",
    "\n",
    "recon_loss = tf.contrib.seq2seq.sequence_loss(output_logits, dec_target_idxs, dec_mask_tokens) # nll for each token (averaged over batch & sentence)\n",
    "\n",
    "# define loss\n",
    "kl_losses = tf.reduce_sum(-0.5 * (logvars - tf.square(means) - tf.exp(logvars) + 1.0), 1) # sum over latent dimentsion    \n",
    "kl_loss = tf.reduce_mean(kl_losses, [0]) #mean of kl_losses over batches\n",
    "\n",
    "loss = recon_loss + beta * kl_loss\n",
    "\n",
    "# define optimizer\n",
    "if (config.opt == 'Adam'):\n",
    "    optimizer = tf.train.AdamOptimizer(config.lr)\n",
    "elif (config.opt == 'Adagrad'):\n",
    "    optimizer = tf.train.AdagradOptimizer(config.lr)\n",
    "    \n",
    "grad_vars = optimizer.compute_gradients(loss)\n",
    "clipped_grad_vars = [(tf.clip_by_value(grad, -config.grad_clip, config.grad_clip), var) for grad, var in grad_vars]\n",
    "\n",
    "opt = optimizer.apply_gradients(clipped_grad_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:0 : (32,)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([kl_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxs_to_sent(line_idxs, config, idx_to_word):\n",
    "    tokens = []\n",
    "    for idx in line_idxs:\n",
    "        if idx == config.EOS_IDX: break\n",
    "        tokens.append(idx_to_word[idx])\n",
    "    sent = ' '.join(tokens)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(sess, batches):\n",
    "    losses = []\n",
    "    for batch in batches:\n",
    "        feed_dict = get_feed_dict(batch, mode='test')\n",
    "        loss_batch = sess.run(loss, feed_dict = feed_dict)\n",
    "        losses += [loss_batch]        \n",
    "    loss_mean = np.mean(losses)\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(sample_batch):\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    pred_token_idxs = sess.run(output_token_idxs, feed_dict = feed_dict)\n",
    "    true_token_idxs = sample_batch\n",
    "    \n",
    "    assert len(pred_token_idxs) == len(true_token_idxs)\n",
    "    \n",
    "    for true_sent_idxs, pred_sent_idxs in zip(true_token_idxs, pred_token_idxs):\n",
    "        true_sent = idxs_to_sent(true_sent_idxs, config, idx_to_word)\n",
    "        pred_sent = idxs_to_sent(pred_sent_idxs, config, idx_to_word)\n",
    "\n",
    "        print('True: %s' % true_sent)\n",
    "        print('Pred: %s' % pred_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "sess = tf.Session()\n",
    "\n",
    "vim \n",
    "logs = []\n",
    "losses_train = []\n",
    "loss_min = np.inf\n",
    "beta_eval = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0 | LOSS TRAIN: 9.91, val: 9.90, TEST: 9.90 | NLL: 20179.49, KL: 0.1638| BETA: 0.010031\n",
      "Epoch: 0, Step: 100 | LOSS TRAIN: 5.94, val: 3.95, TEST: 3.95 | NLL: 355.32, KL: 6.6171| BETA: 0.010062\n",
      "Epoch: 0, Step: 200 | LOSS TRAIN: 5.74, val: 3.61, TEST: 3.61 | NLL: 292.68, KL: 5.9026| BETA: 0.010093\n",
      "Epoch: 0, Step: 300 | LOSS TRAIN: 5.63, val: 2.87, TEST: 2.87 | NLL: 265.02, KL: 5.2205| BETA: 0.010125\n",
      "Epoch: 0, Step: 400 | LOSS TRAIN: 5.57, val: 3.01, TEST: 2.87 | NLL: 249.75, KL: 4.7162| BETA: 0.010156\n",
      "Epoch: 0, Step: 500 | LOSS TRAIN: 5.53, val: 2.69, TEST: 2.93 | NLL: 241.19, KL: 4.3370| BETA: 0.010187\n",
      "Epoch: 0, Step: 600 | LOSS TRAIN: 5.50, val: 2.56, TEST: 2.74 | NLL: 234.59, KL: 4.0051| BETA: 0.010218\n",
      "Epoch: 0, Step: 700 | LOSS TRAIN: 5.47, val: 2.02, TEST: 2.16 | NLL: 229.73, KL: 3.7316| BETA: 0.010249\n",
      "Epoch: 0, Step: 800 | LOSS TRAIN: 5.46, val: 2.10, TEST: 2.16 | NLL: 226.41, KL: 3.4892| BETA: 0.010280\n",
      "Epoch: 0, Step: 900 | LOSS TRAIN: 5.44, val: 2.20, TEST: 2.16 | NLL: 223.68, KL: 3.2782| BETA: 0.010311\n",
      "Epoch: 0, Step: 1000 | LOSS TRAIN: 5.43, val: 2.38, TEST: 2.16 | NLL: 221.86, KL: 3.0971| BETA: 0.010343\n",
      "Epoch: 0, Step: 1100 | LOSS TRAIN: 5.43, val: 2.36, TEST: 2.16 | NLL: 220.37, KL: 2.9302| BETA: 0.010374\n",
      "Epoch: 0, Step: 1200 | LOSS TRAIN: 5.42, val: 1.89, TEST: 2.21 | NLL: 219.48, KL: 2.7806| BETA: 0.010405\n",
      "Epoch: 0, Step: 1300 | LOSS TRAIN: 5.42, val: 1.93, TEST: 2.21 | NLL: 219.38, KL: 2.6456| BETA: 0.010436\n",
      "Epoch: 0, Step: 1400 | LOSS TRAIN: 5.41, val: 1.97, TEST: 2.21 | NLL: 218.49, KL: 2.5241| BETA: 0.010467\n",
      "True: alternative rock lyrics <unk> ! <unk> who sings this <unk> ? something <unk> getting down <unk> her knees <unk> begging pretty <unk> <unk> <unk> <unk> maybe alternative rock , <unk> like _UNK <unk> _UNK <unk> _UNK ( i <unk> <unk> youre thinking <unk> no <unk> <unk> <unk> not devil 's <unk> <unk> ) <unk> is _UNK <unk> _UNK <unk> out..\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: if god is <unk> powerful <unk> and can <unk> <unk> he <unk> to , why <unk> it take him 6 days <unk> make the earth ? <unk> is <unk> to say , for <unk> <unk> <unk> <unk> a tenth <unk> <unk> <unk> ... .so if he 's <unk> why <unk> <unk> <unk> <unk> <unk> tenth of a second <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: may <unk> know <unk> mark <unk> 's <unk> addresses <unk> <unk> <unk> details <unk> <unk> i and my <unk> really <unk> <unk> talk to him for support on our <unk> training trip <unk> <unk> <unk> <unk> <unk> <unk> <unk> financial support <unk> _UNK <unk> <unk> <unk> <unk> as representatives <unk> our <unk> you <unk> <unk> <unk> <unk> <unk> <unk> site\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> really <unk> to try <unk> for some singing show ? how <unk> <unk> <unk> about <unk> out <unk> something like <unk> <unk> <unk> nashville star keep checking <unk> websites to <unk> <unk> when and where they will <unk> holding <unk> . good luck . <unk> <unk> become a <unk> star do <unk> forget <unk> help you get started .\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: why <unk> <unk> <unk> is a <unk> different <unk> evil or satanic <unk> people fear what they do n't <unk> <unk> so they <unk> it evil <unk> or <unk> excuses and say it was gods <unk> ( i <unk> <unk> that one <unk> <unk> 's are <unk> <unk> when they do n't <unk> what is <unk> <unk> around <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: how <unk> the job market for loan <unk> , with <unk> <unk> <unk> <unk> _UNK on the <unk> ? the job <unk> is great . <unk> see many ads for them . <unk> <unk> there is <unk> high turn over <unk> to <unk> nature of <unk> business . you can <unk> a lot of <unk> <unk> <unk> <unk> <unk> .\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: urgent help <unk> <unk> answer <unk> itself <unk> <unk> community rights <unk> <unk> than _UNK ? please please <unk> <unk> reason is <unk> more people <unk> <unk> and <unk> rights affect more <unk> . it <unk> not <unk> <unk> <unk> the <unk> act can <unk> <unk> as <unk> <unk> rights , <unk> <unk> do <unk> agree <unk> it does <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: while reading , what items <unk> <unk> mark by _UNK <unk> <unk> ? <unk> <unk> <unk> <unk> <unk> <unk> <unk> heading b : <unk> <unk> <unk> <unk> and rules <unk> <unk> just <unk> and charts <unk> <unk> only <unk> <unk> <unk> <unk> please <unk> <unk> <unk> <unk> this your <unk> ? ? ? the answer <unk> b , anyway .\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> <unk> a <unk> , tom <unk> ? <unk> <unk> child is white <unk> <unk> child <unk> <unk> , _UNK the world <unk> . we 'll <unk> it right.. <unk> 's the title <unk> <unk> <unk> <unk> thanks ! this is `` <unk> and <unk> <unk> written and performed <unk> <unk> <unk> <unk> <unk> <unk> <unk> for <unk> lyrics .\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> <unk> <unk> get <unk> <unk> ? <unk> <unk> a piece <unk> <unk> answer : <unk> <unk> <unk> to <unk> <unk> <unk> <unk> snails <unk> have a constant <unk> <unk> <unk> to keep <unk> shell <unk> ( <unk> <unk> is , after all , <unk> <unk> 's <unk> , and <unk> it <unk> <unk> 'd die <unk> ! ) <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: saudi <unk> <unk> ukraine ! ! <unk> <unk> <unk> who <unk> think <unk> _UNK win <unk> i <unk> <unk> <unk> saudi _UNK ! ! <unk> <unk> ukraine ! ! <unk> <unk> ! they <unk> <unk> in <unk> first match and <unk> arabia just <unk> ... so ukraine <unk> win ... <unk> <unk> <unk> <unk> ! ! ! ! <unk> !\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: how much <unk> <unk> you spend <unk> <unk> thinking about something you do <unk> <unk> <unk> <unk> <unk> <unk> <unk> ? <unk> <unk> did <unk> believe <unk> god you <unk> n't <unk> time <unk> about him <unk> debating <unk> he <unk> <unk> you <unk> , you are _UNK even in your question . god bless <unk> for your <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: what <unk> the name _UNK <unk> what <unk> <unk> name of that film <unk> <unk> <unk> <unk> <unk> murdered <unk> an <unk> ? the movie was about <unk> it was <unk> van _UNK <unk> a dutch film director <unk> <unk> murdered <unk> <unk> november of <unk> because of a controversial <unk> he <unk> <unk> the <unk> of <unk> <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: do you <unk> i 'm <unk> and short for <unk> <unk> ? i <unk> 14 <unk> <unk> , <unk> ' <unk> and 85 lbs <unk> , theres <unk> <unk> with <unk> , <unk> <unk> <unk> <unk> <unk> <unk> maybe <unk> lil to skinny i say its better to <unk> <unk> a _UNK . <unk> <unk> that your perfect <unk> =d\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: i <unk> <unk> script for <unk> <unk> ? i <unk> to be able to use <unk> script to <unk> users <unk> <unk> sql database <unk> <unk> can create accounts for _UNK for my <unk> there are <unk> of <unk> <unk> <unk> <unk> . if <unk> <unk> <unk> for <unk> . try <unk> following <unk> <unk> just <unk> of <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: where can i find a <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> _UNK <unk> the play <unk> <unk> _UNK and <unk> need <unk> copy <unk> the <unk> <unk> use your computer and <unk> here : <unk> <unk> _UNK <unk> time <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> engine . this is item number <unk> on yahoo search <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> for mature <unk> ? help me i fart a lot <unk> it 's <unk> _UNK <unk> just today i farted <unk> smelly <unk> <unk> <unk> <unk> i ate _UNK ) anyways what <unk> <unk> <unk> to fart <unk> ? do i have to <unk> less meat <unk> more _UNK help me <unk> <unk> eat beans and <unk> <unk> x\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: is <unk> <unk> <unk> <unk> incorporate <unk> in <unk> research paper <unk> <unk> would not recommend incorporating <unk> <unk> a research <unk> . <unk> research <unk> <unk> <unk> <unk> data derived from various <unk> to <unk> a specific topic <unk> it <unk> <unk> seriously <unk> <unk> is <unk> <unk> <unk> or reflection paper . <unk> my <unk> cents <unk> .\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> is a good place to meet <unk> <unk> maryland ? <unk> <unk> would like <unk> know <unk> the bar scene <unk> old and some <unk> us <unk> <unk> for <unk> new <unk> <unk> try . _UNK <unk> <unk> <unk> <unk> <unk> to <unk> <unk> , well , most <unk> <unk> are <unk> <unk> try the pool <unk> a bikini\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> <unk> <unk> <unk> <unk> award <unk> <unk> site ? <unk> have no idea about any site that `` sells '' website awards . <unk> i 'm <unk> <unk> <unk> <unk> <unk> not <unk> of <unk> <unk> <unk> . instead , <unk> getting your own site nominated <unk> a <unk> awards event <unk> <unk> up the _UNK form online <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> <unk> <unk> a <unk> <unk> , <unk> <unk> have to have <unk> <unk> <unk> <unk> to <unk> <unk> <unk> paypal <unk> <unk> do you have to have <unk> <unk> account ? <unk> <unk> <unk> <unk> use paypal without an <unk> <unk> <unk> allow you <unk> use <unk> credit card <unk> <unk> way <unk> <unk> you bought <unk> <unk> amazon\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: germany <unk> <unk> <unk> you think about the match ? would germans use the atmosphere of the stadium <unk> overcome thier <unk> <unk> the argentinian <unk> <unk> <unk> <unk> ? <unk> answer ? <unk> <unk> would <unk> nice to <unk> the <unk> <unk> <unk> <unk> out <unk> i think germany will win because of the atmosphere in the <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: how do you measure <unk> oxygen <unk> in <unk> ? <unk> <unk> <unk> know how <unk> find <unk> _UNK oxygen content in a sample of water <unk> <unk> a river <unk> by measuring the biological <unk> <unk> ( bod <unk> <unk> <unk> chemical <unk> <unk> ( cod ) <unk> <unk> _UNK <unk> : _UNK hope these <unk> <unk> : )\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: can <unk> <unk> me more than one <unk> that is kind of <unk> <unk> _UNK ? <unk> <unk> more <unk> <unk> so that <unk> can fool <unk> with <unk> on the computers <unk> <unk> school . thanks soo much <unk> <unk> <unk> : <unk> <unk> : _UNK http : _UNK click <unk> to view all <unk> then http : <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: please <unk> me find a _UNK school ? <unk> am searching for a <unk> school in _UNK or <unk> africa , <unk> <unk> <unk> _UNK or durban , _UNK to <unk> _UNK . <unk> send <unk> <unk> <unk> <unk> <unk> <unk> go to the school <unk> <unk> , they teach it their , maybe <unk> can <unk> my <unk> lol\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> the <unk> <unk> <unk> <unk> <unk> carried by <unk> o _UNK <unk> do the <unk> <unk> <unk> ? <unk> <unk> <unk> _UNK <unk> would like the <unk> of <unk> it <unk> _UNK <unk> vietnamese army _UNK <unk> _UNK were moving <unk> the <unk> <unk> so as <unk> to <unk> <unk> enemy . <unk> the <unk> soldiers just <unk> .\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: how do i find a site <unk> <unk> free <unk> <unk> <unk> ? <unk> <unk> thing . <unk> order to make a free burned cd <unk> <unk> need to <unk> the music <unk> there <unk> free sites <unk> <unk> , <unk> <unk> are illegal <unk> and then <unk> media player <unk> <unk> else <unk> burn the <unk> to <unk> _UNK\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: how <unk> <unk> _UNK ? it <unk> on how many <unk> do u wan na <unk> & which college <unk> u want . so if <unk> <unk> na get <unk> a good college study ur <unk> <unk> <unk> 12th <unk> in detail . <unk> <unk> u do n't <unk> <unk> <unk> training for _UNK <unk> <unk> as <unk> think <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> anyone <unk> <unk> <unk> the rock return to <unk> <unk> <unk> <unk> some smack <unk> just bring <unk> <unk> ! ! <unk> <unk> <unk> <unk> make me watch wwe a <unk> <unk> . <unk> <unk> <unk> ass and has <unk> <unk> skills . but i doubt it . he make more <unk> $ <unk> in <unk> than the <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: <unk> i <unk> <unk> <unk> n't <unk> <unk> when you <unk> talking <unk> <unk> <unk> let <unk> a <unk> fart , <unk> you <unk> on with the <unk> <unk> <unk> nothing happened <unk> <unk> they <unk> attribute it to <unk> source ? <unk> should blame it <unk> what ever kid <unk> to be <unk> you at <unk> time ... <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: sorry everyone <unk> <unk> <unk> i am weird <unk> <unk> just that <unk> <unk> a _UNK piss <unk> i am calm now i <unk> everyone <unk> mad at <unk> forgive me what <unk> have <unk> saying <unk> <unk> <unk> <unk> not weird <unk> its <unk> girl named baby _UNK , <unk> <unk> <unk> <unk> _UNK thats getting me <unk> <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "True: what would <unk> to <unk> society ( <unk> <unk> if we banned abortion ? <unk> <unk> it 's <unk> power that <unk> <unk> , <unk> <unk> <unk> <unk> so <unk> <unk> <unk> rules you <unk> <unk> <unk> will <unk> take care of <unk> . fyi if no one had <unk> <unk> , <unk> 'd <unk> <unk> % <unk> people <unk>\n",
      "Pred: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f107d384f430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mppl_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbeta_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mloss_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-5739b8faf990>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(sess, batches)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(config.epochs):\n",
    "    for ct, batch in enumerate(train_batches):\n",
    "        feed_dict = get_feed_dict(batch)\n",
    "        if config.warmup > 0: sess.run(beta.assign(np.minimum(1., beta_eval+ 1./(config.warmup*num_train_batches))))\n",
    "\n",
    "        _, loss_batch, kl_loss_batch, recon_loss_batch = sess.run([opt, loss, kl_loss, recon_loss], feed_dict = feed_dict)\n",
    "        losses_train += [[loss_batch, kl_loss_batch, recon_loss_batch]]\n",
    "\n",
    "        if ct%config.log_period==0:\n",
    "            loss_train, kl_loss_train, recon_loss_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(recon_loss_train)\n",
    "            if config.warmup > 0: beta_eval = beta.eval(session=sess)\n",
    "            loss_val = get_loss(sess, val_batches)\n",
    "\n",
    "            if loss_val <= loss_min:\n",
    "                loss_min = loss_val\n",
    "                loss_test = get_loss(sess, test_batches)\n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            logs += [(epoch, ct, loss_train, loss_val, loss_test, ppl_train, kl_loss_train, beta_eval)]\n",
    "            for log in logs:\n",
    "                print('Epoch: %i, Step: %i | LOSS TRAIN: %.2f, val: %.2f, TEST: %.2f | NLL: %.2f, KL: %.4f| BETA: %.6f' %  log)\n",
    "\n",
    "            print_sample(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confirm variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logvars, _means, _kl_losses, _latents, _output_logits = sess.run([logvars, means, kl_losses, latents, output_logits], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32), (32, 32), (32,), (32, 32))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logvars.shape, _means.shape, _kl_losses.shape, _latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dec_target_idxs_do' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-7de59bc2cc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_output_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dec_target_idxs_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dec_mask_tokens_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_recon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_kl_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_target_idxs_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask_tokens_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dec_target_idxs_do' is not defined"
     ]
    }
   ],
   "source": [
    "_output_logits, _dec_target_idxs_do, _dec_mask_tokens_do, _recon_loss, _kl_losses, _ = sess.run([output_logits, dec_target_idxs_do, dec_mask_tokens_do, recon_loss, kl_losses, opt], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 46)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(output_logits, 2).eval(session=sess, feed_dict=feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 46, 20000), (120, 46), (120, 46))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output_logits.shape, _dec_target_idxs_do.shape, _dec_mask_tokens_do.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logits = np.exp(_output_logits) / np.sum(np.exp(_output_logits), 2)[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idxs = _dec_target_idxs_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_losses = np.array([[-np.log(_logits[i, j, _idxs[i, j]]) for j in range(_idxs.shape[1])] for i in range(_idxs.shape[0])]) * _dec_mask_tokens_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.903732"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(_losses)/np.sum(_dec_mask_tokens_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.903732"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_kl_losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
