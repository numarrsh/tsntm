{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import sys\n",
    "import pdb\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from six.moves import zip_longest\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import distributions as tfd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from data_structure import get_batches\n",
    "from components import tf_log, sample_latents, compute_kl_loss, dynamic_rnn, dynamic_bi_rnn\n",
    "from topic_model import TopicModel\n",
    "\n",
    "# from absl import logging\n",
    "# logging.warning('Worrying Stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNK = '<unk>' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "BOS = '<p>' # This has a vocab id, which is used at the beginning of every decoder input sequence\n",
    "EOS = '</p>' # This has a vocab id, which is used at the end of untruncated target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('gpu', '2', 'visible gpu')\n",
    "\n",
    "flags.DEFINE_string('mode', 'train', 'set train or eval')\n",
    "\n",
    "flags.DEFINE_string('data_path', 'data/apnews/instances.pkl', 'path of data')\n",
    "flags.DEFINE_string('modeldir', 'model', 'directory of model')\n",
    "flags.DEFINE_string('modelname', 'sports', 'name of model')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 1000, 'epochs')\n",
    "flags.DEFINE_integer('batch_size', 64, 'number of sentences in each batch')\n",
    "flags.DEFINE_integer('log_period', 500, 'valid period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.1, 'lr')\n",
    "flags.DEFINE_float('reg', 0.1, 'regularization term')\n",
    "flags.DEFINE_float('beta', 0.0, 'initial value of beta')\n",
    "flags.DEFINE_float('grad_clip', 5., 'grad_clip')\n",
    "\n",
    "flags.DEFINE_float('keep_prob', 0.8, 'dropout rate')\n",
    "flags.DEFINE_float('word_keep_prob', 0.75, 'word dropout rate')\n",
    "\n",
    "flags.DEFINE_integer('warmup', 5000, 'warmup period for KL')\n",
    "flags.DEFINE_integer('warmup_topic', 0, 'warmup period for KL of topic')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 2, 'beam_width')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('n_topic', 10, 'number of topic')\n",
    "flags.DEFINE_integer('dim_hidden_bow', 256, 'dim of hidden bow')\n",
    "flags.DEFINE_integer('dim_latent_topic', 32, 'dim of latent topic')\n",
    "flags.DEFINE_integer('dim_emb', 256, 'dim_emb')\n",
    "flags.DEFINE_integer('dim_hidden', 512, 'dim_hidden')\n",
    "flags.DEFINE_integer('dim_latent', 32, 'dim_latent')\n",
    "\n",
    "\n",
    "# for evaluation\n",
    "flags.DEFINE_string('refdir', 'ref', 'refdir')\n",
    "flags.DEFINE_string('outdir', 'out', 'outdir')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_bool('logtostderr', True, 'kernel')\n",
    "flags.DEFINE_bool('showprefixforinfo', False, '')\n",
    "flags.DEFINE_bool('verbosity', False, '')\n",
    "# flags.DEFINE_integer('stderrthreshold', 20, 'kernel')\n",
    "\n",
    "config = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.data_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_integer('PAD_IDX', word_to_idx[PAD], 'PAD_IDX')\n",
    "flags.DEFINE_integer('UNK_IDX', word_to_idx[UNK], 'UNK_IDX')\n",
    "flags.DEFINE_integer('BOS_IDX', word_to_idx[BOS], 'BOS_IDX')\n",
    "flags.DEFINE_integer('EOS_IDX', word_to_idx[EOS], 'EOS_IDX')\n",
    "\n",
    "flags.DEFINE_integer('n_vocab', len(word_to_idx), 'n_vocab')\n",
    "flags.DEFINE_integer('dim_bow', len(bow_idxs), 'dim_bow')\n",
    "\n",
    "maximum_iterations = max([max([instance.max_sent_l for instance in batch]) for ct, batch in dev_batches])\n",
    "flags.DEFINE_integer('maximum_iterations', maximum_iterations, 'maximum_iterations')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build language model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "t_variables = {}\n",
    "t_variables['bow'] = tf.placeholder(tf.float32, [None, config.dim_bow])\n",
    "t_variables['input_token_idxs'] = tf.placeholder(tf.int32, [None, None])\n",
    "t_variables['dec_input_idxs'] = tf.placeholder(tf.int32, [None, None])\n",
    "t_variables['dec_target_idxs'] = tf.placeholder(tf.int32, [None, None])\n",
    "t_variables['doc_l'] = tf.placeholder(tf.int32, [None])\n",
    "t_variables['sent_l'] = tf.placeholder(tf.int32, [None])\n",
    "t_variables['keep_prob'] = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(batch, mode='train', assertion=False):\n",
    "    def token_dropout(sent_idxs):\n",
    "        sent_idxs_dropout = np.asarray(sent_idxs)\n",
    "        sent_idxs_dropout[np.random.rand(len(sent_idxs)) > config.word_keep_prob] = config.UNK_IDX\n",
    "        return list(sent_idxs_dropout)\n",
    "\n",
    "    bow = np.array([instance.bow for instance in batch]).astype(np.float32)\n",
    "    \n",
    "    doc_l = np.array([len(instance.token_idxs) for instance in batch])\n",
    "    \n",
    "    feed_input_token_idxs_list = [sent_idxs for instance in batch for sent_idxs in instance.token_idxs]\n",
    "    feed_dec_input_idxs_list = [[config.BOS_IDX] + token_dropout(sent_idxs) for sent_idxs in feed_input_token_idxs_list]\n",
    "    feed_dec_target_idxs_list = [sent_idxs + [config.EOS_IDX]  for sent_idxs in feed_input_token_idxs_list]\n",
    "        \n",
    "    sent_l = np.array([len(sent_idxs) for sent_idxs in feed_input_token_idxs_list], np.int32)\n",
    "    \n",
    "    feed_input_token_idxs = pad_sequences(feed_input_token_idxs_list, padding='post', value=config.PAD_IDX, dtype=np.int32)\n",
    "    feed_dec_input_idxs = pad_sequences(feed_dec_input_idxs_list, padding='post', value=config.PAD_IDX, dtype=np.int32)\n",
    "    feed_dec_target_idxs = pad_sequences(feed_dec_target_idxs_list, padding='post', value=config.PAD_IDX, dtype=np.int32)\n",
    "    \n",
    "    if assertion:\n",
    "        index = 0\n",
    "        for instance in batch:\n",
    "            for line_idxs in instance.token_idxs:\n",
    "                assert feed_input_token_idxs_list[index] == line_idxs\n",
    "                index += 1\n",
    "        assert feed_input_token_idxs.shape[1] == np.max(sent_l)\n",
    "        assert feed_dec_input_idxs.shape[1] == np.max(sent_l) + 1\n",
    "        assert feed_dec_target_idxs.shape[1] == np.max(sent_l) + 1\n",
    "    \n",
    "    keep_prob = config.keep_prob if mode == 'train' else 1.0\n",
    "\n",
    "    feed_dict = {\n",
    "                t_variables['bow']: bow, \n",
    "                t_variables['doc_l']: doc_l, t_variables['sent_l']: sent_l, \n",
    "                t_variables['input_token_idxs']: feed_input_token_idxs, t_variables['dec_input_idxs']: feed_dec_input_idxs, t_variables['dec_target_idxs']: feed_dec_target_idxs, \n",
    "                t_variables['keep_prob']: keep_prob\n",
    "    }\n",
    "    return  feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_batches[0][1]\n",
    "get_feed_dict(batch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, sess_init=None):\n",
    "    if sess_init is None:\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    else:\n",
    "        sess = sess_init\n",
    "        \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    if sess_init is None: sess.close()\n",
    "\n",
    "def debug_value(variables, return_value=False, sess_init=None):\n",
    "    if sess_init is None:\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    else:\n",
    "        sess = sess_init\n",
    "\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    if return_value: \n",
    "        return _variables\n",
    "    else:\n",
    "        for _variable, variable in zip(_variables, variables):\n",
    "            if hasattr(variable, 'name'):\n",
    "                print(variable.name, ':', _variable)\n",
    "            else:\n",
    "                print(_variable)\n",
    "                \n",
    "    if sess_init is None: sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encode bow\n",
    "with tf.variable_scope('topic/enc', reuse=False):\n",
    "    hidden_bow_ = tf.keras.layers.Dense(units=config.dim_hidden_bow, activation=tf.nn.relu, name='hidden')(t_variables['bow'])\n",
    "    hidden_bow = tf.keras.layers.Dropout(t_variables['keep_prob'])(hidden_bow_)\n",
    "    means_bow = tf.keras.layers.Dense(units=config.dim_latent_topic)(hidden_bow)\n",
    "    logvars_bow = tf.keras.layers.Dense(units=config.dim_latent_topic, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0))(hidden_bow)\n",
    "    latents_bow = sample_latents(means_bow, logvars_bow) # sample latent vectors\n",
    "\n",
    "    prob_topic = tf.layers.Dense(units=config.n_topic, activation=tf.nn.softmax, name='prob')(latents_bow) # inference of topic probabilities\n",
    "\n",
    "# decode bow\n",
    "with tf.variable_scope('shared', reuse=False):\n",
    "    embeddings = tf.get_variable('emb', [config.n_vocab, config.dim_emb], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of vocab\n",
    "\n",
    "bow_embeddings = tf.nn.embedding_lookup(embeddings, bow_idxs) # embeddings of each bow features\n",
    "\n",
    "with tf.variable_scope('topic/dec', reuse=False):\n",
    "    topic_embeddings = tf.get_variable('topic_emb', [config.n_topic, config.dim_emb], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of topics\n",
    "\n",
    "    topic_bow = tf.nn.softmax(tf.matmul(topic_embeddings, bow_embeddings, transpose_b=True), 1) # bow vectors for each topic\n",
    "    logits_bow = tf_log(tf.matmul(prob_topic, topic_bow)) # predicted bow distribution\n",
    "\n",
    "# prior of each gaussian distribution (computed for each topic)\n",
    "with tf.variable_scope('topic/enc/infer', reuse=False):\n",
    "    means_topic = tf.keras.layers.Dense(units=config.dim_latent)(topic_bow)\n",
    "    logvars_topic = tf.keras.layers.Dense(units=config.dim_latent, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0))(topic_bow)\n",
    "sigma_topic = tf.exp(0.5 * logvars_topic)\n",
    "gauss_topic = tfd.Normal(loc=means_topic, scale=sigma_topic)    \n",
    "    \n",
    "# define losses\n",
    "topic_losses_recon = -tf.reduce_sum(tf.multiply(t_variables['bow'], logits_bow), 1)\n",
    "topic_loss_recon = tf.reduce_mean(topic_losses_recon) # negative log likelihood of each words\n",
    "\n",
    "topic_loss_kl = compute_kl_loss(means_bow, logvars_bow) # KL divergence b/w latent dist & gaussian std\n",
    "\n",
    "topic_embeddings_norm = topic_embeddings / tf.norm(topic_embeddings, axis=1, keepdims=True)\n",
    "topic_angles = tf.matmul(topic_embeddings_norm, tf.transpose(topic_embeddings_norm))\n",
    "topic_angles_mean = tf.reduce_mean(topic_angles, keepdims=True)\n",
    "topic_angles_vars = tf.reduce_mean(tf.square(topic_angles - topic_angles_mean))\n",
    "topic_loss_reg = topic_angles_vars - tf.squeeze(topic_angles_mean)\n",
    "\n",
    "# monitor\n",
    "n_bow = tf.reduce_sum(t_variables['bow'], 1)\n",
    "topic_ppls = tf.divide(topic_losses_recon, n_bow)\n",
    "topics_freq_bow_indices = tf.nn.top_k(topic_bow, 10, name='topic_freq_bow').indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic/enc/dropout/cond/Merge:0 : (10, 256)\n",
      "topic/enc/add:0 : (10, 32)\n",
      "topic/enc/prob/Softmax:0 : (10, 10)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([hidden_bow, latents_bow, prob_topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic/dec/topic_emb:0 : (10, 256)\n",
      "topic/dec/Softmax:0 : (10, 2661)\n",
      "topic/dec/Log:0 : (10, 2661)\n",
      "topic/enc/infer/dense_2/BiasAdd:0 : (10, 32)\n",
      "Neg:0 : (10,)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([topic_embeddings, topic_bow, logits_bow, means_topic, topic_losses_recon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum_3:0 : [0.99999994 1.         1.         1.         1.         1.\n",
      " 1.         0.99999994 1.         0.99999994]\n"
     ]
    }
   ],
   "source": [
    "debug_value([tf.reduce_sum(prob_topic, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "input_token_idxs = t_variables['input_token_idxs']\n",
    "batch_l, max_sent_l = tf.shape(input_token_idxs)[0], tf.shape(input_token_idxs)[1]\n",
    "sent_l = t_variables['sent_l']\n",
    "\n",
    "with tf.variable_scope('sent/enc', reuse=False):\n",
    "    # get word embedding\n",
    "    enc_input = tf.nn.embedding_lookup(embeddings, input_token_idxs)\n",
    "\n",
    "    # get sentence embedding\n",
    "    _, enc_state = dynamic_rnn(enc_input, sent_l, config.dim_hidden, t_variables['keep_prob'])\n",
    "\n",
    "    # TODO House Holder flow\n",
    "    prob_topic_infer = tf.layers.Dense(units=config.n_topic, activation=tf.nn.softmax)(enc_state)\n",
    "    \n",
    "    # inference of each gaussian dist. parameter\n",
    "    enc_state_infer = tf.tile(tf.expand_dims(enc_state, 1), [1, config.n_topic, 1]) # tile over topics\n",
    "    means_topic_infer = tf.keras.layers.Dense(units=config.dim_latent)(enc_state_infer)\n",
    "    logvars_topic_infer = tf.keras.layers.Dense(units=config.dim_latent, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0))(enc_state_infer)\n",
    "    sigma_topic_infer = tf.exp(0.5 * logvars_topic_infer)\n",
    "    gauss_topic_infer = tfd.Normal(loc=means_topic_infer, scale=sigma_topic_infer)\n",
    "\n",
    "    # latent vectors from each gaussian dist.\n",
    "    latents_topic_infer = sample_latents(means_topic_infer, logvars_topic_infer) \n",
    "    # latent vector from gaussian mixture    \n",
    "    latents_input = tf.matmul(tf.expand_dims(prob_topic_infer, -1), latents_topic_infer, transpose_a=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder_1:0 : (63, 36)\n",
      "sent/enc/rnn/while/Exit_3:0 : (63, 512)\n",
      "sent/enc/Tile:0 : (63, 10, 512)\n",
      "sent/enc/add:0 : (63, 10, 32)\n",
      "sent/enc/dense/Softmax:0 : (63, 10)\n",
      "sent/enc/MatMul:0 : (63, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([input_token_idxs, enc_state, enc_state_infer, latents_topic_infer, prob_topic_infer, latents_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum_4:0 : [1.         1.         0.99999994 0.99999994 1.0000001  1.0000001\n",
      " 1.         1.         0.99999994 1.         1.         1.\n",
      " 1.         1.         1.         0.9999999  0.99999994 1.\n",
      " 1.         1.         1.         1.         0.99999994 0.99999994\n",
      " 0.9999999  1.         0.99999994 1.         0.99999994 1.\n",
      " 1.0000001  1.         1.         1.0000001  0.99999994 1.\n",
      " 1.         0.99999994 1.         1.         1.0000001  1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99999994 1.         1.         0.99999994\n",
      " 0.99999994 1.         1.         1.         1.         1.0000001\n",
      " 0.99999994 1.         0.99999994]\n"
     ]
    }
   ],
   "source": [
    "debug_value([tf.reduce_sum(prob_topic_infer, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for decoding\n",
    "dec_sent_l = tf.add(sent_l, 1)\n",
    "dec_input_idxs = t_variables['dec_input_idxs']\n",
    "dec_input = tf.nn.embedding_lookup(embeddings, dec_input_idxs)\n",
    "\n",
    "dec_latents_input = tf.tile(latents_input, [1, tf.shape(dec_input)[1], 1])\n",
    "dec_concat_input = tf.concat([dec_input, dec_latents_input], -1)\n",
    "\n",
    "# decode for training\n",
    "with tf.variable_scope('sent/dec/rnn', initializer=tf.contrib.layers.xavier_initializer(), dtype = tf.float32, reuse=tf.AUTO_REUSE):\n",
    "    dec_cell = tf.contrib.rnn.GRUCell(config.dim_hidden)\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, output_keep_prob = t_variables['keep_prob'])\n",
    "\n",
    "    dec_initial_state = tf.layers.Dense(units=config.dim_hidden, activation=tf.nn.relu)(tf.squeeze(latents_input, 1))\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_concat_input, sequence_length=dec_sent_l)\n",
    "\n",
    "    train_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        cell=dec_cell,\n",
    "        helper=helper,\n",
    "        initial_state=dec_initial_state)\n",
    "\n",
    "    dec_outputs, _, output_sent_l = tf.contrib.seq2seq.dynamic_decode(train_decoder)\n",
    "    \n",
    "    output_layer = tf.layers.Dense(config.n_vocab, use_bias=False, name='out')\n",
    "    output_logits = output_layer(dec_outputs.rnn_output)\n",
    "    \n",
    "    output_token_idxs = tf.argmax(output_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat:0 : (63, 37, 288)\n",
      "sent/dec/rnn/dense/Relu:0 : (63, 512)\n",
      "sent/dec/rnn/out/Tensordot:0 : (63, 37, 30832)\n",
      "sent/dec/rnn/ArgMax:0 : (63, 37)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([dec_concat_input, dec_initial_state, output_logits, output_token_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## language modeling cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and mask\n",
    "dec_target_idxs = t_variables['dec_target_idxs']\n",
    "dec_mask_tokens = tf.sequence_mask(dec_sent_l, maxlen=max_sent_l+1, dtype=tf.float32)\n",
    "\n",
    "# nll for each token (averaged over batch & sentence)\n",
    "sent_loss_recon = tf.contrib.seq2seq.sequence_loss(output_logits, dec_target_idxs, dec_mask_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_l = t_variables['doc_l']\n",
    "mask_sents = tf.sequence_mask(doc_l)\n",
    "mask_sents_flatten = tf.reshape(mask_sents, [tf.shape(mask_sents)[0]*tf.shape(mask_sents)[1]])\n",
    "\n",
    "prob_topic_tiled = tf.tile(tf.expand_dims(prob_topic, 1), [1, tf.shape(mask_sents)[1], 1])\n",
    "prob_topic_flatten = tf.reshape(prob_topic_tiled, [tf.shape(mask_sents)[0]*tf.shape(mask_sents)[1], config.n_topic])\n",
    "prob_topic_sents = tf.boolean_mask(prob_topic_flatten, mask_sents_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferred mixture probabilities (computed for each sentence)\n",
    "categ_topic_infer = tfd.Categorical(probs=prob_topic_infer)\n",
    "\n",
    "# prior of mixture probabilities (computed for each document, tiled for each sentence)\n",
    "categ_topic = tfd.Categorical(probs=prob_topic_sents)\n",
    "\n",
    "sent_loss_kl_categ = tf.reduce_mean(tfd.kl_divergence(categ_topic_infer, categ_topic))\n",
    "\n",
    "# inference of each gaussian gaussribution (computed for each sentence)\n",
    "\n",
    "sent_loss_kl_gauss = tf.reduce_sum(tfd.kl_divergence(gauss_topic_infer, gauss_topic), -1)\n",
    "sent_loss_kl_gmm = tf.reduce_mean(tf.reduce_sum(tf.multiply(prob_topic_infer, sent_loss_kl_gauss), -1))\n",
    "\n",
    "sent_loss_kl = sent_loss_kl_categ + sent_loss_kl_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder_4:0 : (10,)\n",
      "SequenceMask_1/Less:0 : (10, 9)\n",
      "Reshape:0 : (90,)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([doc_l, mask_sents, mask_sents_flatten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile_1:0 : (10, 9, 10)\n",
      "Reshape_1:0 : (90, 10)\n",
      "boolean_mask/GatherV2:0 : (63, 10)\n",
      "sent/enc/dense/Softmax:0 : (63, 10)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([prob_topic_tiled, prob_topic_flatten, prob_topic_sents, prob_topic_infer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceMask_1/Less:0 : [[ True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True  True False False]\n",
      " [ True  True  True  True  True  True  True False False]\n",
      " [ True  True  True  True  True  True False False False]\n",
      " [ True  True  True  True  True  True False False False]\n",
      " [ True  True  True  True  True  True False False False]\n",
      " [ True  True  True  True  True False False False False]\n",
      " [ True  True  True  True  True False False False False]\n",
      " [ True  True  True  True False False False False False]]\n",
      "Reshape:0 : [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True False False  True  True  True  True  True  True  True False False\n",
      "  True  True  True  True  True  True False False False  True  True  True\n",
      "  True  True  True False False False  True  True  True  True  True  True\n",
      " False False False  True  True  True  True  True False False False False\n",
      "  True  True  True  True  True False False False False  True  True  True\n",
      "  True False False False False False]\n"
     ]
    }
   ],
   "source": [
    "debug_value([mask_sents, mask_sents_flatten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent/enc/dense_5/BiasAdd:0 : (63, 10, 32)\n",
      "topic/enc/infer/dense_2/BiasAdd:0 : (10, 32)\n"
     ]
    }
   ],
   "source": [
    "debug_shape([means_topic_infer, means_topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m-isonuma/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "beta = tf.Variable(config.beta, name='beta', trainable=False) if config.warmup > 0 else tf.constant(1., name='beta')\n",
    "update_beta = tf.assign_add(beta, 1./(config.warmup*len(train_batches)))\n",
    "sent_loss = sent_loss_recon + beta * sent_loss_kl\n",
    "\n",
    "topic_loss = topic_loss_recon + topic_loss_kl + config.reg * topic_loss_reg\n",
    "loss = topic_loss + sent_loss\n",
    "\n",
    "# define optimizer\n",
    "if config.opt == 'Adam':\n",
    "    optimizer = tf.train.AdamOptimizer(config.lr)\n",
    "elif config.opt == 'Adagrad':\n",
    "    optimizer = tf.train.AdagradOptimizer(config.lr)\n",
    "    \n",
    "grad_vars = optimizer.compute_gradients(loss)\n",
    "clipped_grad_vars = [(tf.clip_by_value(grad, -config.grad_clip, config.grad_clip), var) for grad, var in grad_vars]\n",
    "\n",
    "opt = optimizer.apply_gradients(clipped_grad_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxs_to_sents(token_idxs, config, idx_to_word):\n",
    "    sents = []\n",
    "    for sent_idxs in token_idxs:\n",
    "        tokens = []\n",
    "        for idx in sent_idxs:\n",
    "            if idx == config.EOS_IDX: break\n",
    "            tokens.append(idx_to_word[idx])\n",
    "        sent = ' '.join(tokens)\n",
    "        sents.append(sent)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(sess, batches):\n",
    "    losses = []\n",
    "    ppl_list = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_batch, sent_loss_batch, ppls_batch = sess.run([loss, topic_loss, sent_loss, topic_ppls], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_batch, sent_loss_batch]]\n",
    "        ppl_list += list(ppls_batch)\n",
    "    loss_mean, topic_loss_mean, sent_loss_mean = np.mean(losses, 0)\n",
    "    ppl_mean = np.exp(np.mean(ppl_list))\n",
    "    return loss_mean, topic_loss_mean, sent_loss_mean, ppl_mean\n",
    "\n",
    "def get_all_losses(sess, batches):\n",
    "    losses = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, sent_loss_recon_batch, sent_loss_kl_batch = \\\n",
    "        sess.run([loss, topic_loss_recon, topic_loss_kl, sent_loss_recon, sent_loss_kl], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, sent_loss_recon_batch, sent_loss_kl_batch]]\n",
    "    print('LOSS %.2f | TM NLL: %.2f, KL: %.4f | LM NLL: %.2f, KL: %.4f' %  np.mean(losses, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(sample_batch):\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    pred_token_idxs = sess.run(output_token_idxs, feed_dict = feed_dict)\n",
    "    true_token_idxs = [sent_idxs for instance in sample_batch for sent_idxs in instance.token_idxs]\n",
    "    \n",
    "    assert len(pred_token_idxs) == len(true_token_idxs)\n",
    "    \n",
    "    pred_sents = idxs_to_sents(pred_token_idxs, config, idx_to_word)\n",
    "    true_sents = idxs_to_sents(true_token_idxs, config, idx_to_word)\n",
    "    \n",
    "    for true_sent, pred_sent in zip(true_sents, pred_sents):        \n",
    "        print('True: %s' % true_sent)\n",
    "        print('Pred: %s' % pred_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "logs = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "loss_min = np.inf\n",
    "beta_eval = 1.\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "008[s], 06[s], Ep: 00, Ct: 00000|TR LOSS: 344, PPL: 2660|TM NLL: 333, KL: 0.76 | LM NLL: 10.34, KL: 0.77|DE LOSS: 347, PPL: 2658, TM: 337, LM: 10.34|BETA: 0.000000\n",
      "067[s], 06[s], Ep: 00, Ct: 00500|TR LOSS: 328, PPL: 1648|TM NLL: 320, KL: 0.87 | LM NLL: 7.37, KL: 166.99|DE LOSS: 319, PPL: 1452, TM: 312, LM: 7.00|BETA: 0.000035\n",
      "067[s], 06[s], Ep: 00, Ct: 01000|TR LOSS: 324, PPL: 1522|TM NLL: 316, KL: 1.42 | LM NLL: 7.09, KL: 150.72|DE LOSS: 316, PPL: 1353, TM: 309, LM: 6.69|BETA: 0.000069\n",
      "True: the family of missing utah mother susan powell has settled a court battle over insurance money with the family of her husband , josh powell , who was the only suspect in her disappearance\n",
      "Pred: a say of the the a the a a a a a a a a the a a the , the the the a the\n",
      "True: court records show that two sides reached an agreement in salt lake city thursday resolving the dispute over about $ # million in proceeds from life insurance\n",
      "Pred: the say of the the the a the a a the , a , the a a the the the the the the the\n",
      "True: details about the settlement , which was first reported by the fox # tv station , were not publicly disclosed in court records\n",
      "Pred: the say was the a a a a , the , the the the the the the the\n",
      "True: susan powell disappeared in # and has never been found\n",
      "Pred: the was was was the the the\n",
      "True: while josh powell was investigated as a suspect in his wife 's disappearance , he was n't arrested before he killed himself and the couple 's boys in #\n",
      "Pred: the say , the the the a a a , , a the a , the , , , , the the\n",
      "True: attorneys did not immediately return phone messages seeking comment on the case\n",
      "Pred: the was was the the the the the the\n",
      "True: josh powell 's sister <unk> powell and mother , <unk> powell , had argued they were entitled to half the proceeds from life insurance policies taken out on the couple and their two sons\n",
      "Pred: a say of a the <unk> a the a the the , the a the the the the the the the the the the the\n",
      "True: they argued that susan powell 's father , charles cox , wrongly shut them out of the estate in #\n",
      "Pred: the say was the the the the a the the the a the the the the the\n",
      "True: an attorney for her family has said they want to donate the money to charity\n",
      "Pred: the say was the the the the the the the the the\n",
      "True: officials at the rhode island department of environmental management say an aerial survey conducted in june found more than # acres were <unk> this year as a result of the winter moth caterpillar\n",
      "Pred: the say of the the a a a a a a the a a the the the the a , the the the the\n",
      "True: that 's a tenfold increase from last year\n",
      "Pred: the was the the the\n",
      "True: the moths are originally from europe\n",
      "Pred: the was was\n",
      "True: they are <unk> <unk> while caterpillars\n",
      "Pred: the the was\n",
      "True: repeated years of <unk> can severely damage trees\n",
      "Pred: the was was was the #\n",
      "True: commercial fruit growers have begun using chemical insecticides to prevent the caterpillars from destroying their crops\n",
      "Pred: the say was the the the the the the the the the the\n",
      "True: it is not clear why the moth population is growing so rapidly\n",
      "Pred: the was was the the the the the the\n",
      "True: officials say it is too late in the season to do anything about the moths\n",
      "Pred: the say the the the the the the the the the the the\n",
      "True: gov . jack markell is proposing a # cent increase in delaware 's gas tax to pay for $ # million in additional spending on roads and bridges in delaware\n",
      "Pred: the say the the the a a a a a the the a the , , , the the the the the\n",
      "True: in his state of the state address last week , markell proposed investing $ # billion in the state transportation trust fund over the next five years\n",
      "Pred: the say the the the the the a the a the the the the the the the a the the the the the\n",
      "True: that 's a $ # million increase over the current spending plan\n",
      "Pred: the was was the the the the the the\n",
      "True: markell and transportation secretary <unk> <unk> held a news conference wednesday to give more details on the plan\n",
      "Pred: the say was the the the the the the the the the the the the the\n",
      "True: administration officials say the tax increase would cost a typical driver in delaware about $ # more a year\n",
      "Pred: the say was the the the the the the the the the the the the the the\n",
      "True: in addition to the gas tax increase , officials are proposing an additional $ # million in annual borrowing\n",
      "Pred: the say the the the a the the the the the the the the the the\n",
      "True: officials say the infrastructure spending will improve safety , boost the economy and create jobs\n",
      "Pred: the say the the the the the a the the the the\n",
      "True: police say a st. louis area man stole $ # worth of jewelry from a co worker while he was house sitting for her and her husband\n",
      "Pred: the say the the the the a a a a a the the , a , the the the the\n",
      "True: ladue police say # year old andrew bauer of creve coeur took <unk> , pins , bracelets , rings , <unk> and earrings from barbara <unk> and her husband in august while the couple was on vacation\n",
      "Pred: the say the the a a a , a a , a , the the , the the the a the the the the\n",
      "True: court documents say bauer sold some of the jewelry for $ #\n",
      "Pred: the say was the the the the the the\n",
      "True: the st. louis post dispatch reports ( http : <unk> # ) bauer told police he needed money to pay debts and for a car payment\n",
      "Pred: the say of the the the the a the the a the the the , the the the the the the the\n",
      "True: bauer is charged with one felony count of stealing and is jailed on $ # bail\n",
      "Pred: the say the was the the the the a the the the the the\n",
      "True: he also faces a stealing charge for allegedly taking a $ # ring from his aunt\n",
      "Pred: the say was was the a the the the the the the the\n",
      "True: bauer 's attorney , james <unk> , declined to comment on either case\n",
      "Pred: the say was the the the the the the the\n",
      "True: a man serving a life sentence for killing a police officer has been denied a request to attend his grandmother 's funeral in new york city\n",
      "Pred: the say a the the the a a a the a a a a the the the the the the the the the\n",
      "True: the state corrections department told the daily news ( http : <unk> ) that todd scott 's bid for a furlough was denied due to security concerns\n",
      "Pred: the say a a a the a a a a the a , the a the the the the a the the the\n",
      "True: scott is serving his sentence at the maximum security <unk> correctional facility in upstate erie county\n",
      "Pred: the say the the the the a the the the the the the\n",
      "True: the decision was by the facility 's superintendent , dale <unk>\n",
      "Pred: the was was the the the the the\n",
      "True: nypd spokesman paul browne said that police commissioner raymond kelly opposed furloughs for any reason for anyone convicted of killing a police officer\n",
      "Pred: the say say the the the the a the the a the the the the the the\n",
      "True: scott was convicted of killing officer edward byrne as he sat in a patrol car guarding a prosecution witness ' home in queens on feb. # , #\n",
      "Pred: the say the the the the the a a a the the a the the the , a the the the\n",
      "True: the state pardons board is reviewing the case of a georgia death row inmate who is set to die this month for the # slaying of an elderly woman in savannah\n",
      "Pred: the say the the the a a , , a a , a the the a the a the the the the the the the the the\n",
      "True: roy willard blankenship 's attorneys asked the georgia board of pardons and paroles on monday to spare his life and cancel the june # execution\n",
      "Pred: the say the the a a a the the , a a the a the the the the the the\n",
      "True: it did not immediately issue a decision\n",
      "Pred: the was was the the\n",
      "True: defense attorney brian <unk> said he also urged dr. carlo musso , who assisted georgia in conducting executions , to refuse to participate in blankenship 's death\n",
      "Pred: the say the the a the a a the the a a the the a a a the , the the the the\n",
      "True: blankenship would be the first person put to death in georgia using a new three drug execution combination\n",
      "Pred: the say was the the the the the the a the the the the the\n",
      "True: a switch was needed after the state surrendered its supply of the sedative sodium thiopental to federal regulators amid questions about how it was obtained\n",
      "Pred: the say the the the the the a the the a a the the a the the the the the\n",
      "True: an iowa motorcycle driver was critically hurt when he collided with a sport utility vehicle in des moines\n",
      "Pred: the say was the the the a the the the the the the the the\n",
      "True: police say that # year old bradford clikeman is not expected to survive the injuries he sustained saturday even though he was wearing a helmet\n",
      "Pred: the say of the a the a a the , the the the the the the the a the the the\n",
      "True: police say the # year old driver of a kia suv turned left in front of clikeman as both vehicles were in the same intersection\n",
      "Pred: the say say the the a the a the a a a the the the a the the the the the the\n",
      "True: matthew <unk> 's suv collided with clikeman 's motorcycle\n",
      "Pred: the was was the the the\n",
      "True: <unk> was not hurt in the crash\n",
      "Pred: the was was the #\n",
      "True: police have said alcohol was not a factor in the crash that happened around # p.m. saturday , but they are continuing to investigate\n",
      "Pred: the say the the the the a a a a , the the the the the the a the the the the\n",
      "True: dutch bank rabobank says its men 's cycling team will be renamed blanco pro cycling team next year\n",
      "Pred: the say was the the the a the a the the the the the\n",
      "True: the team is still looking for a sponsor\n",
      "Pred: the was was the the\n",
      "True: rabobank announced this year it was ending its sponsorship of the men 's team because of lost trust in the sport after the u.s. anti doping agency report on lance armstrong\n",
      "Pred: the say of of the a the a the the a , the the , the the the a the the the the the the the the\n",
      "True: on thursday , rabobank said in a statement if a new sponsor does not come forward , the team will fold at the end of #\n",
      "Pred: the say the the the a the a a , , , the a , the the the the the the the\n",
      "True: the team includes dutch rider robert <unk> and <unk> luis leon sanchez , who each won a stage in the # and # tours de france\n",
      "Pred: the say of the the a a a the a , , , the the the the a the the\n",
      "True: a northeastern indiana woman who pleaded guilty to killing her husband by hitting him in the head several times with an ax has been sentenced to # years in prison\n",
      "Pred: the say of the the a the a the a a a , the the , the the the the the the the the the\n",
      "True: steuben superior judge william fee gave # year old norma jean mote of angola the minimum term for murder on monday\n",
      "Pred: the say of the the a the the a the , the a a the the the the the\n",
      "True: mote agreed to a plea deal last month in which she admitted to killing her husband , kevin , at the couple 's home near angola\n",
      "Pred: a say the the the a a a a the the , the , , the the the the the\n",
      "True: police say he was found dead in a second floor bedroom and the couple 's two teenage boys were home at the time of the attack\n",
      "Pred: the say of the the the a a the the the the , the the the the the the the the\n",
      "True: radio station <unk> fm in angola reported norma jean mote testified she and her husband had a lot of arguments during a # year marriage and she was mad at him for lying about marijuana smoking\n",
      "Pred: the say the the a a a a a the the a , the the a the , , the the the the the the the\n",
      "True: the national weather service has issued a hurricane watch and a flood watch for long island , new york city and rockland , westchester and putnam counties\n",
      "Pred: the say say the the a a a a a the , a the the , , the the the the the the\n",
      "True: a hurricane watch means hurricane conditions are possible within the next # hours\n",
      "Pred: the was the the the the the the the the\n",
      "True: hurricane irene has weakened slightly to a category # storm as it approaches the east coast , where a hurricane warning has been extended to new jersey\n",
      "Pred: the say the the the the a a a a a , the the a the the the the\n",
      "True: the new hurricane warning area now extends from north carolina 's coast , northward to sandy hook , n.j. , which is just south of new york city\n",
      "Pred: the say was the the the a a a the a a , a the , the the the the the\n",
      "True: a hurricane warning means hurricane conditions are expected within # hours\n",
      "Pred: the was was the the the the the\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for epoch in range(config.epochs):\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = get_feed_dict(batch)\n",
    "        if config.warmup > 0 and beta_eval < 1.0: sess.run(update_beta)\n",
    "\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, sent_loss_recon_batch, sent_loss_kl_batch, ppls_batch = \\\n",
    "        sess.run([opt, loss, topic_loss_recon, topic_loss_kl, sent_loss_recon, sent_loss_kl, topic_ppls], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, sent_loss_recon_batch, sent_loss_kl_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if ct%config.log_period==0:\n",
    "            time_dev = time.time()\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, sent_loss_recon_train, sent_loss_kl_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_dev, sent_loss_dev, ppl_dev = get_loss(sess, dev_batches)\n",
    "\n",
    "            if config.warmup > 0: beta_eval = beta.eval(session=sess)\n",
    "\n",
    "            clear_output()\n",
    "            time_finish = time.time()\n",
    "            time_log = int(time_finish - time_start)\n",
    "            time_log_dev = int(time_finish - time_dev)\n",
    "            logs += [(time_log, time_log_dev, epoch, ct, loss_train, ppl_train, topic_loss_recon_train, topic_loss_kl_train, sent_loss_recon_train, sent_loss_kl_train, loss_dev, ppl_dev, topic_loss_dev, sent_loss_dev, beta_eval)]\n",
    "            for log in logs:\n",
    "                print('%03d[s], %02d[s], Ep: %02d, Ct: %05d|TR LOSS: %.0f, PPL: %.0f|TM NLL: %.0f, KL: %.2f | LM NLL: %.2f, KL: %.2f|DE LOSS: %.0f, PPL: %.0f, TM: %.0f, LM: %.2f|BETA: %.6f' %  log)\n",
    "\n",
    "            print_sample(batch)\n",
    "\n",
    "            time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : republican senate democratic house election party campaign governor republicans gov\n",
      "1 : court judge federal u.s. attorney lawsuit filed case district law\n",
      "2 : million company http water project reports federal department u.s. plant\n",
      "3 : vehicle car crash driver truck died driving killed hit struck\n",
      "4 : department http people reports health office law officers week security\n",
      "5 : percent million company cents share revenue billion rate shares average\n",
      "6 : national saturday event museum died day years u.s. center president\n",
      "7 : bill tax budget million health lawmakers house measure gov approved\n",
      "8 : school university students board education program president college schools district\n",
      "9 : fire firefighters area reported authorities home people sunday miles blaze\n",
      "10 : found home officers authorities shot woman sheriff shooting arrested body\n",
      "11 : charged guilty prosecutors charges court years prison pleaded attorney murder\n",
      "12 : service weather power national storm snow tuesday expected rain customers\n"
     ]
    }
   ],
   "source": [
    "# visualize topic\n",
    "topics_freq_bow_idxs = bow_idxs[sess.run(topics_freq_bow_indices)]\n",
    "for topic, topic_freq_bow_idxs in enumerate(topics_freq_bow_idxs):\n",
    "    print(topic, ':', ' '.join([idx_to_word[idx] for idx in topic_freq_bow_idxs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confirm variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logvars, _means, _kl_losses, _latents, _output_logits = sess.run([logvars, means, kl_losses, latents, output_logits], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32), (32, 32), (32,), (32, 32))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logvars.shape, _means.shape, _kl_losses.shape, _latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dec_target_idxs_do' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-7de59bc2cc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_output_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dec_target_idxs_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dec_mask_tokens_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_recon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_kl_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_target_idxs_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask_tokens_do\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dec_target_idxs_do' is not defined"
     ]
    }
   ],
   "source": [
    "_output_logits, _dec_target_idxs_do, _dec_mask_tokens_do, _recon_loss, _kl_losses, _ = sess.run([output_logits, dec_target_idxs_do, dec_mask_tokens_do, recon_loss, kl_losses, opt], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 46)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(output_logits, 2).eval(session=sess, feed_dict=feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 46, 20000), (120, 46), (120, 46))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output_logits.shape, _dec_target_idxs_do.shape, _dec_mask_tokens_do.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logits = np.exp(_output_logits) / np.sum(np.exp(_output_logits), 2)[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idxs = _dec_target_idxs_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_losses = np.array([[-np.log(_logits[i, j, _idxs[i, j]]) for j in range(_idxs.shape[1])] for i in range(_idxs.shape[0])]) * _dec_mask_tokens_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.903732"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(_losses)/np.sum(_dec_mask_tokens_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.903732"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_kl_losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
