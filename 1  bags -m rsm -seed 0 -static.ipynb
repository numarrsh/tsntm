{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from gsm import GaussianSoftmaxModel\n",
    "from rsm import RecurrentStickbreakingModel\n",
    "from evaluation import validate, print_flat_topic_sample\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    return _variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','VALID:','','','','','TEST:',''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG','LOSS','PPL']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "if config.model == 'gsm':\n",
    "    Model = GaussianSoftmaxModel\n",
    "elif config.model == 'rsm':\n",
    "    Model = RecurrentStickbreakingModel\n",
    "model = Model(config)    \n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>111.81</td>\n",
       "      <td>507</td>\n",
       "      <td>111.03</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.36</td>\n",
       "      <td>482</td>\n",
       "      <td>103.53</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.51</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>111.46</td>\n",
       "      <td>492</td>\n",
       "      <td>110.51</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.30</td>\n",
       "      <td>474</td>\n",
       "      <td>103.26</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.27</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>111.29</td>\n",
       "      <td>484</td>\n",
       "      <td>110.23</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.42</td>\n",
       "      <td>475</td>\n",
       "      <td>103.29</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.27</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TRAIN:                           VALID:               \\\n",
       "      Time  Ep  Ct    LOSS  PPL     NLL    KL   REG    LOSS  PPL     NLL   \n",
       "5000    37  10   9  111.81  507  111.03  0.77  0.01  104.36  482  103.53   \n",
       "10000   35  20  19  111.46  492  110.51  0.94  0.01  104.30  474  103.26   \n",
       "15000   35  30  29  111.29  484  110.23  1.05  0.01  104.42  475  103.29   \n",
       "\n",
       "                    TEST:       \n",
       "         KL   REG    LOSS  PPL  \n",
       "5000   0.83  0.00  102.51  479  \n",
       "10000  1.04  0.00  102.27  462  \n",
       "15000  1.13  0.00  102.27  462  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 carry pockets room pocket strap back space work small handle\n",
      "1 ! love cover color nice bottom recommend hard top perfectly\n",
      "2 sleeve ; & protection inch inside material zipper snug neoprene\n",
      "3 months $ ... amazon quality broke bought years money time\n",
      "4 air price pro perfectly ... item nice smell scratches protection\n",
      "5 smell price - made time reviews item bad ... cheap\n",
      "6 high big long inside 've chromebook school fine huge leather\n",
      "7 pattern minor lock fine inch base job giving daughter excellent\n",
      "8 knew / line memory kinda durability imagine mba doubt place\n",
      "9 - snug weight found sits things stitching amazon similar rating\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topics_freq_tokens = [[idx_to_word[idx] for idx in topic_freq_idxs] for topic_freq_idxs in topics_freq_idxs]\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)\n",
    "\n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.tree_idxs, update_tree_flg = model.update_tree(topic_prob_topic, recur_prob_topic)\n",
    "                if update_tree_flg:\n",
    "                    print(config.tree_idxs)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = Model(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "display(log_df)\n",
    "print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
