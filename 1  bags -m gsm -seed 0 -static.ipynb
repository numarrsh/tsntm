{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from gsm import GaussianSoftmaxModel\n",
    "from evaluation import validate, print_flat_topic_sample\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    return _variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','VALID:','','','','','TEST:',''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG','LOSS','PPL']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "if config.model == 'gsm':\n",
    "    Model = GaussianSoftmaxModel\n",
    "elif config.model == 'rsm':\n",
    "    Model = RecurrentStickbreakingModel\n",
    "model = Model(config)    \n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>113.07</td>\n",
       "      <td>548</td>\n",
       "      <td>112.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.11</td>\n",
       "      <td>104.70</td>\n",
       "      <td>498</td>\n",
       "      <td>104.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.87</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>112.36</td>\n",
       "      <td>523</td>\n",
       "      <td>111.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>104.45</td>\n",
       "      <td>484</td>\n",
       "      <td>103.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>102.59</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>112.03</td>\n",
       "      <td>510</td>\n",
       "      <td>111.17</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.05</td>\n",
       "      <td>104.52</td>\n",
       "      <td>486</td>\n",
       "      <td>103.58</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.02</td>\n",
       "      <td>102.59</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>111.81</td>\n",
       "      <td>502</td>\n",
       "      <td>110.87</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.04</td>\n",
       "      <td>104.39</td>\n",
       "      <td>473</td>\n",
       "      <td>103.33</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.39</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>111.64</td>\n",
       "      <td>494</td>\n",
       "      <td>110.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.04</td>\n",
       "      <td>104.14</td>\n",
       "      <td>464</td>\n",
       "      <td>102.91</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.21</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>111.48</td>\n",
       "      <td>488</td>\n",
       "      <td>110.37</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>103.94</td>\n",
       "      <td>455</td>\n",
       "      <td>102.62</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.03</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>111.35</td>\n",
       "      <td>483</td>\n",
       "      <td>110.17</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>103.86</td>\n",
       "      <td>452</td>\n",
       "      <td>102.46</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.70</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>16</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>111.24</td>\n",
       "      <td>478</td>\n",
       "      <td>109.99</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>103.67</td>\n",
       "      <td>443</td>\n",
       "      <td>102.19</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.86</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45000</th>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>111.13</td>\n",
       "      <td>473</td>\n",
       "      <td>109.83</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>103.63</td>\n",
       "      <td>441</td>\n",
       "      <td>102.10</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.63</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>111.04</td>\n",
       "      <td>470</td>\n",
       "      <td>109.69</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>103.62</td>\n",
       "      <td>441</td>\n",
       "      <td>102.04</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.63</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55000</th>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>110.95</td>\n",
       "      <td>466</td>\n",
       "      <td>109.57</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>103.45</td>\n",
       "      <td>435</td>\n",
       "      <td>101.84</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.57</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TRAIN:                           VALID:               \\\n",
       "      Time   Ep   Ct    LOSS  PPL     NLL    KL   REG    LOSS  PPL     NLL   \n",
       "5000    17   10    9  113.07  548  112.45  0.51  0.11  104.70  498  104.00   \n",
       "10000   16   20   19  112.36  523  111.60  0.69  0.07  104.45  484  103.67   \n",
       "15000   16   30   29  112.03  510  111.17  0.81  0.05  104.52  486  103.58   \n",
       "20000   16   40   39  111.81  502  110.87  0.90  0.04  104.39  473  103.33   \n",
       "25000   16   50   49  111.64  494  110.61  0.99  0.04  104.14  464  102.91   \n",
       "30000   16   60   59  111.48  488  110.37  1.08  0.03  103.94  455  102.62   \n",
       "35000   16   70   69  111.35  483  110.17  1.15  0.03  103.86  452  102.46   \n",
       "40000   16   80   79  111.24  478  109.99  1.22  0.03  103.67  443  102.19   \n",
       "45000   17   90   89  111.13  473  109.83  1.27  0.02  103.63  441  102.10   \n",
       "50000   16  100   99  111.04  470  109.69  1.32  0.02  103.62  441  102.04   \n",
       "55000   16  110  109  110.95  466  109.57  1.36  0.02  103.45  435  101.84   \n",
       "\n",
       "                    TEST:       \n",
       "         KL   REG    LOSS  PPL  \n",
       "5000   0.65  0.04  102.87  491  \n",
       "10000  0.75  0.02  102.59  477  \n",
       "15000  0.93  0.02  102.59  477  \n",
       "20000  1.04  0.01  102.39  465  \n",
       "25000  1.22  0.01  102.21  458  \n",
       "30000  1.32  0.01  102.03  448  \n",
       "35000  1.39  0.01  101.70  438  \n",
       "40000  1.46  0.01  101.86  441  \n",
       "45000  1.52  0.01  101.63  432  \n",
       "50000  1.58  0.01  101.63  432  \n",
       "55000  1.61  0.01  101.57  427  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sleeve & ; inside protection inch pocket perfectly pro power\n",
      "1 nice bought price quality thing made 'm recommend works perfect\n",
      "2 $ item ... price amazon quality received buy time return\n",
      "3 months zipper years handle strap 've year back bought quality\n",
      "4 bought quality made put price nice wanted time size perfect\n",
      "5 ! love perfect recommend color ... perfectly buy highly awesome\n",
      "6 nice put bought lot made bit 've recommend ; !\n",
      "7 'm price bought & work ; perfect quality 've made\n",
      "8 carry pockets room pocket strap space small plenty hold shoulder\n",
      "9 cover color bottom keyboard mac pro hard top nice apple\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topics_freq_tokens = [[idx_to_word[idx] for idx in topic_freq_idxs] for topic_freq_idxs in topics_freq_idxs]\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)\n",
    "\n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.tree_idxs, update_tree_flg = model.update_tree(topic_prob_topic, recur_prob_topic)\n",
    "                if update_tree_flg:\n",
    "                    print(config.tree_idxs)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = Model(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "display(log_df)\n",
    "print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
