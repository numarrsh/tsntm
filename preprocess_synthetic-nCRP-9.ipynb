{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "\n",
    "import re\n",
    "import pdb\n",
    "import _pickle as cPickle\n",
    "from collections import OrderedDict, defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from data_structure import Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('output_path', 'data/synthetic/instances_ncrp_9.pkl', 'path of output data')\n",
    "\n",
    "flags.DEFINE_integer('n_vocab', 9, 'size of vocab')\n",
    "flags.DEFINE_integer('n_doc', 11000, 'num of doc')\n",
    "flags.DEFINE_integer('doc_l', 100, 'size of vocab')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "config = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth(parent_idx=0, tree_depth = None, depth=1):\n",
    "        if tree_depth is None: tree_depth={0: depth}\n",
    "\n",
    "        child_idxs = tree_idxs[parent_idx]\n",
    "        depth +=1\n",
    "        for child_idx in child_idxs:\n",
    "            tree_depth[child_idx] = depth\n",
    "            if child_idx in tree_idxs: get_depth(child_idx, tree_depth, depth)\n",
    "        return tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_idxs = {0:[1, 2, 3], \n",
    "                      1:[10, 11, 12], 2:[20, 21, 22], 3:[30, 31, 32]}\n",
    "tree_depth = get_depth()\n",
    "max_depth = max(get_depth().values())\n",
    "child_to_parent_idxs = {child_idx: parent_idx for parent_idx, child_idxs in tree_idxs.items() for child_idx in child_idxs}\n",
    "\n",
    "topic_idxs = [0] + [idx for child_idxs in tree_idxs.values() for idx in child_idxs]\n",
    "\n",
    "bow_idxs = np.arange(config.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(config.n_vocab//3)\n",
    "zeros = np.zeros(config.n_vocab//3)\n",
    "leaf_1 = np.concatenate([np.ones([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))]), np.zeros([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))]), np.zeros([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))])], 1).flatten()\n",
    "leaf_2 = np.concatenate([np.zeros([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))]), np.ones([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))]), np.zeros([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))])], 1).flatten()\n",
    "leaf_3 = np.concatenate([np.zeros([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))]), np.zeros([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))]), np.ones([int((config.n_vocab//9)**(1/2)), int((config.n_vocab//9)**(1/2))])], 1).flatten()\n",
    "# leaf_1 = np.concatenate([np.ones(config.n_vocab//9), np.zeros(config.n_vocab//9), np.zeros(config.n_vocab//9)])\n",
    "# leaf_2 = np.concatenate([np.zeros(config.n_vocab//9), np.ones(config.n_vocab//9), np.zeros(config.n_vocab//9)])\n",
    "# leaf_3 = np.concatenate([np.zeros(config.n_vocab//9), np.zeros(config.n_vocab//9), np.ones(config.n_vocab//9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_topic_bow_raw = {\n",
    "                0: np.ones(config.n_vocab, dtype=np.float32),\n",
    "                1: np.concatenate([ones, zeros, zeros]).astype(np.float32),\n",
    "                2: np.concatenate([zeros, ones, zeros]).astype(np.float32),\n",
    "                3: np.concatenate([zeros, zeros, ones]).astype(np.float32),\n",
    "                10: np.concatenate([leaf_1, zeros, zeros]).astype(np.float32),\n",
    "                11: np.concatenate([leaf_2, zeros, zeros]).astype(np.float32),\n",
    "                12: np.concatenate([leaf_3, zeros, zeros]).astype(np.float32),\n",
    "                20: np.concatenate([zeros, leaf_1, zeros]).astype(np.float32),\n",
    "                21: np.concatenate([zeros, leaf_2, zeros]).astype(np.float32),\n",
    "                22: np.concatenate([zeros, leaf_3, zeros]).astype(np.float32),\n",
    "                30: np.concatenate([zeros, zeros, leaf_1]).astype(np.float32),\n",
    "                31: np.concatenate([zeros, zeros, leaf_2]).astype(np.float32),\n",
    "                32: np.concatenate([zeros, zeros, leaf_3]).astype(np.float32),\n",
    "}\n",
    "\n",
    "tree_topic_bow = {topic_idx: topic_bow_raw/np.sum(topic_bow_raw) for topic_idx, topic_bow_raw in tree_topic_bow_raw.items()}\n",
    "topic_bow = np.concatenate([tree_topic_bow[topic_idx][None, :] for topic_idx in topic_idxs], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAD8CAYAAADdcYAbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAA8tJREFUeJzt3TFu40YYgFEyu12aIJUB9T5PrpEr2A0b+Qq5Rs6zvQBXQZqUAVOncL5QlnbG8Hu1TXIG+PADwkhc931fgLf9MPoBYHYigSASCCKBIBIIIoEgEggigSASCF9HP8Bn8Odfv0x5rOGnH39fRz/DR2CSQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCQSRQFj3fcoXw8I0TBIIIoEgEggigSASCCKB8HXYnb/9POdnz49/rLe+5GV5nnKtp+Vsrf+DSQJBJBBEAkEkEEQCQSQQRAJBJBBEAkEkEEQCQSQQhh1wvDz+OurW/+l0j2t+++0OV72Bx/PoJ/gQTBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCON+nO4TcU5tAu84p2aSQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCYR136d8WSpMwySBIBIIIoEgEggigSASCMO+4/73th7+7Pl1e7rHo/zLaTmvt77mZXk+vNaH7eXQ31+zN7Os9aije7Msy/Jl269eq0kCQSQQRAJBJBBEAkEkEEQCQSQQRAJBJBBEAkEkEIYdcPwehxU/MvvztusOc17PJIEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBII677f/WWp8KGZJBBEAkEkEEQCQSQQRAJh2PtJLsvzlJ89n5bzeutrWut471mrSQJBJBBEAkEkEEQCQSQQRAJBJBBEAkEkEEQCQSQQhh1wfNheDv/P6/Z0hyeZ09H9sTdhO199P5MEgkggiASCSCCIBIJIIIgEgkggiASCSCCIBMKws1uf6azRNezP267Zm9M77meSQBAJBJFAEAkEkUAQCQSRQBAJBJFAEAkEkUAQCYR136d8WSpMwySBIBIIIoEgEggigSASCMO+435Znqf87Pm0nNdbX9Nax3vPWk0SCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigTDsx+ketpfD//O6Pd3hSeZ0dH/sTdjOV9/PJIEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBII675P+bJUmIZJAkEkEEQCQSQQRAJBJBBEAkEkEEQCQSQQRAJBJBBEAkEkEEQCQSQQRAJBJBBEAkEkEEQCQSQQRALhH6S7Zkvc/y2FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x288 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import Normalize # Normalizeã‚’import\n",
    "\n",
    "plt.figure(figsize=(3, 4))\n",
    "plt.subplot(5,3,2)\n",
    "plt.axis('off')\n",
    "plt.imshow(topic_bow[0].reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))), cmap='Wistia', norm=Normalize(vmin=0., vmax=np.max(topic_bow)))\n",
    "\n",
    "for i in range(1, len(topic_idxs)):\n",
    "    plt.subplot(5,3,i+3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(topic_bow[i].reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))), cmap='Wistia', norm=Normalize(vmin=0., vmax=np.max(topic_bow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCRP(tree_sticks_topic):\n",
    "    tree_prob_topic = {}\n",
    "    tree_prob_leaf = {}\n",
    "    # calculate topic probability and save\n",
    "    tree_prob_topic[0] = 1.\n",
    "    \n",
    "    for parent_idx, child_idxs in tree_idxs.items():\n",
    "        rest_prob_topic = tree_prob_topic[parent_idx]        \n",
    "        for child_idx in child_idxs:\n",
    "            stick_topic = tree_sticks_topic[child_idx]\n",
    "            if child_idx == child_idxs[-1]:\n",
    "                prob_topic = rest_prob_topic * 1.\n",
    "            else:\n",
    "                prob_topic = rest_prob_topic * stick_topic\n",
    "            \n",
    "            if not child_idx in tree_idxs: # leaf childs\n",
    "                tree_prob_leaf[child_idx] = prob_topic\n",
    "            else:\n",
    "                tree_prob_topic[child_idx] = prob_topic\n",
    "                \n",
    "            rest_prob_topic -= prob_topic\n",
    "            \n",
    "    return tree_prob_leaf\n",
    "\n",
    "def get_ancestor_idxs(leaf_idx, ancestor_idxs = None):\n",
    "    if ancestor_idxs is None: ancestor_idxs = [leaf_idx]\n",
    "    \n",
    "    parent_idx = child_to_parent_idxs[leaf_idx]\n",
    "    ancestor_idxs += [parent_idx]\n",
    "    if parent_idx in child_to_parent_idxs: get_ancestor_idxs(parent_idx, ancestor_idxs)\n",
    "    return ancestor_idxs[::-1]\n",
    "\n",
    "def get_prob_topic(tree_prob_leaf, prob_depth):\n",
    "    tree_prob_topic = defaultdict(float)\n",
    "    \n",
    "    leaf_ancestor_idxs = {leaf_idx: get_ancestor_idxs(leaf_idx) for leaf_idx in tree_prob_leaf}\n",
    "    for leaf_idx, ancestor_idxs in leaf_ancestor_idxs.items():\n",
    "        prob_leaf = tree_prob_leaf[leaf_idx]\n",
    "        for i, ancestor_idx in enumerate(ancestor_idxs):\n",
    "            prob_ancestor = prob_leaf * prob_depth[i]\n",
    "            tree_prob_topic[ancestor_idx] += prob_ancestor\n",
    "    return tree_prob_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp = 2.\n",
    "lam = 1.\n",
    "gam = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "\n",
    "for idx_doc in range(config.n_doc):\n",
    "    if idx_doc%1000 == 0: print(idx_doc)\n",
    "    instance = Instance()\n",
    "    instance.idx = idx_doc\n",
    "    \n",
    "    tree_sticks_topic = {}\n",
    "    for topic_idx in topic_idxs:\n",
    "        depth = tree_depth[topic_idx]\n",
    "        tree_sticks_topic[topic_idx] = np.random.beta(1, alp*(lam**depth), 1)\n",
    "        \n",
    "    tree_prob_leaf = nCRP(tree_sticks_topic)\n",
    "    prob_depth = np.random.dirichlet(np.ones(max_depth, dtype=np.float32) * gam)\n",
    "    \n",
    "    tree_prob_topic = get_prob_topic(tree_prob_leaf, prob_depth)            \n",
    "    prob_topic = np.concatenate([tree_prob_topic[topic_idx] for topic_idx in topic_idxs])\n",
    "    \n",
    "    prob_bow = prob_topic.dot(topic_bow)\n",
    "    prob_bow /= np.sum(prob_bow)\n",
    "    \n",
    "    token_idxs = np.random.choice(config.n_vocab, config.doc_l, p=prob_bow)\n",
    "    bow = np.array([Counter(token_idxs)[bow_idx] for bow_idx in bow_idxs])\n",
    "    assert len(bow) == config.n_vocab\n",
    "    instance.bow = bow\n",
    "    \n",
    "    instances.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "prob_topics = []\n",
    "for idx_doc in range(config.n_doc):\n",
    "    if idx_doc%1000 == 0: print(idx_doc)\n",
    "    instance = Instance()\n",
    "    instance.idx = idx_doc\n",
    "    \n",
    "    tree_sticks_topic = {}\n",
    "    for topic_idx in topic_idxs:\n",
    "        depth = tree_depth[topic_idx]\n",
    "        tree_sticks_topic[topic_idx] = np.random.beta(1, alp*(lam**depth), 1)\n",
    "        \n",
    "    tree_prob_leaf = nCRP(tree_sticks_topic)\n",
    "    prob_depth = np.random.dirichlet(np.ones(max_depth, dtype=np.float32) * gam)\n",
    "    \n",
    "    tree_prob_topic = get_prob_topic(tree_prob_leaf, prob_depth)            \n",
    "    prob_topic = np.concatenate([tree_prob_topic[topic_idx] for topic_idx in topic_idxs])\n",
    "    \n",
    "    prob_topics.append(prob_topic)\n",
    "    \n",
    "prob_topic_mean = np.mean(prob_topics, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33311362, 0.10945191, 0.07472765, 0.14670732, 0.03655314,\n",
       "       0.02509408, 0.0501135 , 0.02461713, 0.01735043, 0.03350143,\n",
       "       0.04964403, 0.03323033, 0.06589544])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_topic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14876979235625004"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prob_topic_mean[10:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAAIrCAYAAACAkVrFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGUtJREFUeJzt2V+s1wX9x/H39zdaGyIzKtFmCieQElMWjAPFipaeBeaiC9xicKEtKBtnYeDszwbcsDZcudhscFFuQm2Hi2DiGIQNx5biJjI4I4g4khEFEzH+RK6Lz++GXCwv6PM9b980H49rPi8/vuHL4blvp2maAAAA4N33f9UvAAAA8F4lyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoMiJpt0najYiI/v7+tO05c+akbV/e77R5rtPppN505cqVadt/+MMf0rYjIjZu3NjqpitWrEi96dq1a9O2H3/88bTtiIjly5dfk39OR48enbZ97ty5tO2IiKZpWt10165dqTe955570rY3b96cth0RMX/+/FY3feqpp1Jvevz48bTt3bt3p21f3m910xdffDH1pjNmzMicz9bqphcuXEi96ahRo9K233jjjbTtiIgxY8a0umlExIkTJ1LvOnLkyLTtM2fOpG1HREycOLHVXfv7+1NvunHjxrTts2fPpm1HXP3Pft+QAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQJER1S/Qxpw5c9K2e3t707a7cfTo0epXaG3ChAnVr/COvvKVr1S/Qmtjx46tfoV39Kc//Sl1/9y5c2nbd9xxR9p2NzZs2JC6v2vXrrTtqVOnpm1344knnkjdHzduXNr2888/n7bdjdGjR6fub968OW178uTJadsR7f9uOXPmzDC/ybtncHAwdf+zn/1s62dvueWWYXyT/3Tp0qW07YkTJ6Ztd2P79u2p+5n/39fKv/t9QwYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAU6TRNM+yjCxcuHP7Rf9Pb25u23d/fn7YdEdE0TafNc9u3b0+96dy5c9O2J0yYkLYdEXH06NFWN7148WLqTX/729+mbff19aVtR7T/c3ro0KHUm+7YsSNte+bMmWnbEREzZsxoddPNmzen3vSBBx5I2/7Upz6Vth0R8fLLL7e6aUSk3nTLli1p21OmTEnbjogYN25cq5t2Op3Um65cuTJt+9ChQ2nbEREDAwPX5E337duXtv3ss8+mbUdE/OAHP2j72U+/68SJE9O2R44cmbYdEbF///5Wd33ppZdSbzp9+vS07e3bt6dtR0TMmTPnqm7qGzIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAo0mmapvodAAAA3pN8QwYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQJERGaOdTqfJ2P2Xn//852nbn/70p9O2IyJuv/32Tpvn9u/fn3rTV155JW37oYceStuOiGiaptVNh4aGUm/a09OTtj00NJS2HRHR09PT6qbZn/2FCxembX/iE59I246I+N73vndN3vS+++5L2541a1badkTEY4891uqmEZF6040bN6Ztnz17Nm07ImLp0qWtbnrvvfem3nTXrl1p2/Pnz0/bjogYGBhoddNVq1al3nTVqlVp208++WTadkTEww8/3PazHxcvXky9a6ZTp06l7rf92f/iiy+m3nTGjBlp25mfg8v7V3VT35ABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAkREZo03TZMy+7cyZM6n716IpU6ak7h89ejRte2BgIG27G1OnTk3df/PNN9O2x48fn7YdETE0NNTquezP/muvvZa2PXLkyLTtbmzatCl1/7777kvbfvbZZ9O2u9Hf35+6v3fv3rTtpUuXpm13Y/369an7PT09adsbNmxI2+7G6tWrU/dPnz6dtn3o0KG07YiIhx9+uPWz11133TC+yX86depU6v61aPTo0dWv0NoXv/jF6leICN+QAQAAlBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEVGZIxu27YtY/Zt48aNS9seNWpU2nZExAc/+MFWz23fvn2Y3+RKN998c9r2+fPn07a7MW3atNT9np6e/8ntbhw+fDh1/+Mf/3ja9uuvv5623Y1f/OIXqfsLFixI2541a1badjfWrVuXuv/000+nbc+dOzdtuxtDQ0Op+0uWLEnbXrx4cdp2N1auXJm6P3v27LTtgYGBtO1udTqd1P2ZM2emba9evTptO6L9vy127NgxzG9ypTvuuCNtO/P3KyKiaZqr+nW+IQMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAinaZpqt8BAADgPck3ZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARUZkjB47dqzJ2P2XMWPGpG0fO3YsbTsiYtq0aZ02z/34xz9OvemPfvSj/8ntiIj58+e3uulNN92UetOxY8embS9atChtOyJi+fLlrW66atWq1JveeOONadvf+ta30rYjIpqmaXXTL3zhC6k3/c1vfpO2/d3vfjdtOyJizZo1rW7a6XRSb/rCCy+kbWf/fTowMNDqpkuWLEm96fr169O2N2zYkLYdEbF48eJWN/3Zz36WetPPfOYzaduPPvpo2nZExNatW1vdNCL/879nz5607ey/U/fs2dPqrnv37k296dDQUNr2Jz/5ybTtiIg777zzqm7qGzIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoMiJjdOvWrRmzb3vkkUfStg8ePJi2HRExbdq0Vs8tW7ZsmN/kSrfcckva9okTJ9K2u/HXv/41df/AgQNp24sWLUrbjohYvnx5q+dOnz49zG9ypcmTJ6dtN02Ttt2NpUuXpu4/99xzadtbtmxJ2+5G9u/1zJkzU/evRYsXL07d/8tf/pK2vX79+rTtiPzbtDVp0qS07S9/+ctp29168803U/ffeuuttO0nn3wybbsbd955Z+p+b29v2vbg4GDa9n/DN2QAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAkREZozt27MiYfVtfX1/a9kMPPZS2HRHx4IMPtnou+6aZHnnkkdT9ZcuWtXqu0+kM85u8exYtWlT9Cu/oxhtvTN2fPHly2vbmzZvTtiMi5s+f3+q5efPmDfObvHuu1XfP/r3+6Ec/mrp/LZo6dWrq/pIlS9K29+3bl7bdjddffz11/8yZM2nbX/va19K2I7r7t9rBgweH8U3+06xZs9K2//GPf6Rtd+PVV19N3V+zZk3a9i9/+cu07YiIpmmu6tf5hgwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKdJqmqX4HAACA9yTfkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUGRExuiRI0eajN1/+dCHPpS2/bvf/S5tOyJi1qxZnTbPPfDAA6k37evrS9v++te/nrYdEdE0TaubHjhwIPWmd911V9r2qVOn0rYjIsaOHdvqphGRetMLFy6kbZ88eTJtOyLi9ttvb3XT1157LfWmt956a+Z8tlY33bJlS+pNt2zZkrZ9/PjxtO2IiN27d1+Tn/0jR45kzqeaNGlSq5s+8cQTqTfN9O1vfzv7P9H2z2n09fWl3nXnzp1p2wcOHEjbjoi46667rsnP/8WLF9O2BwcH07YjInp7e6/qpr4hAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCIjMkYnTZqUMfu2M2fOpG1Pnz49bbsba9euTd2/7bbb/ie3uzFq1KjU/V/96ldp2z/96U/TtiMidu7c2eq566+/fpjf5Erf+c530rZXr16dth0R0TRNq+cee+yxYX6TK2V+Pn/4wx+mbUe0v+m8efOG+U3ePfv3769+hXd05MiR1P1bb701df9adMMNN6Tuz549O2179+7dadsRue/erccffzxte/ny5Wnb3VizZk3q/le/+tW07dOnT6dt/zd8QwYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUGZEx2ul0MmbftnXr1rTtw4cPp21HRDz66KOtnvvjH/84zG9ypb/97W9p27fddlvadjd27tyZuv/Nb34zbXv8+PFp2914+eWXU/cnTZqUtv3MM8+kbXfjhhtuSN1fsGBB2vbBgwfTtrsxbty41P3Mv68/97nPpW134+9//3vq/siRI9O277nnnrTtiIhf//rXrZ578MEHh/lNrvTKK6+kbT/11FNp2xERs2fPbv3sgQMHhu9F3kHb3++rsWLFirTtiIimaVo99/3vf3+Y3+RKp0+fTtt+7rnn0rYjIu6///6r+nW+IQMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAinaZpqt8BAADgPck3ZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARUYk7TZJuxERcf78+bTtuXPnpm1HROzZs6fT5rne3t7Um27atClte8yYMWnbl/db3XRoaCj1pkNDQ2nbZ8+eTduOiJg/f36rmy5YsCD1pi+88ELa9vHjx9O2IyKapml10z//+c+pN/3whz+ctv3888+nbUdE3Hvvva1ueunSpdSb/v73v0/bvvvuu9O2L2t103nz5qXedOvWrWnbN998c9p2RMTJkydb3TSS/y21bt26tO3e3t607YiI6dOnt71pPP3006l3vemmm9K2+/r60rYj2v+cOnXqVOpNR40albb90ksvpW1HRHz+85+/qpv6hgwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKdJqmGfbRw4cPD//ov3n/+9+ftn3u3Lm07YiIu+++u9PmuVWrVqXe9Cc/+Una9qZNm9K2IyLmzJnT6qZDQ0OpN+3p6UnbHhoaStuOiOjp6Wl1071796be9LrrrkvbvnjxYtp2RERvb2+rm+7fvz/1plOmTEnbPn/+fNp2RMT111/f6qYRkXrTEydOpG1v27YtbTsi4hvf+Earm548eTL1ppcuXUrb/tjHPpa2fVmrm/b396fedOHChWnbmf+miIjYuHFj289+9PX1pd51xYoVads7d+5M246IWLt2bau7nj17NvWmH/jAB9K2//nPf6ZtR0S8733vu6qb+oYMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKNJpmmbYRw8fPjz8o//mrbfeStueMmVK2nZERNM0nTbPdTqd1Jvu3bs3bXv69Olp25e1uunUqVNTb7pv37607fHjx6dtR0QMDQ21uumrr76aetPBwcG07fvvvz9t+7Jr8rN/7NixtO1t27albUdE9Pf3t7rptm3bUm/6pS99KW2702n1v3zV2v6MGhwcTL3phAkT0rbfeOONtO2IiI985COtbjpmzJjUmy5cuDBte926dWnbEe3/nEZEnDp1KvWumcaOHZv9n7gmf05t2LAhbfvChQtp2xERy5Ytu6qb+oYMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAiggyAACAIoIMAACgiCADAAAoIsgAAACKCDIAAIAiggwAAKCIIAMAACgiyAAAAIoIMgAAgCKCDAAAoIggAwAAKCLIAAAAinSapql+BwAAgPck35ABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAEUEGAABQRJABAAAUEWQAAABFBBkAAEARQQYAAFBEkAEAABQRZAAAAEUEGQAAQBFBBgAAUESQAQAAFBFkAAAARQQZAABAkf8HzxSBGyme6FsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, instance in enumerate(instances[:50]):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(instance.bow.reshape(int(config.n_vocab**(1/2)),int(config.n_vocab**(1/2))), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train = instances[:10000]\n",
    "instances_valid = instances[10000:]\n",
    "instances_test = instances_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word = {bow_idx: str(10*(bow_idx//3+1) + bow_idx%3) for bow_idx in bow_idxs}\n",
    "word_to_idx = {word: idx for idx, word in idx_to_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessed instances...\n"
     ]
    }
   ],
   "source": [
    "print('saving preprocessed instances...')\n",
    "cPickle.dump((instances_train, instances_valid, instances_test, word_to_idx, idx_to_word, bow_idxs),open(config.output_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
