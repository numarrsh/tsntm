{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib nbagg\n",
    "\n",
    "from six.moves import zip_longest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import distributions as tfd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from data_structure import get_batches, get_test_batches\n",
    "from components import tf_log, sample_latents, compute_kl_loss, dynamic_rnn, dynamic_bi_rnn\n",
    "\n",
    "from topic_beam_search_decoder import BeamSearchDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('gpu', '2', 'visible gpu')\n",
    "\n",
    "flags.DEFINE_string('mode', 'train', 'set train or eval')\n",
    "\n",
    "flags.DEFINE_string('data_path', 'data/bags/instances.pkl', 'path of data')\n",
    "flags.DEFINE_string('modeldir', 'model/topic_vae', 'directory of model')\n",
    "flags.DEFINE_string('modelname', 'bags', 'name of model')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 1000, 'epochs')\n",
    "flags.DEFINE_integer('batch_size', 64, 'number of sentences in each batch')\n",
    "flags.DEFINE_integer('log_period', 3000, 'valid period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "# flags.DEFINE_string('opt', 'Adam', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.01, 'lr')\n",
    "flags.DEFINE_float('reg', 1., 'regularization term')\n",
    "flags.DEFINE_float('grad_clip', 5., 'grad_clip')\n",
    "\n",
    "flags.DEFINE_float('keep_prob', 0.8, 'dropout rate')\n",
    "flags.DEFINE_float('word_keep_prob', 0.75, 'word dropout rate')\n",
    "\n",
    "flags.DEFINE_bool('warmup', True, 'flg of warming up')\n",
    "flags.DEFINE_integer('epochs_cycle', 5, 'number of epochs within a cycle')\n",
    "flags.DEFINE_float('r_cycle', 0.5, 'proportion used to increase beta within a cycle')\n",
    "flags.DEFINE_integer('warmup_topic', 0, 'warmup period for KL of topic')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 2, 'beam_width')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('n_topic', 20, 'number of topic')\n",
    "flags.DEFINE_integer('dim_hidden_bow', 256, 'dim of hidden bow')\n",
    "flags.DEFINE_integer('dim_latent_bow', 32, 'dim of latent topic')\n",
    "flags.DEFINE_integer('dim_emb', 256, 'dim_emb')\n",
    "flags.DEFINE_integer('dim_hidden', 512, 'dim_hidden')\n",
    "flags.DEFINE_integer('dim_hidden_topic', 512, 'dim_hidden_topic')\n",
    "flags.DEFINE_integer('dim_latent', 32, 'dim_latent')\n",
    "flags.DEFINE_bool('bidirectional', True, 'flg of bidirectional encoding')\n",
    "\n",
    "# for evaluation\n",
    "flags.DEFINE_string('refdir', 'ref', 'refdir')\n",
    "flags.DEFINE_string('outdir', 'out', 'outdir')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_bool('logtostderr', True, 'kernel')\n",
    "flags.DEFINE_bool('showprefixforinfo', False, '')\n",
    "flags.DEFINE_bool('verbosity', False, '')\n",
    "# flags.DEFINE_integer('stderrthreshold', 20, 'kernel')\n",
    "\n",
    "config = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('modelpath', os.path.join(config.modeldir, config.modelname), 'path of model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.data_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_batches(instances, batch_size, iterator=False):\n",
    "    iter_instances = iter(instances)\n",
    "    n_batch = len(instances)//batch_size\n",
    "    \n",
    "    batches = [(i_batch, [next(iter_instances) for i_doc in range(batch_size)]) for i_batch in range(n_batch)]\n",
    "    \n",
    "    if iterator: batches = iter(batches)\n",
    "    return batches\n",
    "\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_integer('n_vocab', len(word_to_idx), 'n_vocab')\n",
    "flags.DEFINE_integer('dim_bow', len(bow_idxs), 'dim_bow')\n",
    "\n",
    "flags.DEFINE_integer('cycle_steps', len(train_batches)*config.epochs_cycle, 'number of steps for each cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     10,
     24,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = dev_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    if return_value: \n",
    "        return _variables\n",
    "    else:\n",
    "        for _variable, variable in zip(_variables, variables):\n",
    "            if hasattr(variable, 'name'):\n",
    "                print(variable.name, ':', _variable)\n",
    "            else:\n",
    "                print(_variable)\n",
    "                \n",
    "def check_shape(variables):\n",
    "    if 'sess' in globals(): raise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "def check_value(variables):\n",
    "    if 'sess' in globals(): raise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    sess.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doubly rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublyRNNCell:\n",
    "    def __init__(self, dim_hidden, output_layer=None):\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.ancestral_layer=tf.layers.Dense(units=dim_hidden, activation=tf.nn.tanh, name='ancestral')\n",
    "        self.fraternal_layer=tf.layers.Dense(units=dim_hidden, activation=tf.nn.tanh, name='fraternal')\n",
    "        self.hidden_layer = tf.layers.Dense(units=dim_hidden, name='hidden')\n",
    "        \n",
    "        self.output_layer=output_layer\n",
    "        \n",
    "    def __call__(self, state_ancestral, state_fraternal, reuse=True):\n",
    "        with tf.variable_scope('input', reuse=reuse):\n",
    "            state_ancestral = self.ancestral_layer(state_ancestral)\n",
    "            state_fraternal = self.fraternal_layer(state_fraternal)\n",
    "\n",
    "        with tf.variable_scope('output', reuse=reuse):\n",
    "            state_hidden = self.hidden_layer(state_ancestral + state_fraternal)\n",
    "            if self.output_layer is not None: \n",
    "                output = self.output_layer(state_hidden)\n",
    "            else:\n",
    "                output = state_hidden\n",
    "            \n",
    "        return output, state_hidden\n",
    "    \n",
    "    def get_initial_state(self, name):\n",
    "        initial_state = tf.get_variable(name, [1, self.dim_hidden], dtype=tf.float32)\n",
    "        return initial_state\n",
    "    \n",
    "    def get_zero_state(self, name):\n",
    "        zero_state = tf.zeros([1, self.dim_hidden], dtype=tf.float32, name=name)\n",
    "        return zero_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_rnn(dim_hidden, tree_idxs, initial_state_parent=None, initial_state_sibling=None, output_layer=None, name=''):\n",
    "    outputs, states_parent = {}, {}\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=False):\n",
    "        doubly_rnn_cell = DoublyRNNCell(dim_hidden, output_layer)\n",
    "\n",
    "        if initial_state_parent is None: \n",
    "            initial_state_parent = doubly_rnn_cell.get_initial_state('init_state_parent')\n",
    "#             initial_state_parent = doubly_rnn_cell.get_zero_state('init_state_parent')\n",
    "        if initial_state_sibling is None: \n",
    "#             initial_state_sibling = doubly_rnn_cell.get_initial_state('init_state_sibling')\n",
    "            initial_state_sibling = doubly_rnn_cell.get_zero_state('init_state_sibling')\n",
    "        output, state_sibling = doubly_rnn_cell(initial_state_parent, initial_state_sibling, reuse=False)\n",
    "        outputs[0], states_parent[0] = output, state_sibling\n",
    "\n",
    "        for parent_idx, child_idxs in tree_idxs.items():\n",
    "            state_parent = states_parent[parent_idx]\n",
    "            state_sibling = initial_state_sibling\n",
    "            for child_idx in child_idxs:\n",
    "                output, state_sibling = doubly_rnn_cell(state_parent, state_sibling)\n",
    "                outputs[child_idx], states_parent[child_idx] = output, state_sibling\n",
    "\n",
    "    return outputs, states_parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nCRP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": [
     2,
     25
    ]
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, config, tree_idxs):\n",
    "        def get_depth(parent_idx=0, tree_depth=None, depth=1):\n",
    "            if tree_depth is None: tree_depth={0: depth}\n",
    "\n",
    "            child_idxs = tree_idxs[parent_idx]\n",
    "            depth +=1\n",
    "            for child_idx in child_idxs:\n",
    "                tree_depth[child_idx] = depth\n",
    "                if child_idx in tree_idxs: get_depth(child_idx, tree_depth, depth)\n",
    "            return tree_depth\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.t_variables = {}\n",
    "        \n",
    "        self.tree_idxs = tree_idxs\n",
    "        self.topic_idxs = [0] + [idx for child_idxs in tree_idxs.values() for idx in child_idxs]\n",
    "        self.child_to_parent_idxs = {child_idx: parent_idx for parent_idx, child_idxs in self.tree_idxs.items() for child_idx in child_idxs}\n",
    "        self.tree_depth = get_depth()\n",
    "        self.n_depth = max(self.tree_depth.values())\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        def nCRP(tree_sticks_topic):\n",
    "            tree_prob_topic = {}\n",
    "            tree_prob_leaf = {}\n",
    "            # calculate topic probability and save\n",
    "            tree_prob_topic[0] = 1.\n",
    "\n",
    "            for parent_idx, child_idxs in self.tree_idxs.items():\n",
    "                rest_prob_topic = tree_prob_topic[parent_idx]\n",
    "                for child_idx in child_idxs:\n",
    "                    stick_topic = tree_sticks_topic[child_idx]\n",
    "                    if child_idx == child_idxs[-1]:\n",
    "                        prob_topic = rest_prob_topic * 1.\n",
    "                    else:\n",
    "                        prob_topic = rest_prob_topic * stick_topic\n",
    "\n",
    "                    if not child_idx in self.tree_idxs: # leaf childs\n",
    "                        tree_prob_leaf[child_idx] = prob_topic\n",
    "                    else:\n",
    "                        tree_prob_topic[child_idx] = prob_topic\n",
    "\n",
    "                    rest_prob_topic -= prob_topic\n",
    "            return tree_prob_leaf\n",
    "\n",
    "        def get_prob_topic(tree_prob_leaf, prob_depth):\n",
    "            def get_ancestor_idxs(leaf_idx, ancestor_idxs = None):\n",
    "                if ancestor_idxs is None: ancestor_idxs = [leaf_idx]\n",
    "                parent_idx = self.child_to_parent_idxs[leaf_idx]\n",
    "                ancestor_idxs += [parent_idx]\n",
    "                if parent_idx in self.child_to_parent_idxs: get_ancestor_idxs(parent_idx, ancestor_idxs)\n",
    "                return ancestor_idxs[::-1]\n",
    "            \n",
    "            tree_prob_topic = defaultdict(float)\n",
    "            leaf_ancestor_idxs = {leaf_idx: get_ancestor_idxs(leaf_idx) for leaf_idx in tree_prob_leaf}\n",
    "            for leaf_idx, ancestor_idxs in leaf_ancestor_idxs.items():\n",
    "                prob_leaf = tree_prob_leaf[leaf_idx]\n",
    "                for i, ancestor_idx in enumerate(ancestor_idxs):\n",
    "                    prob_ancestor = prob_leaf * tf.expand_dims(prob_depth[:, i], -1)\n",
    "                    tree_prob_topic[ancestor_idx] += prob_ancestor\n",
    "            prob_topic = tf.concat([tree_prob_topic[topic_idx] for topic_idx in self.topic_idxs], -1)\n",
    "            return prob_topic\n",
    "        \n",
    "        def get_tree_topic_bow(tree_topic_embeddings):\n",
    "            def softmax_with_temperature(logits, axis=None, name=None, temperature=1.):\n",
    "                if axis is None:\n",
    "                    axis = -1\n",
    "                return tf.exp(logits / temperature) / tf.reduce_sum(tf.exp(logits / temperature), axis=axis)\n",
    "\n",
    "            tree_topic_bow = {}\n",
    "            for topic_idx, depth in self.tree_depth.items():\n",
    "                topic_embedding = tree_topic_embeddings[topic_idx]\n",
    "                temperature = tf.constant(10 ** (1./depth), dtype=tf.float32)\n",
    "                logits = tf.matmul(topic_embedding, self.bow_embeddings, transpose_b=True)\n",
    "                tree_topic_bow[topic_idx] = softmax_with_temperature(logits, axis=-1, temperature=temperature)\n",
    "            return tree_topic_bow\n",
    "\n",
    "        def get_tree_mask_reg():\n",
    "            def get_descendant_idxs(parent_idx, descendant_idxs = None):\n",
    "                if descendant_idxs is None: descendant_idxs = []\n",
    "\n",
    "                child_idxs = self.tree_idxs[parent_idx]\n",
    "                descendant_idxs += child_idxs\n",
    "                for child_idx in child_idxs:\n",
    "                    if child_idx in self.tree_idxs: get_descendant_idxs(child_idx, descendant_idxs)\n",
    "                return descendant_idxs\n",
    "\n",
    "            tree_mask_reg = np.ones([len(self.topic_idxs), len(self.topic_idxs)], dtype=np.float32)\n",
    "            parent_to_descendant_idxs = {parent_idx: get_descendant_idxs(parent_idx) for parent_idx in self.tree_idxs}\n",
    "\n",
    "            for parent_idx, descendant_idxs in parent_to_descendant_idxs.items():\n",
    "                for descendant_idx in descendant_idxs:\n",
    "                    parent_index = self.topic_idxs.index(parent_idx)\n",
    "                    descendant_index = self.topic_idxs.index(descendant_idx)\n",
    "                    tree_mask_reg[parent_index, descendant_index] = tree_mask_reg[descendant_index, parent_index] = 0.\n",
    "            return tree_mask_reg\n",
    "       \n",
    "        # -------------- Build Model --------------\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.t_variables['bow'] = tf.placeholder(tf.float32, [None, self.config.dim_bow])\n",
    "        self.t_variables['keep_prob'] = tf.placeholder(tf.float32)\n",
    "        \n",
    "        # encode bow\n",
    "        with tf.variable_scope('topic/enc', reuse=False):\n",
    "            hidden_bow_ = tf.layers.Dense(units=self.config.dim_hidden_bow, activation=tf.nn.tanh, name='hidden_bow')(self.t_variables['bow'])\n",
    "            hidden_bow = tf.layers.Dropout(self.t_variables['keep_prob'])(hidden_bow_)\n",
    "            means_bow = tf.layers.Dense(units=self.config.dim_latent_bow, name='mean_bow')(hidden_bow)\n",
    "            logvars_bow = tf.layers.Dense(units=self.config.dim_latent_bow, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0), name='logvar_bow')(hidden_bow)\n",
    "            latents_bow = sample_latents(means_bow, logvars_bow) # sample latent vectors\n",
    "            prob_layer = lambda h: tf.nn.sigmoid(tf.matmul(latents_bow, h, transpose_b=True))\n",
    "\n",
    "            tree_sticks_topic, tree_states_sticks_topic = doubly_rnn(self.config.dim_latent_bow, self.tree_idxs, output_layer=prob_layer, name='sticks_topic')\n",
    "            tree_prob_leaf = nCRP(tree_sticks_topic)\n",
    "            self.tree_prob_leaf = tree_prob_leaf\n",
    "            prob_depth = tf.layers.Dense(units=self.n_depth, activation=tf.nn.softmax, name='prob_depth')(latents_bow) # inference of topic probabilities\n",
    "            self.prob_depth = prob_depth\n",
    "\n",
    "            prob_topic = get_prob_topic(tree_prob_leaf, prob_depth)\n",
    "            self.prob_topic = prob_topic # n_batch x n_topic\n",
    "\n",
    "        # decode bow\n",
    "        with tf.variable_scope('shared', reuse=False):\n",
    "            self.bow_embeddings = tf.get_variable('emb', [self.config.dim_bow, self.config.dim_emb], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of vocab\n",
    "\n",
    "        with tf.variable_scope('topic/dec', reuse=False):\n",
    "        #     tree_topic_embeddings, tree_states_topic_embeddings = doubly_rnn(self.config.dim_emb, self.tree_idxs, name='emb_topic')\n",
    "            emb_layer = lambda h: tf.layers.Dense(units=self.config.dim_emb, name='output')(tf.nn.tanh(h))\n",
    "            tree_topic_embeddings, tree_states_topic_embeddings = doubly_rnn(self.config.dim_emb, self.tree_idxs, output_layer=emb_layer, name='emb_topic')\n",
    "#             topic_embeddings = tf.get_variable('topic_emb', [len(self.topic_idxs), self.config.dim_emb], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of topics\n",
    "#             tree_topic_embeddings = {topic_idx: tf.expand_dims(topic_embeddings[self.topic_idxs.index(topic_idx)], 0) for topic_idx in self.topic_idxs}\n",
    "\n",
    "            tree_topic_bow = get_tree_topic_bow(tree_topic_embeddings) # bow vectors for each topic\n",
    "\n",
    "            topic_bow = tf.concat([tree_topic_bow[topic_idx] for topic_idx in self.topic_idxs], 0) # KxV\n",
    "            self.topic_bow = topic_bow\n",
    "            logits_bow = tf_log(tf.matmul(prob_topic, topic_bow)) # predicted bow distribution N_Batch x  V\n",
    "            self.logits_bow = logits_bow\n",
    "            \n",
    "        # define losses\n",
    "        self.topic_losses_recon = -tf.reduce_sum(tf.multiply(self.t_variables['bow'], logits_bow), 1)\n",
    "        self.topic_loss_recon = tf.reduce_mean(self.topic_losses_recon) # negative log likelihood of each words\n",
    "\n",
    "        self.topic_loss_kl = compute_kl_loss(means_bow, logvars_bow) # KL divergence b/w latent dist & gaussian std\n",
    "\n",
    "#         topic_bow_norm = topic_bow / tf.norm(topic_bow, axis=1, keepdims=True)\n",
    "#         self.topic_dots = tf.clip_by_value(tf.matmul(topic_bow_norm, tf.transpose(topic_bow_norm)), -1., 1.)\n",
    "        \n",
    "        self.topic_embeddings = tf.concat([tree_topic_embeddings[topic_idx] for topic_idx in self.topic_idxs], 0)\n",
    "        topic_embeddings_norm = self.topic_embeddings / tf.norm(self.topic_embeddings, axis=1, keepdims=True)\n",
    "        self.topic_dots = tf.clip_by_value(tf.matmul(topic_embeddings_norm, tf.transpose(topic_embeddings_norm)), -1., 1.)        \n",
    "        \n",
    "        self.tree_mask_reg = get_tree_mask_reg()\n",
    "        self.topic_losses_reg = tf.square(self.topic_dots - tf.eye(len(self.topic_idxs))) * self.tree_mask_reg\n",
    "        self.topic_loss_reg = tf.reduce_sum(self.topic_losses_reg) / tf.reduce_sum(self.tree_mask_reg)\n",
    "\n",
    "        self.global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "\n",
    "        self.loss = self.topic_loss_recon + self.topic_loss_kl + self.config.reg * self.topic_loss_reg\n",
    "\n",
    "        # define optimizer\n",
    "        if self.config.opt == 'Adam':\n",
    "            optimizer = tf.train.AdamOptimizer(self.config.lr)\n",
    "        elif self.config.opt == 'Adagrad':\n",
    "            optimizer = tf.train.AdagradOptimizer(self.config.lr)\n",
    "\n",
    "        self.grad_vars = optimizer.compute_gradients(self.loss)\n",
    "        self.clipped_grad_vars = [(tf.clip_by_value(grad, -self.config.grad_clip, self.config.grad_clip), var) for grad, var in self.grad_vars]\n",
    "        self.opt = optimizer.apply_gradients(self.clipped_grad_vars, global_step=self.global_step)\n",
    "\n",
    "        # monitor\n",
    "        self.n_bow = tf.reduce_sum(self.t_variables['bow'], 1)\n",
    "        self.topic_ppls = tf.divide(self.topic_losses_recon, tf.maximum(1e-5, self.n_bow))\n",
    "        self.topics_freq_bow_indices = tf.nn.top_k(topic_bow, 10, name='topic_freq_bow').indices\n",
    "    \n",
    "        # growth criteria\n",
    "#         self.dist_bow = -tf.matmul(self.t_variables['bow'], tf.log(topic_bow), transpose_b=True)\n",
    "#         self.rads_bow = tf.divide(tf.multiply(self.dist_bow, prob_topic), tf.expand_dims(self.n_bow, -1))\n",
    "        self.n_topics = tf.multiply(tf.expand_dims(self.n_bow, -1), prob_topic)\n",
    "        \n",
    "        self.arcs_bow = tf.acos(tf.matmul(tf.linalg.l2_normalize(self.bow_embeddings, axis=-1), tf.linalg.l2_normalize(self.topic_embeddings, axis=-1), transpose_b=True)) # n_vocab x n_topic\n",
    "        self.rads_bow = tf.multiply(tf.matmul(self.t_variables['bow'], self.arcs_bow), self.prob_topic) # n_batch x n_topic\n",
    "    \n",
    "    def get_feed_dict(self, batch, mode='train'):\n",
    "        bow = np.array([instance.bow for instance in batch]).astype(np.float32)\n",
    "        keep_prob = self.config.keep_prob if mode == 'train' else 1.0\n",
    "        feed_dict = {\n",
    "                    self.t_variables['bow']: bow, \n",
    "                    self.t_variables['keep_prob']: keep_prob\n",
    "        }\n",
    "        return  feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_loss(sess, batches, model):\n",
    "    losses = []\n",
    "    ppl_list = []\n",
    "    rads_bow_list = []\n",
    "    prob_topic_list = []\n",
    "    n_bow_list = []\n",
    "    n_topics_list = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = model.get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, rads_bow_batch, prob_topic_batch, n_bow_batch, n_topics_batch \\\n",
    "            = sess.run([model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, model.rads_bow, model.prob_topic, model.n_bow, model.n_topics], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppl_list += list(ppls_batch)\n",
    "        rads_bow_list.append(rads_bow_batch)\n",
    "        prob_topic_list.append(prob_topic_batch)\n",
    "        n_bow_list.append(n_bow_batch)\n",
    "        n_topics_list.append(n_topics_batch)\n",
    "    loss_mean, topic_loss_recon_mean, topic_loss_kl_mean, topic_loss_reg_mean = np.mean(losses, 0)\n",
    "    ppl_mean = np.exp(np.mean(ppl_list))\n",
    "    \n",
    "    probs_topic = np.concatenate(prob_topic_list, 0)\n",
    "    \n",
    "    n_bow = np.concatenate(n_bow_list, 0)\n",
    "    n_topics = np.concatenate(n_topics_list, 0)\n",
    "    probs_topic_mean = np.sum(n_topics, 0) / np.sum(n_bow)\n",
    "    \n",
    "    rads_bow = np.concatenate(rads_bow_list, 0)\n",
    "    rads_bow_mean = np.cos(np.sum(rads_bow, 0) / np.sum(n_topics, 0))\n",
    "    \n",
    "    return loss_mean, topic_loss_recon_mean, topic_loss_kl_mean, topic_loss_reg_mean, ppl_mean, rads_bow_mean, probs_topic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def print_topic_sample(tree_idxs, sess=None, model=None, topic_rad_bow=None, topic_prob_topic=None, parent_idx=0, topics_freq_bow_idxs=None, depth = 0):\n",
    "    if topics_freq_bow_idxs is None:\n",
    "        topics_freq_bow_idxs = bow_idxs[sess.run(model.topics_freq_bow_indices)]\n",
    "        topic_freq_bow_idxs = topics_freq_bow_idxs[model.topic_idxs.index(parent_idx)]\n",
    "        rad_bow = topic_rad_bow[parent_idx]\n",
    "        prob_topic = topic_prob_topic[parent_idx]\n",
    "        print(parent_idx, 'R: %.3f' % rad_bow, 'P: %.3f' % prob_topic, ' '.join([idx_to_word[idx] for idx in topic_freq_bow_idxs]))\n",
    "    \n",
    "    child_idxs = tree_idxs[parent_idx]\n",
    "    depth += 1\n",
    "    for child_idx in child_idxs:\n",
    "        topic_freq_bow_idxs = topics_freq_bow_idxs[model.topic_idxs.index(child_idx)]\n",
    "        rad_bow = topic_rad_bow[child_idx]\n",
    "        prob_topic = topic_prob_topic[child_idx]\n",
    "        print('  '*depth, child_idx, 'R: %.2f' % rad_bow, 'P: %.3f' % prob_topic, ' '.join([idx_to_word[idx] for idx in topic_freq_bow_idxs]))\n",
    "        \n",
    "        if child_idx in tree_idxs: print_topic_sample(tree_idxs, model=model, topic_rad_bow=topic_rad_bow, topic_prob_topic=topic_prob_topic, parent_idx=child_idx, topics_freq_bow_idxs=topics_freq_bow_idxs, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recur_topic_idxs(model, parent_idx, recur_topic_idxs = None):\n",
    "    if recur_topic_idxs is None: recur_topic_idxs = [parent_idx]\n",
    "\n",
    "    if parent_idx in model.tree_idxs:\n",
    "        child_idxs = model.tree_idxs[parent_idx]\n",
    "        recur_topic_idxs += child_idxs\n",
    "        for child_idx in child_idxs:\n",
    "            if child_idx in model.tree_idxs: get_recur_topic_idxs(model, child_idx, recur_topic_idxs)\n",
    "    return recur_topic_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def update_tree(recur_prob_topic, topic_prob_topic, model, add_threshold=0.3, remove_threshold=0.1):    \n",
    "    assert len(model.topic_idxs) == len(recur_prob_topic) == len(topic_prob_topic)\n",
    "    update_tree_flg = False\n",
    "    \n",
    "    def add_topic(topic_idx, tree_idxs):\n",
    "        if topic_idx in tree_idxs:\n",
    "            child_idx = min([10*topic_idx+i for i in range(1, 10) if 10*topic_idx+i not in tree_idxs[topic_idx]])\n",
    "            tree_idxs[topic_idx].append(child_idx)        \n",
    "        else:\n",
    "            child_idx = 10*topic_idx+1\n",
    "            tree_idxs[topic_idx] = [10*topic_idx+1]\n",
    "        return tree_idxs, child_idx\n",
    "    \n",
    "    added_tree_idxs = copy.deepcopy(model.tree_idxs)\n",
    "    for parent_idx, child_idxs in model.tree_idxs.items():\n",
    "#         rad_bow = topic_rad_bow[parent_idx]\n",
    "        rad_bow = topic_prob_topic[parent_idx]\n",
    "        if rad_bow > add_threshold:\n",
    "            update_tree_flg = True\n",
    "            for depth in range(model.tree_depth[parent_idx], model.n_depth):\n",
    "                added_tree_idxs, parent_idx = add_topic(parent_idx, added_tree_idxs)\n",
    "    \n",
    "    def remove_topic(parent_idx, child_idx, tree_idxs):\n",
    "        if parent_idx in tree_idxs:\n",
    "            tree_idxs[parent_idx].remove(child_idx)\n",
    "            if child_idx in tree_idxs:\n",
    "                tree_idxs.pop(child_idx)    \n",
    "        return tree_idxs\n",
    "    \n",
    "    removed_tree_idxs = copy.deepcopy(added_tree_idxs)\n",
    "    for parent_idx, child_idxs in model.tree_idxs.items():\n",
    "#         probs_child = np.array([topic_prob_topic[child_idx] for child_idx in child_idxs])\n",
    "        probs_child = np.array([recur_prob_topic[child_idx] for child_idx in child_idxs])\n",
    "#         prob_child = np.min(probs_child)\n",
    "#         child_idx = child_idxs[np.argmin(probs_child)]\n",
    "        for prob_child, child_idx in zip(probs_child, child_idxs):\n",
    "            if prob_child < remove_threshold:\n",
    "                update_tree_flg = True\n",
    "                removed_tree_idxs = remove_topic(parent_idx, child_idx, removed_tree_idxs)\n",
    "                if parent_idx in removed_tree_idxs:\n",
    "                    if len(removed_tree_idxs[parent_idx]) == 0:\n",
    "                        ancestor_idx = model.child_to_parent_idxs[parent_idx]\n",
    "                        removed_tree_idxs = remove_topic(ancestor_idx, parent_idx, removed_tree_idxs)\n",
    "    return removed_tree_idxs, update_tree_flg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "ppls_train = []\n",
    "loss_min = np.inf\n",
    "beta_eval = 1.\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','TM','','','','VALID:','TM','','',''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG']]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_idxs = {0:[1, 2], \n",
    "#           1:[10, 11], 2:[20, 21]}\n",
    "\n",
    "tree_idxs = {0:[1, 2, 3, 4], \n",
    "              1:[11, 12], 2:[21, 22], 3:[31, 32], 4:[41, 42]}\n",
    "\n",
    "# tree_idxs = {0:[1, 2, 3], \n",
    "#               1:[10, 11, 12], 2:[20, 21, 22], 3:[30, 31, 32]}\n",
    "\n",
    "\n",
    "if 'sess' in globals(): sess.close()\n",
    "model = Model(config, tree_idxs)\n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))}\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th>TM</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th>TM</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>111.62</td>\n",
       "      <td>493</td>\n",
       "      <td>110.53</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>103.77</td>\n",
       "      <td>453</td>\n",
       "      <td>102.45</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>111.03</td>\n",
       "      <td>470</td>\n",
       "      <td>109.69</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>103.58</td>\n",
       "      <td>441</td>\n",
       "      <td>102.05</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>110.71</td>\n",
       "      <td>457</td>\n",
       "      <td>109.20</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>103.35</td>\n",
       "      <td>428</td>\n",
       "      <td>101.57</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>110.48</td>\n",
       "      <td>447</td>\n",
       "      <td>108.83</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>102.86</td>\n",
       "      <td>409</td>\n",
       "      <td>100.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>110.31</td>\n",
       "      <td>440</td>\n",
       "      <td>108.56</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>103.06</td>\n",
       "      <td>413</td>\n",
       "      <td>101.01</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>110.18</td>\n",
       "      <td>435</td>\n",
       "      <td>108.35</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.05</td>\n",
       "      <td>103.00</td>\n",
       "      <td>409</td>\n",
       "      <td>100.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>110.08</td>\n",
       "      <td>430</td>\n",
       "      <td>108.19</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>103.00</td>\n",
       "      <td>409</td>\n",
       "      <td>100.86</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>110.00</td>\n",
       "      <td>427</td>\n",
       "      <td>108.06</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.83</td>\n",
       "      <td>402</td>\n",
       "      <td>100.70</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45000</th>\n",
       "      <td>66</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>109.93</td>\n",
       "      <td>424</td>\n",
       "      <td>107.95</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.87</td>\n",
       "      <td>404</td>\n",
       "      <td>100.70</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>109.87</td>\n",
       "      <td>422</td>\n",
       "      <td>107.85</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.76</td>\n",
       "      <td>400</td>\n",
       "      <td>100.55</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55000</th>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>109.82</td>\n",
       "      <td>420</td>\n",
       "      <td>107.77</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.86</td>\n",
       "      <td>401</td>\n",
       "      <td>100.62</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60000</th>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>109.78</td>\n",
       "      <td>418</td>\n",
       "      <td>107.71</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.62</td>\n",
       "      <td>397</td>\n",
       "      <td>100.48</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65000</th>\n",
       "      <td>58</td>\n",
       "      <td>130</td>\n",
       "      <td>129</td>\n",
       "      <td>109.74</td>\n",
       "      <td>417</td>\n",
       "      <td>107.66</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>102.76</td>\n",
       "      <td>399</td>\n",
       "      <td>100.55</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>59</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>109.71</td>\n",
       "      <td>415</td>\n",
       "      <td>107.60</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.61</td>\n",
       "      <td>395</td>\n",
       "      <td>100.37</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75000</th>\n",
       "      <td>58</td>\n",
       "      <td>150</td>\n",
       "      <td>149</td>\n",
       "      <td>109.68</td>\n",
       "      <td>414</td>\n",
       "      <td>107.55</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.63</td>\n",
       "      <td>393</td>\n",
       "      <td>100.38</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>59</td>\n",
       "      <td>160</td>\n",
       "      <td>159</td>\n",
       "      <td>109.65</td>\n",
       "      <td>413</td>\n",
       "      <td>107.51</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.58</td>\n",
       "      <td>392</td>\n",
       "      <td>100.33</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85000</th>\n",
       "      <td>58</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>109.63</td>\n",
       "      <td>412</td>\n",
       "      <td>107.47</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.56</td>\n",
       "      <td>392</td>\n",
       "      <td>100.29</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>57</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>109.60</td>\n",
       "      <td>411</td>\n",
       "      <td>107.44</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.68</td>\n",
       "      <td>394</td>\n",
       "      <td>100.41</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95000</th>\n",
       "      <td>79</td>\n",
       "      <td>190</td>\n",
       "      <td>189</td>\n",
       "      <td>109.59</td>\n",
       "      <td>410</td>\n",
       "      <td>107.40</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.86</td>\n",
       "      <td>399</td>\n",
       "      <td>100.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>55</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>109.57</td>\n",
       "      <td>409</td>\n",
       "      <td>107.38</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.97</td>\n",
       "      <td>403</td>\n",
       "      <td>100.72</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105000</th>\n",
       "      <td>58</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>109.55</td>\n",
       "      <td>409</td>\n",
       "      <td>107.35</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>102.69</td>\n",
       "      <td>396</td>\n",
       "      <td>100.40</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TRAIN:   TM                      VALID:   TM          \\\n",
       "       Time   Ep   Ct    LOSS  PPL     NLL    KL   REG    LOSS  PPL     NLL   \n",
       "5000     66   10    9  111.62  493  110.53  1.01  0.08  103.77  453  102.45   \n",
       "10000    66   20   19  111.03  470  109.69  1.28  0.06  103.58  441  102.05   \n",
       "15000    66   30   29  110.71  457  109.20  1.46  0.05  103.35  428  101.57   \n",
       "20000    68   40   39  110.48  447  108.83  1.59  0.05  102.86  409  100.91   \n",
       "25000    72   50   49  110.31  440  108.56  1.70  0.05  103.06  413  101.01   \n",
       "30000    62   60   59  110.18  435  108.35  1.78  0.05  103.00  409  100.87   \n",
       "35000    70   70   69  110.08  430  108.19  1.85  0.05  103.00  409  100.86   \n",
       "40000    66   80   79  110.00  427  108.06  1.90  0.04  102.83  402  100.70   \n",
       "45000    66   90   89  109.93  424  107.95  1.94  0.04  102.87  404  100.70   \n",
       "50000    75  100   99  109.87  422  107.85  1.98  0.04  102.76  400  100.55   \n",
       "55000    63  110  109  109.82  420  107.77  2.01  0.04  102.86  401  100.62   \n",
       "60000    56  120  119  109.78  418  107.71  2.03  0.04  102.62  397  100.48   \n",
       "65000    58  130  129  109.74  417  107.66  2.05  0.04  102.76  399  100.55   \n",
       "70000    59  140  139  109.71  415  107.60  2.07  0.03  102.61  395  100.37   \n",
       "75000    58  150  149  109.68  414  107.55  2.09  0.03  102.63  393  100.38   \n",
       "80000    59  160  159  109.65  413  107.51  2.11  0.03  102.58  392  100.33   \n",
       "85000    58  170  169  109.63  412  107.47  2.12  0.03  102.56  392  100.29   \n",
       "90000    57  180  179  109.60  411  107.44  2.14  0.03  102.68  394  100.41   \n",
       "95000    79  190  189  109.59  410  107.40  2.15  0.03  102.86  399  100.53   \n",
       "100000   55  200  199  109.57  409  107.38  2.16  0.03  102.97  403  100.72   \n",
       "105000   58  210  209  109.55  409  107.35  2.17  0.03  102.69  396  100.40   \n",
       "\n",
       "                    \n",
       "          KL   REG  \n",
       "5000    1.27  0.04  \n",
       "10000   1.50  0.03  \n",
       "15000   1.74  0.04  \n",
       "20000   1.92  0.03  \n",
       "25000   1.99  0.06  \n",
       "30000   2.11  0.03  \n",
       "35000   2.11  0.04  \n",
       "40000   2.11  0.02  \n",
       "45000   2.14  0.03  \n",
       "50000   2.17  0.03  \n",
       "55000   2.21  0.03  \n",
       "60000   2.13  0.01  \n",
       "65000   2.20  0.01  \n",
       "70000   2.23  0.01  \n",
       "75000   2.24  0.01  \n",
       "80000   2.24  0.01  \n",
       "85000   2.26  0.01  \n",
       "90000   2.27  0.01  \n",
       "95000   2.29  0.04  \n",
       "100000  2.24  0.01  \n",
       "105000  2.29  0.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 R: 1.000 P: 0.109 quality price ... - 'm made $ buy time nice\n",
      "   1 R: 0.47 P: 0.206 carry pockets room shoulder strap space camera compartment compartments plenty\n",
      "     11 R: 0.13 P: 0.129 sleeve protection inside inch padding nice protect pro air snug\n",
      "     14 R: 0.10 P: 0.097 pocket room power mouse charger perfect ipad cord small netbook\n",
      "     12 R: 0.04 P: 0.037 ; & pro drive hard tablet usb mouse works nice\n",
      "   2 R: 0.21 P: 0.085 ! bought love school recommend quality ... amazon price time\n",
      "     24 R: 0.05 P: 0.049 smell ! air price perfectly color mac pro love protect\n",
      "     21 R: 0.08 P: 0.077 ! love color perfectly cover mac recommend perfect pro picture\n",
      "   6 R: 0.07 P: 0.042 strap handle zipper zippers straps months years shoulder back 've\n",
      "     61 R: 0.03 P: 0.030 zipper flap close velcro open side : -- closed top\n",
      "   3 R: 0.14 P: 0.043 months return broke back money received item cracked started bottom\n",
      "     31 R: 0.10 P: 0.095 cover keyboard bottom hard pro top nice mac screen air\n",
      "{0: [1, 2, 3, 4], 1: [11, 14, 13], 2: [21, 22], 3: [31], 4: [41]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-d30cbac9893b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_recon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_kl_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_reg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppls_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_log\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_loss_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_loss_kl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_loss_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_ppls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlosses_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_recon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_kl_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_loss_reg_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if len(log_df) == 0:\n",
    "    cmd_rm = 'rm -r %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_rm.split())\n",
    "\n",
    "    cmd_mk = 'mkdir %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "time_start = time.time()\n",
    "while epoch < config.epochs:    \n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        # validate\n",
    "#         if global_step_log % config.log_period == 0:\n",
    "        if global_step_log % 5000 == 0:            \n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, rads_bow_dev, probs_topic_dev = get_loss(sess, dev_batches, model)\n",
    "\n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "\n",
    "            # visualize topic\n",
    "#             topic_rad_bow = {topic_idx: rad_bow for topic_idx, rad_bow in zip(model.topic_idxs, rads_bow_dev)}\n",
    "            topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "            \n",
    "            recur_topic_idxs = {parent_idx: get_recur_topic_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "            recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in recur_topic_idxs.items()}\n",
    "            \n",
    "            print_topic_sample(tree_idxs, sess, model, topic_prob_topic=topic_prob_topic, topic_rad_bow=recur_prob_topic)\n",
    "            time_start = time.time()\n",
    "\n",
    "            # update tree\n",
    "#             tree_idxs, update_tree_flg = update_tree(topic_rad_bow, topic_prob_topic, model, add_threshold=0.2, remove_threshold=0.05)\n",
    "            tree_idxs, update_tree_flg = update_tree(recur_prob_topic, topic_prob_topic, model, add_threshold=0.05, remove_threshold=0.05)\n",
    "            if update_tree_flg:\n",
    "                print(tree_idxs)\n",
    "                name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                if 'sess' in globals(): sess.close()\n",
    "                model = Model(config, tree_idxs)\n",
    "                sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, rads_bow_dev, probs_topic_dev = get_loss(sess, dev_batches, model)\n",
    "topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "\n",
    "recur_topic_idxs = {parent_idx: get_recur_topic_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in recur_topic_idxs.items()}\n",
    "display(log_df)\n",
    "print_topic_sample(tree_idxs, sess, model, topic_prob_topic=topic_prob_topic, topic_rad_bow=recur_prob_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confirm variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_bow = sess.run(model.topic_bow)\n",
    "norm_bow = np.sum([instance.bow for instance in instances_train], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_vec = topics_bow / np.linalg.norm(topics_bow, axis=1, keepdims=True)\n",
    "norm_vec = norm_bow / np.linalg.norm(norm_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_spec = 1 - topics_vec.dot(norm_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_topic_idxs = defaultdict(list)\n",
    "for topic_idx, depth in model.tree_depth.items():\n",
    "    depth_topic_idxs[depth].append(topic_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5091926\n",
      "2 0.5277941\n",
      "3 0.54874736\n"
     ]
    }
   ],
   "source": [
    "for depth, topic_idxs in depth_topic_idxs.items():\n",
    "    topic_indices = np.array([model.topic_idxs.index(topic_idx) for topic_idx in topic_idxs])\n",
    "    depth_spec = np.mean(topics_spec[topic_indices])\n",
    "    print(depth, depth_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
