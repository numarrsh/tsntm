{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import pdb\n",
    "import _pickle as cPickle\n",
    "import time\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from rcrp import Topic, Doc, init, sample, get_perplexity, get_topic_specialization, get_hierarchical_affinities, get_freq_tokens_rcrp, get_docs\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load config & data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9006, 1995)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.n_doc = len(instances_train)\n",
    "config.n_vocab = len(bow_idxs)\n",
    "config.n_doc, config.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bow = [instance.bow for instance in instances_train]\n",
    "docs_raw = [[[bow_index]*int(doc_bow[bow_index]) for bow_index in np.where(doc_bow > 0)[0]] for doc_bow in docs_bow]\n",
    "docs_words = [[idx for idxs in doc for idx in idxs] for doc in docs_raw]\n",
    "np.sum([len(doc_words) for doc_words in docs_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','VALID:','TEST:','SPEC:', '', '', 'HIER:', ''],\n",
    "                            ['Time','Ep','Ct','PPL','PPL', 'PPL','1', '2', '3', 'CHILD', 'OTHER']]))))\n",
    "\n",
    "def update_checkpoint(config, checkpoint, epoch):\n",
    "    checkpoint.append(config.path_model + '-%i' % epoch)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0)\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_root = Topic(idx='0', sibling_idx=0, parent=None, depth=1, config=config)\n",
    "train_docs = get_docs(instances_train, config, topic_root=topic_root)\n",
    "dev_docs = get_docs(instances_dev, config, topic_root=topic_root)\n",
    "test_docs = get_docs(instances_test, config, topic_root=topic_root)\n",
    "init(train_docs, dev_docs, test_docs, topic_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th>VALID:</th>\n",
       "      <th>TEST:</th>\n",
       "      <th>SPEC:</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "      <th>HIER:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>CHILD</th>\n",
       "      <th>OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>759</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>683</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7991</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>647</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5797</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785</td>\n",
       "      <td>625</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3312</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>769</td>\n",
       "      <td>610</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3259</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>600</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3358</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>743</td>\n",
       "      <td>592</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3313</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>733</td>\n",
       "      <td>585</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3293</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>725</td>\n",
       "      <td>579</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3158</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>575</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3218</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>716</td>\n",
       "      <td>569</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3324</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>710</td>\n",
       "      <td>565</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3216</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>706</td>\n",
       "      <td>563</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3318</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>703</td>\n",
       "      <td>559</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3439</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>556</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TRAIN: VALID: TEST: SPEC:             HIER:      \n",
       "    Time  Ep Ct    PPL    PPL   PPL     1     2     3 CHILD OTHER\n",
       "0   8562   0  0      0    948   759  0.02  0.48  0.43  0.60  0.46\n",
       "1   9017   1  0      0    856   683  0.02  0.51  0.44  0.51  0.44\n",
       "2   7991   2  0      0    812   647  0.02  0.53  0.44  0.54  0.46\n",
       "3   5797   3  0      0    785   625  0.02  0.54  0.45  0.53  0.45\n",
       "4   3312   4  0      0    769   610  0.02  0.54  0.45  0.59  0.43\n",
       "5   3259   5  0      0    755   600  0.02  0.54  0.45  0.53  0.43\n",
       "6   3358   6  0      0    743   592  0.02  0.55  0.46  0.56  0.42\n",
       "7   3313   7  0      0    733   585  0.02  0.54  0.46  0.58  0.43\n",
       "8   3293   8  0      0    725   579  0.02  0.54  0.46  0.50  0.44\n",
       "9   3158   9  0      0    721   575  0.02  0.55  0.47  0.52  0.40\n",
       "10  3218  10  0      0    716   569  0.02  0.55  0.47  0.51  0.40\n",
       "11  3324  11  0      0    710   565  0.02  0.55  0.47  0.48  0.41\n",
       "12  3216  12  0      0    706   563  0.02  0.55  0.48  0.46  0.39\n",
       "13  3318  13  0      0    703   559  0.02  0.55  0.48  0.49  0.40\n",
       "14  3439  14  0      0    699   556  0.02  0.55  0.48  0.51  0.41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 : ['0-1', '0-2', '0-3', '0-4', '0-5', '0-6', '0-7', '0-8', '0-9', '0-10', '0-11', '0-12', '0-13', '0-14', '0-15', '0-16', '0-17', '0-18', '0-19', '0-20', '0-21', '0-22', '0-23', '0-24', '0-25', '0-26', '0-27', '0-28', '0-29', '0-30', '0-31', '0-32', '0-33', '0-34', '0-35', '0-37', '0-38', '0-43', '0-49', '0-50', '0-52', '0-53'] 88 2663.0 ['use', 'write', 'one', 'get', 'article', 'know', 'like', 'make', 'say', 'go']\n",
      "     0-1 : ['0-1-1', '0-1-2', '0-1-3'] 8825 85062.0 ['write', 'article', 'get', 'know', 'like', 'one', 'go', 'think', 'anyone', 'make']\n",
      "       0-1-1 : [] 64 1573.0 ['georgia', 'cost', 'university', 'michael', 'nasa', 'say', 'like', 'work', 'problem', 'fee']\n",
      "       0-1-2 : [] 25 531.0 ['jewish', 'come', 'thanks', 'john', 'player', 'maybe', 'article', 'somebody', 'brain', 'anyone']\n",
      "       0-1-3 : [] 1 1.0 ['oo', 'bhj', 'series', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw', 'washington']\n",
      "     0-2 : ['0-2-1', '0-2-2', '0-2-3'] 4772 64005.0 ['use', 'get', 'problem', 'card', 'write', 'one', 'windows', 'know', 'work', 'run']\n",
      "       0-2-1 : [] 355 8318.0 ['file', 'problem', 'windows', 'use', 'run', 'window', 'mouse', 'time', 'dos', 'program']\n",
      "       0-2-2 : [] 1 1.0 ['wife', 'bhj', 'peace', 'bob', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw']\n",
      "       0-2-3 : [] 1 1.0 ['nothing', 'bhj', 'peace', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw', 'washington']\n",
      "     0-3 : [] 3483 63783.0 ['car', 'write', 'get', 'article', 'one', 'go', 'like', 'bike', 'make', 'think']\n",
      "     0-4 : ['0-4-2'] 2021 40412.0 ['one', 'get', 'write', 'article', 'people', 'use', 'say', 'know', 'think', 'take']\n",
      "       0-4-2 : [] 108 3683.0 ['msg', 'food', 'effect', 'study', 'one', 'use', 'people', 'human', 'cause', 'say']\n",
      "     0-5 : [] 718 10671.0 ['use', 'power', 'circuit', 'signal', 'output', 'input', 'pin', 'work', 'current', 'audio']\n",
      "     0-6 : ['0-6-1'] 2706 60324.0 ['game', 'team', 'year', 'play', 'go', 'get', 'player', 'win', 'write', 'think']\n",
      "       0-6-1 : [] 67 4055.0 ['game', 'play', 'goal', 'puck', 'shot', 'get', 'period', 'penalty', 'flyers', 'take']\n",
      "     0-7 : [] 1250 13937.0 ['price', 'sale', 'offer', 'sell', 'new', 'include', 'please', 'condition', 'ask', 'shipping']\n",
      "     0-8 : ['0-8-1'] 175 2426.0 ['new', 'york', 'lose', 'san', 'woman', 'chicago', 'washington', 'houston', 'los', 'francisco']\n",
      "       0-8-1 : [] 1 1.0 ['long', 'bhj', 'series', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw', 'washington']\n",
      "     0-9 : [] 66 2332.0 ['pt', 'period', 'pp', 'la', 'play', 'power', 'philadelphia', 'pittsburgh', 'vs', 'shot']\n",
      "     0-10 : [] 1705 49083.0 ['god', 'one', 'say', 'write', 'people', 'think', 'believe', 'make', 'atheist', 'know']\n",
      "     0-11 : ['0-11-2'] 1554 36533.0 ['image', 'file', 'use', 'available', 'program', 'version', 'software', 'format', 'include', 'ftp']\n",
      "       0-11-2 : [] 64 4657.0 ['image', 'jpeg', 'file', 'color', 'gif', 'format', 'display', 'use', 'program', 'convert']\n",
      "     0-12 : ['0-12-1'] 57 1308.0 ['instruction', 'set', 'computer', 'reduce', 'screw', 'thread', 'performance', 'mean', 'difference', 'software']\n",
      "       0-12-1 : [] 1 1.0 ['local', 'bhj', 'peace', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw', 'washington']\n",
      "     0-13 : [] 22 932.0 ['oo', 'rg', 'eus', 'mr', 'mw', 'mi', 'mg', 'md', 'ma', 'ax']\n",
      "     0-14 : ['0-14-1', '0-14-2'] 341 6533.0 ['point', 'line', 'object', 'theory', 'one', 'find', 'plane', 'edge', 'give', 'algorithm']\n",
      "       0-14-1 : [] 3 11.0 ['target', 'complete', 'md', 'charge', 'tv', 'extension', 'select', 'limit', 'period', 'add']\n",
      "       0-14-2 : [] 1 25.0 ['solid', 'mix', 'form', 'sample', 'suspect', 'al', 'bunch', 'crack', 'usually', 'process']\n",
      "     0-15 : ['0-15-2'] 812 26674.0 ['god', 'jesus', 'say', 'one', 'christian', 'people', 'know', 'bible', 'see', 'christ']\n",
      "       0-15-2 : [] 1 5.0 ['hr', 'corporation', 'lose', 'data', 'throw', 'currently', 'various', 'legal', 'washington', 'james']\n",
      "     0-16 : [] 51 1271.0 ['unit', 'ca', 'cross', 'link', 'wing', 'fly', 'pat', 'nasa', 'backup', 'mary']\n",
      "     0-17 : [] 1104 25824.0 ['drive', 'disk', 'use', 'scsi', 'hard', 'controller', 'system', 'ide', 'bus', 'card']\n",
      "     0-18 : ['0-18-2'] 119 2919.0 ['vote', 'send', 'list', 'request', 'discussion', 'newsgroup', 'post', 'john', 'david', 'apr']\n",
      "       0-18-2 : [] 1 1.0 ['perform', 'bhj', 'peace', 'bob', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw']\n",
      "     0-19 : [] 78 9616.0 ['entry', 'file', 'output', 'program', 'use', 'section', 'printf', 'char', 'oname', 'rule']\n",
      "     0-20 : ['0-20-5'] 1364 37102.0 ['window', 'use', 'widget', 'server', 'application', 'get', 'set', 'program', 'file', 'run']\n",
      "       0-20-5 : [] 1 1.0 ['motherboard', 'bhj', 'handle', 'dave', 'knowledge', 'prevent', 'james', 'throw', 'washington', 'legal']\n",
      "     0-21 : ['0-21-1'] 57 1716.0 ['appear', 'cover', 'copy', 'art', 'new', 'vs', 'title', 'annual', 'rider', 'app']\n",
      "       0-21-1 : [] 2 6.0 ['basically', 'another', 'old', 'hand', 'suffer', 'expand', 'citizen', 'sign', 'washington', 'legal']\n",
      "     0-22 : ['0-22-1'] 82 1890.0 ['dos', 'good', 'excellent', 'cd', 'include', 'book', 'miss', 'issue', 'cover', 'fair']\n",
      "       0-22-1 : [] 2 5.0 ['disease', 'minority', 'bank', 'gas', 'prepare', 'bhj', 'washington', 'currently', 'various', 'legal']\n",
      "     0-23 : [] 102 2973.0 ['dod', 'may', 'ride', 'motorcycle', 'dog', 'club', 'run', 'bmw', 'flame', 'bike']\n",
      "     0-24 : [] 223 8503.0 ['team', 'hockey', 'gm', 'det', 'vs', 'tor', 'cal', 'win', 'la', 'van']\n",
      "     0-25 : [] 1312 44498.0 ['key', 'use', 'chip', 'encryption', 'government', 'clipper', 'system', 'one', 'law', 'phone']\n",
      "     0-26 : [] 8 1435.0 ['db', 'mov', 'bh', 'byte', 'cs', 'al', 'bit', 'push', 'pop', 'one']\n",
      "     0-27 : ['0-27-1'] 70 2482.0 ['right', 'arm', 'amendment', 'bear', 'people', 'constitution', 'second', 'keep', 'militia', 'american']\n",
      "       0-27-1 : [] 1 2.0 ['etc', 'hot', 'bhj', 'peace', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw']\n",
      "     0-28 : [] 152 7462.0 ['health', 'medical', 'use', 'center', 'research', 'disease', 'cancer', 'university', 'report', 'year']\n",
      "     0-29 : [] 138 7496.0 ['ground', 'wire', 'use', 'wiring', 'outlet', 'circuit', 'neutral', 'one', 'box', 'cable']\n",
      "     0-30 : ['0-30-2'] 77 2674.0 ['software', 'day', 'keyboard', 'level', 'picture', 'tool', 'per', 'also', 'exercise', 'prevent']\n",
      "       0-30-2 : [] 2 3.0 ['remember', 'enter', 'north', 'washington', 'la', 'final', 'currently', 'various', 'legal', 'james']\n",
      "     0-31 : ['0-31-1'] 78 1926.0 ['water', 'plant', 'nuclear', 'use', 'air', 'hot', 'cool', 'power', 'fuel', 'get']\n",
      "       0-31-1 : [] 1 1.0 ['maintain', 'bhj', 'la', 'bob', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw']\n",
      "     0-32 : ['0-32-1', '0-32-2'] 5 176.0 ['motor', 'patient', 'region', 'upgrade', 'path', 'dec', 'old', 'evidence', 'structure', 'unit']\n",
      "       0-32-1 : [] 3 49.0 ['region', 'structure', 'int', 'store', 'school', 'corporation', 'remember', 'australia', 'besides', 'little']\n",
      "       0-32-2 : [] 1 1.0 ['average', 'bhj', 'series', 'ram', 'dave', 'knowledge', 'prevent', 'james', 'throw', 'washington']\n",
      "     0-33 : [] 156 4759.0 ['conference', 'university', 'research', 'information', 'pm', 'computer', 'include', 'fax', 'technical', 'virtual']\n",
      "     0-34 : [] 807 26140.0 ['space', 'launch', 'nasa', 'satellite', 'orbit', 'mission', 'earth', 'lunar', 'use', 'system']\n",
      "     0-35 : [] 24 533.0 ['gun', 'fear', 'model', 'subject', 'university', 'cap', 'guarantee', 'marriage', 'freedom', 'without']\n",
      "     0-37 : [] 235 13512.0 ['internet', 'anonymous', 'post', 'use', 'list', 'information', 'email', 'privacy', 'user', 'mail']\n",
      "     0-38 : [] 8 225.0 ['de', 'van', 'na', 'la', 'meet', 'battery', 'roger', 'et', 'ram', 'monitor']\n",
      "     0-43 : [] 4 306.0 ['disease', 'god', 'double', 'sin', 'satan', 'perfect', 'code', 'billion', 'tend', 'original']\n",
      "     0-49 : ['0-49-1'] 6 269.0 ['attack', 'mother', 'distribution', 'input', 'boy', 'kill', 'guilty', 'satellite', 'properly', 'serve']\n",
      "       0-49-1 : [] 2 31.0 ['guilty', 'criminal', 'crime', 'amendment', 'location', 'innocent', 'suspect', 'trial', 'middle', 'technical']\n",
      "     0-50 : [] 4 125.0 ['pen', 'installation', 'register', 'order', 'general', 'device', 'black', 'act', 'chapter', 'hour']\n",
      "     0-52 : [] 2 11.0 ['show', 'lay', 'grant', 'refer', 'staff', 'tim', 'bank', 'car', 'straight', 'various']\n",
      "     0-53 : [] 1 262.0 ['tax', 'fund', 'center', 'go', 'billion', 'spend', 'year', 'library', 'congress', 'battery']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4acc2dc4e675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     ppl_train = get_perplexity(train_docs, topic_root)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mppl_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(train_docs, dev_docs, test_docs, topic_root)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0msample_word_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0msample_doc_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0msample_word_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36msample_word_topics\u001b[0;34m(docs, topic_root, train)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;31m# sample topic_index of word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_cnt_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36msample_index\u001b[0;34m(self, word_idx, init)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mprobs_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probs_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36mget_probs_index\u001b[0;34m(self, word_idx, init)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mlogits_index_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logits_index_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mlogits_index_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logits_index_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mlogits_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_index_prior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogits_index_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36mget_logits_index_likelihood\u001b[0;34m(self, word_idx)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mlogits_index_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_index_likelihood\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mz_index_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mlogit_new_index_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logit_new_index_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mlogits_index_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_index_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_new_index_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36mget_logit_new_index_likelihood\u001b[0;34m(word_idx)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0ms_child_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mz_child_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mp_child_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_child_likelihood\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mz_child_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topicsum/rcrp.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0ms_child_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mz_child_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mp_child_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_child_likelihood\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mz_child_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2076\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    sample(train_docs, dev_docs, test_docs, topic_root)\n",
    "#     ppl_train = get_perplexity(train_docs, topic_root)\n",
    "    ppl_train = 0.\n",
    "    ppl_dev = get_perplexity(dev_docs, topic_root)\n",
    "    \n",
    "    if ppl_dev < ppl_min:\n",
    "        ppl_min = ppl_dev\n",
    "        ppl_test = get_perplexity(test_docs, topic_root)\n",
    "        cPickle.dump([test_docs, topic_root], open(config.path_model + '-%i'%epoch, 'wb'))\n",
    "        update_checkpoint(config, checkpoint, epoch)\n",
    "        \n",
    "    depth_spec = get_topic_specialization(test_docs, topic_root)\n",
    "    hierarchical_affinities = get_hierarchical_affinities(topic_root)\n",
    "    \n",
    "    clear_output()\n",
    "    time_log = int(time.time() - time_start)\n",
    "    time_start = time.time()\n",
    "    log_series = pd.Series([time_log, epoch, 0, \\\n",
    "            '%.0f'%ppl_train, '%.0f'%ppl_dev, '%.0f'%ppl_test, \\\n",
    "            '%.2f'%depth_spec[1], '%.2f'%depth_spec[2] if 2 in depth_spec else 0, '%.2f'%depth_spec[3] if 3 in depth_spec else 0, \\\n",
    "            '%.2f'%hierarchical_affinities[0], '%.2f'%hierarchical_affinities[1]],\n",
    "            index=log_df.columns)\n",
    "    log_df.loc[epoch] = log_series\n",
    "    display(log_df)\n",
    "    get_freq_tokens_rcrp(topic_root, idx_to_word, bow_idxs)\n",
    "    \n",
    "    cPickle.dump(log_df, open(config.path_log, 'wb'))\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
