{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from gsm import GaussianSoftmaxModel\n",
    "from rsm import RecurrentStickbreakingModel\n",
    "from evaluation import validate, print_flat_topic_sample\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    return _variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','VALID:','','','','','TEST:',''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG','LOSS','PPL']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "if config.model == 'gsm':\n",
    "    Model = GaussianSoftmaxModel\n",
    "elif config.model == 'rsm':\n",
    "    Model = RecurrentStickbreakingModel\n",
    "model = Model(config)    \n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>112.75</td>\n",
       "      <td>543</td>\n",
       "      <td>112.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>104.84</td>\n",
       "      <td>507</td>\n",
       "      <td>104.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.89</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>112.29</td>\n",
       "      <td>526</td>\n",
       "      <td>111.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>104.72</td>\n",
       "      <td>497</td>\n",
       "      <td>104.15</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.87</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>112.07</td>\n",
       "      <td>517</td>\n",
       "      <td>111.46</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>104.51</td>\n",
       "      <td>489</td>\n",
       "      <td>103.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.71</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>111.91</td>\n",
       "      <td>511</td>\n",
       "      <td>111.23</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>104.45</td>\n",
       "      <td>484</td>\n",
       "      <td>103.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.59</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>111.79</td>\n",
       "      <td>505</td>\n",
       "      <td>111.05</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.38</td>\n",
       "      <td>481</td>\n",
       "      <td>103.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.44</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>111.69</td>\n",
       "      <td>501</td>\n",
       "      <td>110.89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.33</td>\n",
       "      <td>476</td>\n",
       "      <td>103.41</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.36</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>27</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>111.62</td>\n",
       "      <td>498</td>\n",
       "      <td>110.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.26</td>\n",
       "      <td>475</td>\n",
       "      <td>103.34</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.39</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>26</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>111.55</td>\n",
       "      <td>495</td>\n",
       "      <td>110.68</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.32</td>\n",
       "      <td>476</td>\n",
       "      <td>103.35</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.39</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45000</th>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>111.50</td>\n",
       "      <td>493</td>\n",
       "      <td>110.59</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.29</td>\n",
       "      <td>472</td>\n",
       "      <td>103.29</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.58</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>111.45</td>\n",
       "      <td>491</td>\n",
       "      <td>110.51</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>104.26</td>\n",
       "      <td>473</td>\n",
       "      <td>103.20</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.58</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRAIN:                           VALID:               \\\n",
       "      Time   Ep  Ct    LOSS  PPL     NLL    KL   REG    LOSS  PPL     NLL   \n",
       "5000    34   10   9  112.75  543  112.33  0.41  0.02  104.84  507  104.38   \n",
       "10000   28   20  19  112.29  526  111.75  0.53  0.02  104.72  497  104.15   \n",
       "15000   27   30  29  112.07  517  111.46  0.60  0.02  104.51  489  103.83   \n",
       "20000   27   40  39  111.91  511  111.23  0.67  0.02  104.45  484  103.64   \n",
       "25000   27   50  49  111.79  505  111.05  0.73  0.01  104.38  481  103.54   \n",
       "30000   28   60  59  111.69  501  110.89  0.78  0.01  104.33  476  103.41   \n",
       "35000   27   70  69  111.62  498  110.77  0.83  0.01  104.26  475  103.34   \n",
       "40000   26   80  79  111.55  495  110.68  0.87  0.01  104.32  476  103.35   \n",
       "45000   28   90  89  111.50  493  110.59  0.90  0.01  104.29  472  103.29   \n",
       "50000   28  100  99  111.45  491  110.51  0.93  0.01  104.26  473  103.20   \n",
       "\n",
       "                    TEST:       \n",
       "         KL   REG    LOSS  PPL  \n",
       "5000   0.45  0.01  102.89  498  \n",
       "10000  0.55  0.01  102.87  491  \n",
       "15000  0.67  0.01  102.71  486  \n",
       "20000  0.80  0.01  102.59  475  \n",
       "25000  0.84  0.01  102.44  470  \n",
       "30000  0.91  0.01  102.36  467  \n",
       "35000  0.91  0.01  102.39  469  \n",
       "40000  0.96  0.00  102.39  469  \n",
       "45000  0.99  0.00  102.58  471  \n",
       "50000  1.05  0.00  102.58  471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ! cover color love pro price nice bottom perfectly bought\n",
      "1 carry pockets room strap ! pocket back shoulder space small\n",
      "2 sleeve & ; inside pocket inch protection power netbook mouse\n",
      "3 zipper quality months bought years broke year zippers design made\n",
      "4 made pro ! thought love put ... color happy perfectly\n",
      "5 bought nice inside short travel loves holds padded pleased recently\n",
      "6 terrible neoprene simple retina leather son wanted poor leave stylish\n",
      "7 works campus basis slim installed free room fast due flaw\n",
      "8 ripped worn sliding half bad scratch packed drives accessory minimal\n",
      "9 mac wonderful shape week prefer replace cracked features hit plug\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topics_freq_tokens = [[idx_to_word[idx] for idx in topic_freq_idxs] for topic_freq_idxs in topics_freq_idxs]\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)\n",
    "\n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.tree_idxs, update_tree_flg = model.update_tree(topic_prob_topic, recur_prob_topic)\n",
    "                if update_tree_flg:\n",
    "                    print(config.tree_idxs)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = Model(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "display(log_df)\n",
    "print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
