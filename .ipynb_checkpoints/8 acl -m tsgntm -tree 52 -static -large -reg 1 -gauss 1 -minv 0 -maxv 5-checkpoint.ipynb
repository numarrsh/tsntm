{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from hntm import HierarchicalNeuralTopicModel\n",
    "from nhdp import nestedHierarchicalNeuralTopicModel\n",
    "from tsgntm import TreeStructuredGaussianNeuralTopicModel\n",
    "from tree import get_descendant_idxs\n",
    "from evaluation import get_hierarchical_affinity, get_topic_specialization, print_topic_sample\n",
    "from configure import get_config\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def debug(variable, sample_batch=None):\n",
    "    if sample_batch is None: sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch, mode='test')\n",
    "    _variable = sess.run(variable, feed_dict=feed_dict)\n",
    "    return _variable\n",
    "\n",
    "def check(variable):\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sample_batch = test_batches[0]\n",
    "    feed_dict = model.get_feed_dict(sample_batch, mode='test', assertion=True)\n",
    "    _variable = sess.run(variable, feed_dict=feed_dict)\n",
    "    return _variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "TopicModels = {'hntm': HierarchicalNeuralTopicModel, 'nhdp': nestedHierarchicalNeuralTopicModel, 'tsgntm': TreeStructuredGaussianNeuralTopicModel}\n",
    "TopicModel = TopicModels[config.model]\n",
    "model = TopicModel(config)\n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     24
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','','VALID:','','','','','','TEST:','', 'SPEC:', '', '', 'HIER:', ''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL', 'GAUSS', 'REG','LOSS','PPL','NLL','KL', 'GAUSS','REG','LOSS','PPL', '1', '2', '3', 'CHILD', 'OTHER']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))\n",
    "    \n",
    "def validate(sess, batches, model):\n",
    "    losses = []\n",
    "    ppl_list = []\n",
    "    prob_topic_list = []\n",
    "    n_bow_list = []\n",
    "    n_topics_list = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = model.get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_gauss_batch, topic_loss_reg_batch, ppls_batch, prob_topic_batch, n_bow_batch, n_topics_batch \\\n",
    "            = sess.run([model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_gauss, model.topic_loss_reg, model.topic_ppls, model.prob_topic, model.n_bow, model.n_topics], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_gauss_batch, topic_loss_reg_batch]]\n",
    "        ppl_list += list(ppls_batch)\n",
    "        prob_topic_list.append(prob_topic_batch)\n",
    "        n_bow_list.append(n_bow_batch)\n",
    "        n_topics_list.append(n_topics_batch)\n",
    "    loss_mean, topic_loss_recon_mean, topic_loss_kl_mean, topic_loss_gauss_mean, topic_loss_reg_mean = np.mean(losses, 0)\n",
    "    ppl_mean = np.exp(np.mean(ppl_list))\n",
    "    \n",
    "    probs_topic = np.concatenate(prob_topic_list, 0)\n",
    "    \n",
    "    n_bow = np.concatenate(n_bow_list, 0)\n",
    "    n_topics = np.concatenate(n_topics_list, 0)\n",
    "    probs_topic_mean = np.sum(n_topics, 0) / np.sum(n_bow)\n",
    "    \n",
    "    return loss_mean, topic_loss_recon_mean, topic_loss_kl_mean, topic_loss_gauss_mean, topic_loss_reg_mean, ppl_mean, probs_topic_mean    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "      <th>SPEC:</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "      <th>HIER:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>GAUSS</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>GAUSS</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>CHILD</th>\n",
       "      <th>OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>463</td>\n",
       "      <td>9308.31</td>\n",
       "      <td>2051</td>\n",
       "      <td>9272.20</td>\n",
       "      <td>12.70</td>\n",
       "      <td>23.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9268.46</td>\n",
       "      <td>1912</td>\n",
       "      <td>9220.11</td>\n",
       "      <td>16.56</td>\n",
       "      <td>31.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9267.50</td>\n",
       "      <td>1911</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>360</td>\n",
       "      <td>9250.27</td>\n",
       "      <td>1946</td>\n",
       "      <td>9205.92</td>\n",
       "      <td>15.48</td>\n",
       "      <td>28.70</td>\n",
       "      <td>0.19</td>\n",
       "      <td>9222.81</td>\n",
       "      <td>1838</td>\n",
       "      <td>9169.15</td>\n",
       "      <td>18.70</td>\n",
       "      <td>34.75</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9222.07</td>\n",
       "      <td>1837</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>79</td>\n",
       "      <td>26</td>\n",
       "      <td>257</td>\n",
       "      <td>9220.39</td>\n",
       "      <td>1896</td>\n",
       "      <td>9172.61</td>\n",
       "      <td>16.74</td>\n",
       "      <td>30.88</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9206.39</td>\n",
       "      <td>1814</td>\n",
       "      <td>9151.65</td>\n",
       "      <td>19.42</td>\n",
       "      <td>35.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9206.40</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>154</td>\n",
       "      <td>9201.86</td>\n",
       "      <td>1866</td>\n",
       "      <td>9152.31</td>\n",
       "      <td>17.47</td>\n",
       "      <td>31.97</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9195.00</td>\n",
       "      <td>1797</td>\n",
       "      <td>9140.08</td>\n",
       "      <td>19.63</td>\n",
       "      <td>35.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>9196.63</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TRAIN:                                      VALID:  \\\n",
       "      Time  Ep   Ct     LOSS   PPL      NLL     KL  GAUSS   REG     LOSS   \n",
       "5000    82   8  463  9308.31  2051  9272.20  12.70  23.18  0.22  9268.46   \n",
       "10000   74  17  360  9250.27  1946  9205.92  15.48  28.70  0.19  9222.81   \n",
       "15000   79  26  257  9220.39  1896  9172.61  16.74  30.88  0.17  9206.39   \n",
       "20000   73  35  154  9201.86  1866  9152.31  17.47  31.97  0.17  9195.00   \n",
       "\n",
       "                                            TEST:       SPEC:              \\\n",
       "        PPL      NLL     KL  GAUSS   REG     LOSS   PPL     1     2     3   \n",
       "5000   1912  9220.11  16.56  31.65  0.15  9267.50  1911  0.21  0.20  0.32   \n",
       "10000  1838  9169.15  18.70  34.75  0.20  9222.07  1837  0.45  0.29  0.38   \n",
       "15000  1814  9151.65  19.42  35.20  0.12  9206.40  1814  0.24  0.33  0.41   \n",
       "20000  1797  9140.08  19.63  35.16  0.13  9196.63  1800  0.78  0.28  0.43   \n",
       "\n",
       "      HIER:        \n",
       "      CHILD OTHER  \n",
       "5000   0.74  0.50  \n",
       "10000  0.68  0.37  \n",
       "15000  0.58  0.32  \n",
       "20000  0.56  0.33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 R: 1.000 P: 0.034 speech dialogue user utterances utterance recognition spoken speaker speakers systems\n",
      "   1 R: 0.294 P: 0.075 features sentiment classification topic sentences dataset negative tweets positive scores\n",
      "     11 R: 0.079 P: 0.079 translation english source phrase target alignment sentences parallel translations languages\n",
      "     12 R: 0.140 P: 0.140 training models features learning performance vector feature embeddings neural trained\n",
      "   2 R: 0.244 P: 0.060 character error errors segmentation characters test chinese english speech correction\n",
      "     21 R: 0.073 P: 0.073 pos features morphological tags training tagging accuracy languages tag parser\n",
      "     22 R: 0.111 P: 0.111 similarity method features sense entity performance semantic precision context algorithm\n",
      "   3 R: 0.159 P: 0.028 user analysis systems specific terms research annotation texts evaluation process\n",
      "     31 R: 0.072 P: 0.072 annotation resources corpora texts tools languages linguistic annotations tool project\n",
      "     32 R: 0.059 P: 0.059 document documents question query terms questions answer term retrieval search\n",
      "   4 R: 0.142 P: 0.033 discourse human speaker event agent events utterance action participants dialogue\n",
      "     41 R: 0.041 P: 0.041 relations event relation semantic events knowledge temporal discourse concepts entities\n",
      "     42 R: 0.067 P: 0.067 verb verbs syntactic semantic noun argument analysis subject object predicate\n",
      "   5 R: 0.128 P: 0.018 rules input generation grammar rule form structure context natural level\n",
      "     51 R: 0.054 P: 0.054 structure rules grammar semantic representation structures form rule type lexical\n",
      "     52 R: 0.055 P: 0.055 tree algorithm node trees parsing nodes dependency parse parser graph\n",
      "[  0.15695739 -16.950466   -11.588828    -0.9157133   -5.2212324\n",
      "  -6.8077526  -41.91268    -45.8015     -33.17669    -39.06054\n",
      " -26.98734    -25.381393   -21.536129   -27.191952   -25.724644\n",
      " -29.484367  ]\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_gauss_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_gauss, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_gauss_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_gauss_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_gauss_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topic_freq_tokens = {topic_idx: [idx_to_word[idx] for idx in topic_freq_idxs] for topic_idx, topic_freq_idxs in zip(model.topic_idxs, topics_freq_idxs)}\n",
    "            topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "            descendant_idxs = {parent_idx: get_descendant_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "            recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in descendant_idxs.items()}\n",
    "            \n",
    "            depth_specs = get_topic_specialization(sess, model, instances_test)\n",
    "            hierarchical_affinities = get_hierarchical_affinity(sess, model)\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_gauss_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_gauss_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test, \\\n",
    "                    '%.2f'%depth_specs[1], '%.2f'%depth_specs[2], '%.2f'%depth_specs[3], \\\n",
    "                    '%.2f'%hierarchical_affinities[0], '%.2f'%hierarchical_affinities[1]],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_topic_sample(sess, model, topic_prob_topic=topic_prob_topic, recur_prob_topic=recur_prob_topic, topic_freq_tokens=topic_freq_tokens)\n",
    "            print(np.sum(debug(model.topic_logvars), 1))\n",
    "            \n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.tree_idxs, update_tree_flg = model.update_tree(topic_prob_topic, recur_prob_topic)\n",
    "                if update_tree_flg:\n",
    "                    print(config.tree_idxs)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = HierarchicalNeuralTopicModel(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "topic_freq_tokens = {topic_idx: [idx_to_word[idx] for idx in topic_freq_idxs] for topic_idx, topic_freq_idxs in zip(model.topic_idxs, topics_freq_idxs)}\n",
    "topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "descendant_idxs = {parent_idx: get_descendant_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in descendant_idxs.items()}\n",
    "display(log_df)\n",
    "print_topic_sample(sess, model, topic_prob_topic=topic_prob_topic, recur_prob_topic=recur_prob_topic, topic_freq_tokens=topic_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
