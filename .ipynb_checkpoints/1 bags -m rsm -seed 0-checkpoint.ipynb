{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from gsm import GaussianSoftmaxModel\n",
    "from rsm import RecurrentStickbreakingModel\n",
    "from evaluation import validate, print_flat_topic_sample\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    return _variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','VALID:','','','','','TEST:',''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG','LOSS','PPL']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "if config.model == 'gsm':\n",
    "    Model = GaussianSoftmaxModel\n",
    "elif config.model == 'rsm':\n",
    "    Model = RecurrentStickbreakingModel\n",
    "model = Model(config)    \n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "      <td>99</td>\n",
       "      <td>600.12</td>\n",
       "      <td>925</td>\n",
       "      <td>596.89</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>586.09</td>\n",
       "      <td>1065</td>\n",
       "      <td>582.68</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.08</td>\n",
       "      <td>586.31</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>24</td>\n",
       "      <td>601.01</td>\n",
       "      <td>925</td>\n",
       "      <td>597.35</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.10</td>\n",
       "      <td>574.02</td>\n",
       "      <td>968</td>\n",
       "      <td>570.27</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.06</td>\n",
       "      <td>574.07</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>38</td>\n",
       "      <td>85</td>\n",
       "      <td>124</td>\n",
       "      <td>599.19</td>\n",
       "      <td>920</td>\n",
       "      <td>595.28</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.08</td>\n",
       "      <td>575.08</td>\n",
       "      <td>960</td>\n",
       "      <td>570.91</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>574.86</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>40</td>\n",
       "      <td>114</td>\n",
       "      <td>49</td>\n",
       "      <td>598.95</td>\n",
       "      <td>916</td>\n",
       "      <td>594.85</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>572.73</td>\n",
       "      <td>958</td>\n",
       "      <td>568.60</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>572.85</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>39</td>\n",
       "      <td>142</td>\n",
       "      <td>149</td>\n",
       "      <td>598.22</td>\n",
       "      <td>914</td>\n",
       "      <td>593.98</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>572.17</td>\n",
       "      <td>942</td>\n",
       "      <td>567.78</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.04</td>\n",
       "      <td>572.00</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>42</td>\n",
       "      <td>171</td>\n",
       "      <td>74</td>\n",
       "      <td>597.72</td>\n",
       "      <td>911</td>\n",
       "      <td>593.39</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>572.94</td>\n",
       "      <td>947</td>\n",
       "      <td>568.53</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.06</td>\n",
       "      <td>572.00</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>44</td>\n",
       "      <td>199</td>\n",
       "      <td>174</td>\n",
       "      <td>597.64</td>\n",
       "      <td>909</td>\n",
       "      <td>593.23</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>571.86</td>\n",
       "      <td>941</td>\n",
       "      <td>567.28</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.07</td>\n",
       "      <td>572.01</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>42</td>\n",
       "      <td>228</td>\n",
       "      <td>99</td>\n",
       "      <td>597.05</td>\n",
       "      <td>908</td>\n",
       "      <td>592.58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>575.08</td>\n",
       "      <td>983</td>\n",
       "      <td>570.56</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.06</td>\n",
       "      <td>572.01</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TRAIN:                           VALID:                \\\n",
       "      Time   Ep   Ct    LOSS  PPL     NLL    KL   REG    LOSS   PPL     NLL   \n",
       "5000    41   28   99  600.12  925  596.89  3.11  0.12  586.09  1065  582.68   \n",
       "10000   39   57   24  601.01  925  597.35  3.55  0.10  574.02   968  570.27   \n",
       "15000   38   85  124  599.19  920  595.28  3.83  0.08  575.08   960  570.91   \n",
       "20000   40  114   49  598.95  916  594.85  4.02  0.08  572.73   958  568.60   \n",
       "25000   39  142  149  598.22  914  593.98  4.16  0.07  572.17   942  567.78   \n",
       "30000   42  171   74  597.72  911  593.39  4.26  0.07  572.94   947  568.53   \n",
       "35000   44  199  174  597.64  909  593.23  4.35  0.07  571.86   941  567.28   \n",
       "40000   42  228   99  597.05  908  592.58  4.41  0.07  575.08   983  570.56   \n",
       "\n",
       "                    TEST:        \n",
       "         KL   REG    LOSS   PPL  \n",
       "5000   3.33  0.08  586.31  1068  \n",
       "10000  3.68  0.06  574.07   968  \n",
       "15000  4.12  0.05  574.86   956  \n",
       "20000  4.08  0.05  572.85   957  \n",
       "25000  4.35  0.04  572.00   939  \n",
       "30000  4.35  0.06  572.00   939  \n",
       "35000  4.52  0.07  572.01   941  \n",
       "40000  4.46  0.06  572.01   941  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 use file get window drive thanks write work program problem\n",
      "1 game team play go player hockey get season win year\n",
      "2 one write say think people god know make article see\n",
      "3 people say israel turkish jews armenian one israeli armenians kill\n",
      "4 key use encryption chip system government information privacy clipper message\n",
      "5 space launch system nasa center university satellite include research use\n",
      "6 president go tax stephanopoulos think money say people make work\n",
      "7 food cause disease doctor get study patient article one medical\n",
      "8 people write government law state article right make rights case\n",
      "9 gun number man use homosexual crime drug rate gay child\n",
      "10 file gun firearm bill weapon law use house control handgun\n",
      "11 koresh fbi fire gun people say compound batf think go\n",
      "12 fire gun people compound tank one weapon gas say batf\n",
      "13 gun people weapon fire fbi think get use one police\n",
      "Diff: -0.000013\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topics_freq_tokens = [[idx_to_word[idx] for idx in topic_freq_idxs] for topic_freq_idxs in topics_freq_idxs]\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)\n",
    "\n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.n_topic, update_flg, diff = model.update_topic(sess, dev_batches)\n",
    "                print('Diff: %.6f' % diff)\n",
    "                if update_flg:\n",
    "                    print('Update to %i' % config.n_topic)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = Model(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "display(log_df)\n",
    "print_flat_topic_sample(sess, model, topics_freq_tokens=topics_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
