{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from hntm import HierarchicalNeuralTopicModel\n",
    "from tree import get_descendant_idxs\n",
    "from evaluation import validate, get_hierarchical_affinity, get_topic_specialization, print_topic_sample\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    return _variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','VALID:','','','','','TEST:','', 'SPEC:', '', '', 'HIER:', ''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG','LOSS','PPL', '1', '2', '3', 'CHILD', 'OTHER']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "model = HierarchicalNeuralTopicModel(config)\n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "      <th>SPEC:</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "      <th>HIER:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>CHILD</th>\n",
       "      <th>OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>111.45</td>\n",
       "      <td>491</td>\n",
       "      <td>110.45</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.91</td>\n",
       "      <td>459</td>\n",
       "      <td>102.65</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.12</td>\n",
       "      <td>457</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>111.07</td>\n",
       "      <td>473</td>\n",
       "      <td>109.80</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.68</td>\n",
       "      <td>443</td>\n",
       "      <td>102.20</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>101.92</td>\n",
       "      <td>445</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>110.86</td>\n",
       "      <td>463</td>\n",
       "      <td>109.44</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.68</td>\n",
       "      <td>439</td>\n",
       "      <td>102.03</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.78</td>\n",
       "      <td>438</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>110.72</td>\n",
       "      <td>456</td>\n",
       "      <td>109.19</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.60</td>\n",
       "      <td>433</td>\n",
       "      <td>101.83</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.76</td>\n",
       "      <td>434</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>110.60</td>\n",
       "      <td>450</td>\n",
       "      <td>108.97</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.38</td>\n",
       "      <td>424</td>\n",
       "      <td>101.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.60</td>\n",
       "      <td>426</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>110.51</td>\n",
       "      <td>446</td>\n",
       "      <td>108.81</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.32</td>\n",
       "      <td>420</td>\n",
       "      <td>101.35</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.62</td>\n",
       "      <td>426</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>55</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>110.44</td>\n",
       "      <td>442</td>\n",
       "      <td>108.67</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.32</td>\n",
       "      <td>418</td>\n",
       "      <td>101.25</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.53</td>\n",
       "      <td>421</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>110.38</td>\n",
       "      <td>439</td>\n",
       "      <td>108.56</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.28</td>\n",
       "      <td>418</td>\n",
       "      <td>101.23</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.51</td>\n",
       "      <td>421</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45000</th>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>110.32</td>\n",
       "      <td>437</td>\n",
       "      <td>108.45</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.19</td>\n",
       "      <td>413</td>\n",
       "      <td>101.06</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.38</td>\n",
       "      <td>415</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>110.27</td>\n",
       "      <td>434</td>\n",
       "      <td>108.37</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.15</td>\n",
       "      <td>412</td>\n",
       "      <td>101.02</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.36</td>\n",
       "      <td>415</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55000</th>\n",
       "      <td>55</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>110.23</td>\n",
       "      <td>432</td>\n",
       "      <td>108.29</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.09</td>\n",
       "      <td>411</td>\n",
       "      <td>100.91</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.41</td>\n",
       "      <td>414</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TRAIN:                           VALID:               \\\n",
       "      Time   Ep   Ct    LOSS  PPL     NLL    KL   REG    LOSS  PPL     NLL   \n",
       "5000    57   10    9  111.45  491  110.45  1.00  0.01  103.91  459  102.65   \n",
       "10000   51   20   19  111.07  473  109.80  1.25  0.01  103.68  443  102.20   \n",
       "15000   51   30   29  110.86  463  109.44  1.41  0.01  103.68  439  102.03   \n",
       "20000   49   40   39  110.72  456  109.19  1.52  0.01  103.60  433  101.83   \n",
       "25000   51   50   49  110.60  450  108.97  1.62  0.01  103.38  424  101.47   \n",
       "30000   49   60   59  110.51  446  108.81  1.69  0.01  103.32  420  101.35   \n",
       "35000   55   70   69  110.44  442  108.67  1.76  0.01  103.32  418  101.25   \n",
       "40000   50   80   79  110.38  439  108.56  1.81  0.01  103.28  418  101.23   \n",
       "45000   55   90   89  110.32  437  108.45  1.86  0.01  103.19  413  101.06   \n",
       "50000   50  100   99  110.27  434  108.37  1.90  0.01  103.15  412  101.02   \n",
       "55000   55  110  109  110.23  432  108.29  1.94  0.01  103.09  411  100.91   \n",
       "\n",
       "                    TEST:      SPEC:             HIER:        \n",
       "         KL   REG    LOSS  PPL     1     2     3 CHILD OTHER  \n",
       "5000   1.25  0.01  102.12  457  0.32  0.43  0.48  0.58  0.34  \n",
       "10000  1.48  0.01  101.92  445  0.30  0.61  0.52  0.35  0.19  \n",
       "15000  1.65  0.00  101.78  438  0.31  0.61  0.50  0.32  0.18  \n",
       "20000  1.77  0.00  101.76  434  0.33  0.65  0.54  0.24  0.14  \n",
       "25000  1.92  0.00  101.60  426  0.33  0.64  0.56  0.25  0.12  \n",
       "30000  1.96  0.00  101.62  426  0.31  0.69  0.58  0.21  0.11  \n",
       "35000  2.07  0.00  101.53  421  0.31  0.65  0.58  0.26  0.11  \n",
       "40000  2.05  0.00  101.51  421  0.31  0.70  0.60  0.19  0.09  \n",
       "45000  2.13  0.00  101.38  415  0.29  0.65  0.57  0.23  0.10  \n",
       "50000  2.12  0.00  101.36  415  0.30  0.68  0.59  0.20  0.09  \n",
       "55000  2.17  0.00  101.41  414  0.31  0.66  0.61  0.23  0.10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 R: 1.000 P: 0.386 carry pockets strap room back shoulder work space ! nice\n",
      "   1 R: 0.224 P: 0.098 pocket inch charger power netbook mouse cord ipad room small\n",
      "     11 R: 0.050 P: 0.050 ; & perfect bought ! price perfectly loves size quality\n",
      "     14 R: 0.044 P: 0.044 price ordered quality item arrived received amazon bought shipping happy\n",
      "     12 R: 0.033 P: 0.033 return $ amazon item ... received money reviews ? buy\n",
      "   2 R: 0.158 P: 0.068 sleeve protection inside air neoprene snug padding zipper material protect\n",
      "     23 R: 0.044 P: 0.044 ! love color cute absolutely perfect ... awesome recommend super\n",
      "     21 R: 0.046 P: 0.046 pro mac air perfectly smell protects retina protect recommend book\n",
      "   4 R: 0.142 P: 0.046 protection air protect scratches : mbp - hard thin nice\n",
      "     41 R: 0.053 P: 0.053 cover color keyboard apple love ! screen hard easy blue\n",
      "     42 R: 0.043 P: 0.043 cover bottom hard speck mac shell plastic nice easily scratches\n",
      "   5 R: 0.090 P: 0.034 zipper months broke design cheap tear side zippers stitching weeks\n",
      "     51 R: 0.056 P: 0.056 bottom top back part months piece corners plastic bought broke\n",
      "{0: [1, 2, 4, 5, 3], 1: [13], 2: [22], 4: [41], 5: [51], 3: [31]}\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topic_freq_tokens = {topic_idx: [idx_to_word[idx] for idx in topic_freq_idxs] for topic_idx, topic_freq_idxs in zip(model.topic_idxs, topics_freq_idxs)}\n",
    "            topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "            descendant_idxs = {parent_idx: get_descendant_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "            recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in descendant_idxs.items()}\n",
    "            \n",
    "            depth_specs = get_topic_specialization(sess, model, instances_test)\n",
    "            hierarchical_affinities = get_hierarchical_affinity(sess, model)\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test, \\\n",
    "                    '%.2f'%depth_specs[1], '%.2f'%depth_specs[2], '%.2f'%depth_specs[3], \\\n",
    "                    '%.2f'%hierarchical_affinities[0], '%.2f'%hierarchical_affinities[1]],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_topic_sample(sess, model, topic_prob_topic=topic_prob_topic, recur_prob_topic=recur_prob_topic, topic_freq_tokens=topic_freq_tokens)\n",
    "\n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.tree_idxs, update_tree_flg = model.update_tree(topic_prob_topic, recur_prob_topic)\n",
    "                if update_tree_flg:\n",
    "                    print(config.tree_idxs)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = HierarchicalNeuralTopicModel(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, rads_bow_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "topic_freq_tokens = {topic_idx: [idx_to_word[idx] for idx in topic_freq_idxs] for topic_idx, topic_freq_idxs in zip(model.topic_idxs, topics_freq_idxs)}\n",
    "topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "descendant_idxs = {parent_idx: get_descendant_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in descendant_idxs.items()}\n",
    "display(log_df)\n",
    "cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "print_topic_sample(sess, model, topic_prob_topic=topic_prob_topic, recur_prob_topic=recur_prob_topic, topic_freq_tokens=topic_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
