{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import pdb\n",
    "import _pickle as cPickle\n",
    "import time\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from rcrp import Topic, Doc, init, sample, get_perplexity, get_topic_specialization, get_hierarchical_affinities, get_freq_tokens_rcrp, get_docs\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load config & data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31943, 1035)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.n_doc = len(instances_train)\n",
    "config.n_vocab = len(bow_idxs)\n",
    "config.n_doc, config.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568401"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bow = [instance.bow for instance in instances_train]\n",
    "docs_raw = [[[bow_index]*int(doc_bow[bow_index]) for bow_index in np.where(doc_bow > 0)[0]] for doc_bow in docs_bow]\n",
    "docs_words = [[idx for idxs in doc for idx in idxs] for doc in docs_raw]\n",
    "np.sum([len(doc_words) for doc_words in docs_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','VALID:','TEST:','SPEC:', '', '', 'HIER:', ''],\n",
    "                            ['Time','Ep','Ct','PPL','PPL', 'PPL','1', '2', '3', 'CHILD', 'OTHER']]))))\n",
    "\n",
    "def update_checkpoint(config, checkpoint, epoch):\n",
    "    checkpoint.append(config.path_model + '-%i' % epoch)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0)\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_root = Topic(idx='0', sibling_idx=0, parent=None, depth=1, config=config)\n",
    "train_docs = get_docs(instances_train, config, topic_root=topic_root)\n",
    "dev_docs = get_docs(instances_dev, config, topic_root=topic_root)\n",
    "test_docs = get_docs(instances_test, config, topic_root=topic_root)\n",
    "init(train_docs, dev_docs, test_docs, topic_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    sample(train_docs, dev_docs, test_docs, topic_root)\n",
    "#     ppl_train = get_perplexity(train_docs, topic_root)\n",
    "    ppl_train = 0\n",
    "    ppl_dev = get_perplexity(dev_docs, topic_root)\n",
    "    \n",
    "    if ppl_dev < ppl_min:\n",
    "        ppl_min = ppl_dev\n",
    "        ppl_test = get_perplexity(test_docs, topic_root)\n",
    "        cPickle.dump([test_docs, topic_root], open(config.path_model + '-%i'%epoch, 'wb'))\n",
    "        update_checkpoint(config, checkpoint, epoch)\n",
    "        \n",
    "    depth_spec = get_topic_specialization(test_docs, topic_root)\n",
    "    hierarchical_affinities = get_hierarchical_affinities(topic_root)\n",
    "    \n",
    "    clear_output()\n",
    "    time_log = int(time.time() - time_start)\n",
    "    time_start = time.time()\n",
    "    log_series = pd.Series([time_log, epoch, 0, \\\n",
    "            '%.0f'%ppl_train, '%.0f'%ppl_dev, '%.0f'%ppl_test, \\\n",
    "            '%.2f'%depth_spec[1], '%.2f'%depth_spec[2] if 2 in depth_spec else 0, '%.2f'%depth_spec[3] if 3 in depth_spec else 0, \\\n",
    "            '%.2f'%hierarchical_affinities[0], '%.2f'%hierarchical_affinities[1]],\n",
    "            index=log_df.columns)\n",
    "    log_df.loc[epoch] = log_series\n",
    "    display(log_df)\n",
    "    get_freq_tokens_rcrp(topic_root, idx_to_word, bow_idxs)\n",
    "    \n",
    "    cPickle.dump(log_df, open(config.path_log, 'wb'))\n",
    "    epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
