{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_structure import get_batches\n",
    "from hntm import HierarchicalNeuralTopicModel\n",
    "from tree import get_descendant_idxs\n",
    "from evaluation import validate, get_hierarchical_affinity, get_topic_specialization, print_topic_sample\n",
    "from configure import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.path_data,'rb'))\n",
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)\n",
    "config.dim_bow = len(bow_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables, model):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, model, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = model.get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    return _variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "ppl_min = np.inf\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "\n",
    "log_df = pd.DataFrame(columns=pd.MultiIndex.from_tuples(\n",
    "                    list(zip(*[['','','','TRAIN:','','','','','VALID:','','','','','TEST:','', 'SPEC:', '', '', 'HIER:', ''],\n",
    "                            ['Time','Ep','Ct','LOSS','PPL','NLL','KL','REG','LOSS','PPL','NLL','KL','REG','LOSS','PPL', '1', '2', '3', 'CHILD', 'OTHER']]))))\n",
    "\n",
    "cmd_rm = 'rm -r %s' % config.dir_model\n",
    "res = subprocess.call(cmd_rm.split())\n",
    "cmd_mk = 'mkdir %s' % config.dir_model\n",
    "res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "def update_checkpoint(config, checkpoint, global_step):\n",
    "    checkpoint.append(config.path_model + '-%i' % global_step)\n",
    "    if len(checkpoint) > config.max_to_keep:\n",
    "        path_model = checkpoint.pop(0) + '.*'\n",
    "        for p in glob.glob(path_model):\n",
    "            os.remove(p)\n",
    "    cPickle.dump(checkpoint, open(config.path_checkpoint, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "model = HierarchicalNeuralTopicModel(config)\n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n",
    "update_tree_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train & validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>TRAIN:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>VALID:</th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>TEST:</th>\n",
       "      <th></th>\n",
       "      <th>SPEC:</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "      <th>HIER:</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Ep</th>\n",
       "      <th>Ct</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>NLL</th>\n",
       "      <th>KL</th>\n",
       "      <th>REG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>PPL</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>CHILD</th>\n",
       "      <th>OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>463</td>\n",
       "      <td>9551.79</td>\n",
       "      <td>1805</td>\n",
       "      <td>9530.96</td>\n",
       "      <td>20.58</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9385.05</td>\n",
       "      <td>1767</td>\n",
       "      <td>9363.43</td>\n",
       "      <td>21.45</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9386.53</td>\n",
       "      <td>1769</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>360</td>\n",
       "      <td>9517.58</td>\n",
       "      <td>1757</td>\n",
       "      <td>9496.25</td>\n",
       "      <td>21.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>9364.63</td>\n",
       "      <td>1739</td>\n",
       "      <td>9343.68</td>\n",
       "      <td>20.79</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9365.23</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>62</td>\n",
       "      <td>26</td>\n",
       "      <td>257</td>\n",
       "      <td>9501.80</td>\n",
       "      <td>1735</td>\n",
       "      <td>9480.44</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9360.49</td>\n",
       "      <td>1732</td>\n",
       "      <td>9339.33</td>\n",
       "      <td>21.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9361.26</td>\n",
       "      <td>1733</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "      <td>154</td>\n",
       "      <td>9492.68</td>\n",
       "      <td>1723</td>\n",
       "      <td>9471.28</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9357.52</td>\n",
       "      <td>1729</td>\n",
       "      <td>9336.33</td>\n",
       "      <td>21.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9358.46</td>\n",
       "      <td>1730</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>62</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>9486.44</td>\n",
       "      <td>1715</td>\n",
       "      <td>9465.05</td>\n",
       "      <td>21.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9356.10</td>\n",
       "      <td>1726</td>\n",
       "      <td>9335.26</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9355.85</td>\n",
       "      <td>1726</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485000</th>\n",
       "      <td>65</td>\n",
       "      <td>855</td>\n",
       "      <td>214</td>\n",
       "      <td>9450.35</td>\n",
       "      <td>1669</td>\n",
       "      <td>9431.09</td>\n",
       "      <td>19.47</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9351.62</td>\n",
       "      <td>1720</td>\n",
       "      <td>9332.99</td>\n",
       "      <td>18.55</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9349.65</td>\n",
       "      <td>1718</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490000</th>\n",
       "      <td>67</td>\n",
       "      <td>864</td>\n",
       "      <td>111</td>\n",
       "      <td>9450.29</td>\n",
       "      <td>1669</td>\n",
       "      <td>9431.02</td>\n",
       "      <td>19.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9351.19</td>\n",
       "      <td>1720</td>\n",
       "      <td>9332.54</td>\n",
       "      <td>18.57</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9349.65</td>\n",
       "      <td>1718</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495000</th>\n",
       "      <td>66</td>\n",
       "      <td>873</td>\n",
       "      <td>8</td>\n",
       "      <td>9450.22</td>\n",
       "      <td>1669</td>\n",
       "      <td>9430.95</td>\n",
       "      <td>19.45</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9351.60</td>\n",
       "      <td>1720</td>\n",
       "      <td>9332.94</td>\n",
       "      <td>18.58</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9349.65</td>\n",
       "      <td>1718</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500000</th>\n",
       "      <td>67</td>\n",
       "      <td>881</td>\n",
       "      <td>472</td>\n",
       "      <td>9450.17</td>\n",
       "      <td>1669</td>\n",
       "      <td>9430.89</td>\n",
       "      <td>19.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9351.23</td>\n",
       "      <td>1720</td>\n",
       "      <td>9332.62</td>\n",
       "      <td>18.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9349.65</td>\n",
       "      <td>1718</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505000</th>\n",
       "      <td>67</td>\n",
       "      <td>890</td>\n",
       "      <td>369</td>\n",
       "      <td>9450.12</td>\n",
       "      <td>1669</td>\n",
       "      <td>9430.84</td>\n",
       "      <td>19.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9352.60</td>\n",
       "      <td>1721</td>\n",
       "      <td>9333.99</td>\n",
       "      <td>18.54</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9349.65</td>\n",
       "      <td>1718</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TRAIN:                               VALID:        \\\n",
       "       Time   Ep   Ct     LOSS   PPL      NLL     KL   REG     LOSS   PPL   \n",
       "5000     66    8  463  9551.79  1805  9530.96  20.58  0.22  9385.05  1767   \n",
       "10000    62   17  360  9517.58  1757  9496.25  21.07  0.19  9364.63  1739   \n",
       "15000    62   26  257  9501.80  1735  9480.44  21.16  0.18  9360.49  1732   \n",
       "20000    63   35  154  9492.68  1723  9471.28  21.16  0.17  9357.52  1729   \n",
       "25000    62   44   51  9486.44  1715  9465.05  21.11  0.16  9356.10  1726   \n",
       "...     ...  ...  ...      ...   ...      ...    ...   ...      ...   ...   \n",
       "485000   65  855  214  9450.35  1669  9431.09  19.47  0.10  9351.62  1720   \n",
       "490000   67  864  111  9450.29  1669  9431.02  19.46  0.10  9351.19  1720   \n",
       "495000   66  873    8  9450.22  1669  9430.95  19.45  0.10  9351.60  1720   \n",
       "500000   67  881  472  9450.17  1669  9430.89  19.44  0.10  9351.23  1720   \n",
       "505000   67  890  369  9450.12  1669  9430.84  19.44  0.10  9352.60  1721   \n",
       "\n",
       "                                TEST:       SPEC:             HIER:        \n",
       "            NLL     KL   REG     LOSS   PPL     1     2     3 CHILD OTHER  \n",
       "5000    9363.43  21.45  0.17  9386.53  1769  0.37  0.40  0.39  0.38  0.31  \n",
       "10000   9343.68  20.79  0.16  9365.23  1740  0.42  0.41  0.39  0.37  0.30  \n",
       "15000   9339.33  21.01  0.15  9361.26  1733  0.43  0.42  0.39  0.37  0.29  \n",
       "20000   9336.33  21.04  0.14  9358.46  1730  0.45  0.42  0.41  0.36  0.28  \n",
       "25000   9335.26  20.70  0.14  9355.85  1726  0.45  0.42  0.40  0.36  0.28  \n",
       "...         ...    ...   ...      ...   ...   ...   ...   ...   ...   ...  \n",
       "485000  9332.99  18.55  0.08  9349.65  1718  0.45  0.42  0.42  0.35  0.28  \n",
       "490000  9332.54  18.57  0.08  9349.65  1718  0.46  0.42  0.41  0.35  0.28  \n",
       "495000  9332.94  18.58  0.08  9349.65  1718  0.45  0.42  0.41  0.35  0.28  \n",
       "500000  9332.62  18.53  0.08  9349.65  1718  0.45  0.43  0.41  0.34  0.28  \n",
       "505000  9333.99  18.54  0.08  9349.65  1718  0.46  0.42  0.42  0.34  0.28  \n",
       "\n",
       "[101 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 R: 1.000 P: 0.089 translation english source alignment target phrase sentences pairs systems translations\n",
      "   1 R: 0.240 P: 0.077 text annotation resources user project linguistic tools database research tool\n",
      "     11 R: 0.088 P: 0.088 document documents text question topic query sentences answer terms questions\n",
      "     12 R: 0.074 P: 0.074 semantic sense similarity lexical wordnet senses context noun verb method\n",
      "   2 R: 0.211 P: 0.065 speech study speakers text number time speaker texts annotation analysis\n",
      "     21 R: 0.065 P: 0.065 sentiment classification feature classifier task positive negative tweets text analysis\n",
      "     22 R: 0.081 P: 0.081 pos morphological character segmentation languages errors tags chinese tag tagging\n",
      "   3 R: 0.229 P: 0.058 dialogue user utterance utterances speech human task systems figure recognition\n",
      "     31 R: 0.058 P: 0.058 models embeddings network vector neural training vectors representations task representation\n",
      "     32 R: 0.113 P: 0.113 training models algorithm learning feature performance probability number method test\n",
      "   4 R: 0.231 P: 0.085 semantic verb structure case syntactic lexical type verbs clause discourse\n",
      "     41 R: 0.068 P: 0.068 relation relations event entity annotation semantic entities argument task annotated\n",
      "     42 R: 0.078 P: 0.078 tree parsing dependency parser grammar rules node trees parse rule\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "while epoch < config.n_epochs:\n",
    "    # train\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = model.get_feed_dict(batch)\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, ppls_batch, global_step_log = \\\n",
    "        sess.run([model.opt, model.loss, model.topic_loss_recon, model.topic_loss_kl, model.topic_loss_reg, model.topic_ppls, tf.train.get_global_step()], feed_dict = feed_dict)\n",
    "\n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if global_step_log % config.log_period == 0:\n",
    "            # validate\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "\n",
    "            # test\n",
    "            if ppl_dev < ppl_min:\n",
    "                ppl_min = ppl_dev\n",
    "                loss_test, _, _, _, ppl_test, _ = validate(sess, test_batches, model)\n",
    "                saver.save(sess, config.path_model, global_step=global_step_log)\n",
    "                cPickle.dump(config, open(config.path_config % global_step_log, 'wb'))\n",
    "                update_checkpoint(config, checkpoint, global_step_log)\n",
    "            \n",
    "            # visualize topic\n",
    "            topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "            topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "            topic_freq_tokens = {topic_idx: [idx_to_word[idx] for idx in topic_freq_idxs] for topic_idx, topic_freq_idxs in zip(model.topic_idxs, topics_freq_idxs)}\n",
    "            topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "            descendant_idxs = {parent_idx: get_descendant_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "            recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in descendant_idxs.items()}\n",
    "            \n",
    "            depth_specs = get_topic_specialization(sess, model, instances_test)\n",
    "            hierarchical_affinities = get_hierarchical_affinity(sess, model)\n",
    "            \n",
    "            # log\n",
    "            clear_output()\n",
    "            time_log = int(time.time() - time_start)\n",
    "            log_series = pd.Series([time_log, epoch, ct, \\\n",
    "                    '%.2f'%loss_train, '%.0f'%ppl_train, '%.2f'%topic_loss_recon_train, '%.2f'%topic_loss_kl_train, '%.2f'%topic_loss_reg_train, \\\n",
    "                    '%.2f'%loss_dev, '%.0f'%ppl_dev, '%.2f'%topic_loss_recon_dev, '%.2f'%topic_loss_kl_dev, '%.2f'%topic_loss_reg_dev, \\\n",
    "                    '%.2f'%loss_test, '%.0f'%ppl_test, \\\n",
    "                    '%.2f'%depth_specs[1], '%.2f'%depth_specs[2], '%.2f'%depth_specs[3], \\\n",
    "                    '%.2f'%hierarchical_affinities[0], '%.2f'%hierarchical_affinities[1]],\n",
    "                    index=log_df.columns)\n",
    "            log_df.loc[global_step_log] = log_series\n",
    "            display(log_df)\n",
    "            cPickle.dump(log_df, open(os.path.join(config.path_log), 'wb'))\n",
    "            print_topic_sample(sess, model, topic_prob_topic=topic_prob_topic, recur_prob_topic=recur_prob_topic, topic_freq_tokens=topic_freq_tokens)\n",
    "\n",
    "            # update tree\n",
    "            if not config.static:\n",
    "                config.tree_idxs, update_tree_flg = model.update_tree(topic_prob_topic, recur_prob_topic)\n",
    "                if update_tree_flg:\n",
    "                    print(config.tree_idxs)\n",
    "                    name_variables = {tensor.name: variable for tensor, variable in zip(tf.global_variables(), sess.run(tf.global_variables()))} # store paremeters\n",
    "                    if 'sess' in globals(): sess.close()\n",
    "                    model = HierarchicalNeuralTopicModel(config)\n",
    "                    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1))\n",
    "                    name_tensors = {tensor.name: tensor for tensor in tf.global_variables()}\n",
    "                    sess.run([name_tensors[name].assign(variable) for name, variable in name_variables.items()]) # restore parameters\n",
    "                    saver = tf.train.Saver(max_to_keep=1)\n",
    "                \n",
    "            time_start = time.time()\n",
    "\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "    epoch += 1\n",
    "\n",
    "loss_dev, topic_loss_recon_dev, topic_loss_kl_dev, topic_loss_reg_dev, ppl_dev, probs_topic_dev = validate(sess, dev_batches, model)\n",
    "topics_freq_indices = np.argsort(sess.run(model.topic_bow), 1)[:, ::-1][:, :config.n_freq]\n",
    "topics_freq_idxs = bow_idxs[topics_freq_indices]\n",
    "topic_freq_tokens = {topic_idx: [idx_to_word[idx] for idx in topic_freq_idxs] for topic_idx, topic_freq_idxs in zip(model.topic_idxs, topics_freq_idxs)}\n",
    "topic_prob_topic = {topic_idx: prob_topic for topic_idx, prob_topic in zip(model.topic_idxs, probs_topic_dev)}\n",
    "descendant_idxs = {parent_idx: get_descendant_idxs(model, parent_idx) for parent_idx in model.topic_idxs}\n",
    "recur_prob_topic = {parent_idx: np.sum([topic_prob_topic[child_idx] for child_idx in recur_child_idxs]) for parent_idx, recur_child_idxs in descendant_idxs.items()}\n",
    "display(log_df)\n",
    "print_topic_sample(sess, model, topic_prob_topic=topic_prob_topic, recur_prob_topic=recur_prob_topic, topic_freq_tokens=topic_freq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
