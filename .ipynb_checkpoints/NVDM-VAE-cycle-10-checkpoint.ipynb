{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pdb\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from six.moves import zip_longest\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import distributions as tfd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from data_structure import get_batches\n",
    "from components import tf_log, sample_latents, compute_kl_loss, dynamic_rnn, dynamic_bi_rnn\n",
    "from topic_model import TopicModel\n",
    "\n",
    "from topic_beam_search_decoder import BeamSearchDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNK = '<unk>' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "BOS = '<p>' # This has a vocab id, which is used at the beginning of every decoder input sequence\n",
    "EOS = '</p>' # This has a vocab id, which is used at the end of untruncated target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('gpu', '4', 'visible gpu')\n",
    "\n",
    "flags.DEFINE_string('mode', 'train', 'set train or eval')\n",
    "\n",
    "flags.DEFINE_string('data_path', 'data/apnews/instances.pkl', 'path of data')\n",
    "flags.DEFINE_string('modeldir', 'model/nvdm_vae', 'directory of model')\n",
    "flags.DEFINE_string('modelname', 'apnews', 'name of model')\n",
    "\n",
    "flags.DEFINE_integer('epochs', 50, 'epochs')\n",
    "flags.DEFINE_integer('batch_size', 64, 'number of sentences in each batch')\n",
    "flags.DEFINE_integer('log_period', 500, 'valid period')\n",
    "\n",
    "flags.DEFINE_string('opt', 'Adagrad', 'optimizer')\n",
    "flags.DEFINE_float('lr', 0.1, 'lr')\n",
    "flags.DEFINE_float('reg', 1., 'regularization term')\n",
    "flags.DEFINE_float('grad_clip', 5., 'grad_clip')\n",
    "\n",
    "flags.DEFINE_float('keep_prob', 0.8, 'dropout rate')\n",
    "flags.DEFINE_float('word_keep_prob', 0.75, 'word dropout rate')\n",
    "\n",
    "flags.DEFINE_bool('warmup', True, 'flg of warming up')\n",
    "flags.DEFINE_integer('epochs_cycle', 10, 'number of epochs within a cycle')\n",
    "flags.DEFINE_float('r_cycle', 0.5, 'proportion used to increase beta within a cycle')\n",
    "flags.DEFINE_integer('warmup_topic', 0, 'warmup period for KL of topic')\n",
    "\n",
    "flags.DEFINE_integer('beam_width', 2, 'beam_width')\n",
    "flags.DEFINE_float('length_penalty_weight', 0.0, 'length_penalty_weight')\n",
    "\n",
    "flags.DEFINE_integer('n_topic', 10, 'number of topic')\n",
    "flags.DEFINE_integer('dim_hidden_bow', 256, 'dim of hidden bow')\n",
    "flags.DEFINE_integer('dim_latent_bow', 32, 'dim of latent topic')\n",
    "flags.DEFINE_integer('dim_emb', 256, 'dim_emb')\n",
    "flags.DEFINE_integer('dim_hidden', 512, 'dim_hidden')\n",
    "flags.DEFINE_integer('dim_hidden_topic', 512, 'dim_hidden_topic')\n",
    "flags.DEFINE_integer('dim_latent', 32, 'dim_latent')\n",
    "flags.DEFINE_bool('bidirectional', True, 'flg of bidirectional encoding')\n",
    "\n",
    "# for evaluation\n",
    "flags.DEFINE_string('refdir', 'ref', 'refdir')\n",
    "flags.DEFINE_string('outdir', 'out', 'outdir')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_bool('logtostderr', True, 'kernel')\n",
    "flags.DEFINE_bool('showprefixforinfo', False, '')\n",
    "flags.DEFINE_bool('verbosity', False, '')\n",
    "# flags.DEFINE_integer('stderrthreshold', 20, 'kernel')\n",
    "\n",
    "config = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('modelpath', os.path.join(config.modeldir, config.modelname), 'path of model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train, instances_dev, instances_test, word_to_idx, idx_to_word, bow_idxs = cPickle.load(open(config.data_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = get_batches(instances_train, config.batch_size)\n",
    "dev_batches = get_batches(instances_dev, config.batch_size)\n",
    "test_batches = get_batches(instances_test, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_integer('PAD_IDX', word_to_idx[PAD], 'PAD_IDX')\n",
    "flags.DEFINE_integer('UNK_IDX', word_to_idx[UNK], 'UNK_IDX')\n",
    "flags.DEFINE_integer('BOS_IDX', word_to_idx[BOS], 'BOS_IDX')\n",
    "flags.DEFINE_integer('EOS_IDX', word_to_idx[EOS], 'EOS_IDX')\n",
    "\n",
    "flags.DEFINE_integer('n_vocab', len(word_to_idx), 'n_vocab')\n",
    "flags.DEFINE_integer('dim_bow', len(bow_idxs), 'dim_bow')\n",
    "\n",
    "maximum_iterations = max([max([instance.max_sent_l for instance in batch]) for ct, batch in dev_batches])\n",
    "flags.DEFINE_integer('maximum_iterations', maximum_iterations, 'maximum_iterations')\n",
    "\n",
    "flags.DEFINE_integer('cycle_steps', len(train_batches)*config.epochs_cycle, 'number of steps for each cycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build language model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "t_variables = {}\n",
    "t_variables['bow'] = tf.placeholder(tf.float32, [None, config.dim_bow], name='bow')\n",
    "t_variables['input_token_idxs'] = tf.placeholder(tf.int32, [None, None], name='input_token_idxs')\n",
    "t_variables['dec_input_idxs'] = tf.placeholder(tf.int32, [None, None], name='dec_input_idxs')\n",
    "t_variables['dec_target_idxs'] = tf.placeholder(tf.int32, [None, None], name='dec_target_idxs')\n",
    "t_variables['batch_l'] = tf.placeholder(tf.int32, name='batch_l')\n",
    "t_variables['doc_l'] = tf.placeholder(tf.int32, [None], name='doc_l')\n",
    "t_variables['sent_l'] = tf.placeholder(tf.int32, [None], name='sent_l')\n",
    "t_variables['keep_prob'] = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(batch, mode='train', assertion=False):\n",
    "    def token_dropout(sent_idxs):\n",
    "        sent_idxs_dropout = np.asarray(sent_idxs)\n",
    "        sent_idxs_dropout[np.random.rand(len(sent_idxs)) > config.word_keep_prob] = config.UNK_IDX\n",
    "        return list(sent_idxs_dropout)\n",
    "\n",
    "    bow = np.array([instance.bow for instance in batch]).astype(np.float32)\n",
    "    \n",
    "    doc_l = np.array([len(instance.token_idxs) for instance in batch])\n",
    "    \n",
    "    feed_input_token_idxs_list = [sent_idxs for instance in batch for sent_idxs in instance.token_idxs]\n",
    "    feed_dec_input_idxs_list = [[config.BOS_IDX] + token_dropout(sent_idxs) for sent_idxs in feed_input_token_idxs_list]\n",
    "    feed_dec_target_idxs_list = [sent_idxs + [config.EOS_IDX]  for sent_idxs in feed_input_token_idxs_list]\n",
    "        \n",
    "    sent_l = np.array([len(sent_idxs) for sent_idxs in feed_input_token_idxs_list], np.int32)\n",
    "    batch_l = len(sent_l)\n",
    "    \n",
    "    feed_input_token_idxs = pad_sequences(feed_input_token_idxs_list, padding='post', value=config.PAD_IDX, dtype=np.int32)\n",
    "    feed_dec_input_idxs = pad_sequences(feed_dec_input_idxs_list, padding='post', value=config.PAD_IDX, dtype=np.int32)\n",
    "    feed_dec_target_idxs = pad_sequences(feed_dec_target_idxs_list, padding='post', value=config.PAD_IDX, dtype=np.int32)\n",
    "    \n",
    "    if assertion:\n",
    "        index = 0\n",
    "        for instance in batch:\n",
    "            for line_idxs in instance.token_idxs:\n",
    "                assert feed_input_token_idxs_list[index] == line_idxs\n",
    "                index += 1\n",
    "        assert feed_input_token_idxs.shape[1] == np.max(sent_l)\n",
    "        assert feed_dec_input_idxs.shape[1] == np.max(sent_l) + 1\n",
    "        assert feed_dec_target_idxs.shape[1] == np.max(sent_l) + 1\n",
    "    \n",
    "    keep_prob = config.keep_prob if mode == 'train' else 1.0\n",
    "\n",
    "    feed_dict = {\n",
    "                t_variables['bow']: bow, \n",
    "                t_variables['batch_l']: batch_l, t_variables['doc_l']: doc_l, t_variables['sent_l']: sent_l, \n",
    "                t_variables['input_token_idxs']: feed_input_token_idxs, t_variables['dec_input_idxs']: feed_dec_input_idxs, t_variables['dec_target_idxs']: feed_dec_target_idxs, \n",
    "                t_variables['keep_prob']: keep_prob\n",
    "    }\n",
    "    return  feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0,
     10,
     24,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def debug_shape(variables):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "\n",
    "def debug_value(variables, return_value=False):\n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    if return_value: \n",
    "        return _variables\n",
    "    else:\n",
    "        for _variable, variable in zip(_variables, variables):\n",
    "            if hasattr(variable, 'name'):\n",
    "                print(variable.name, ':', _variable)\n",
    "            else:\n",
    "                print(_variable)\n",
    "                \n",
    "def check_shape(variables):\n",
    "    if 'sess' in globals(): raise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable.shape)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    sess.close()\n",
    "    \n",
    "def check_value(variables):\n",
    "    if 'sess' in globals(): raise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample_batch = test_batches[0][1]\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    _variables = sess.run(variables, feed_dict=feed_dict)\n",
    "    for _variable, variable in zip(_variables, variables):\n",
    "        if hasattr(variable, 'name'):\n",
    "            print(variable.name, ':', _variable)\n",
    "        else:\n",
    "            print(_variable.shape)\n",
    "            \n",
    "    sess.close()    \n",
    "    \n",
    "# sent_loss_kl_categ_tmp = tf.reduce_mean(tf.reduce_sum(tf.multiply(prob_topic_infer, tf_log(prob_topic_infer/prob_topic_sents)), 1))\n",
    "# debug_value([sent_loss_kl_categ, sent_loss_kl_categ_tmp])\n",
    "# sent_loss_kl_gauss_tmp = 0.5 * tf.reduce_sum(tf.exp(logvars_topic_infer-logvars_topic) + tf.square(means_topic - means_topic_infer) / tf.exp(logvars_topic) - 1 + (logvars_topic - logvars_topic_infer), -1)\n",
    "# sent_loss_kl_gmm_tmp = tf.reduce_mean(tf.reduce_sum(tf.multiply(prob_topic_infer, sent_loss_kl_gauss_tmp), -1))\n",
    "# debug_value([sent_loss_kl_gmm_tmp, sent_loss_kl_gmm])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encode bow\n",
    "with tf.variable_scope('topic/enc', reuse=False):\n",
    "    hidden_bow_ = tf.layers.Dense(units=config.dim_hidden_bow, activation=tf.nn.relu, name='hidden_bow')(t_variables['bow'])\n",
    "    hidden_bow = tf.layers.Dropout(t_variables['keep_prob'])(hidden_bow_)\n",
    "    means_bow = tf.layers.Dense(units=config.dim_latent_bow, name='mean_bow')(hidden_bow)\n",
    "    logvars_bow = tf.layers.Dense(units=config.dim_latent_bow, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0), name='logvar_topic')(hidden_bow)\n",
    "    latents_bow = sample_latents(means_bow, logvars_bow) # sample latent vectors\n",
    "\n",
    "    prob_topic = tf.layers.Dense(units=config.n_topic, activation=tf.nn.softmax, name='prob_topic')(latents_bow) # inference of topic probabilities\n",
    "\n",
    "# decode bow\n",
    "with tf.variable_scope('shared', reuse=False):\n",
    "    embeddings = tf.get_variable('emb', [config.n_vocab, config.dim_emb], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of vocab\n",
    "\n",
    "bow_embeddings = tf.nn.embedding_lookup(embeddings, bow_idxs) # embeddings of each bow features\n",
    "\n",
    "with tf.variable_scope('topic/dec', reuse=False):\n",
    "    topic_bow = tf.get_variable('topic_bow', [config.n_topic, config.dim_bow], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer()) # embeddings of topics\n",
    "    logits_bow = tf_log(tf.nn.softmax(tf.tensordot(prob_topic, topic_bow, axes=[[1], [0]]), 1))\n",
    "\n",
    "    # prior of each gaussian distribution (computed for each topic)\n",
    "    hidden_topic = tf.layers.Dense(units=config.dim_hidden_topic, activation=tf.nn.relu, name='hidden_topic')(topic_bow)\n",
    "    means_topic = tf.layers.Dense(units=config.dim_latent, name='mean_topic')(hidden_topic)\n",
    "    logvars_topic = tf.layers.Dense(units=config.dim_latent, kernel_initializer=tf.constant_initializer(0), bias_initializer=tf.constant_initializer(0), name='logvar_topic')(hidden_topic)\n",
    "    sigma_topic = tf.exp(0.5 * logvars_topic)\n",
    "    gauss_topic = tfd.Normal(loc=means_topic, scale=sigma_topic)    \n",
    "    \n",
    "# define losses\n",
    "topic_losses_recon = -tf.reduce_sum(tf.multiply(t_variables['bow'], logits_bow), 1)\n",
    "topic_loss_recon = tf.reduce_mean(topic_losses_recon) # negative log likelihood of each words\n",
    "\n",
    "topic_loss_kl = compute_kl_loss(means_bow, logvars_bow) # KL divergence b/w latent dist & gaussian std\n",
    "\n",
    "topic_bow_norm = topic_bow / tf.norm(topic_bow, axis=1, keepdims=True)\n",
    "topic_dots = tf.clip_by_value(tf.matmul(topic_bow_norm, tf.transpose(topic_bow_norm)), -1., 1.)\n",
    "topic_loss_reg = tf.reduce_mean(tf.square(topic_dots - tf.eye(config.n_topic)))\n",
    "# topic_angles = tf.acos(topic_dots)\n",
    "# topic_angles_mean = tf.reduce_mean(topic_angles)\n",
    "# topic_angles_vars = tf.reduce_mean(tf.square(topic_angles - topic_angles_mean))\n",
    "# topic_loss_reg = tf.exp(topic_angles_vars - topic_angles_mean)\n",
    "\n",
    "# monitor\n",
    "n_bow = tf.reduce_sum(t_variables['bow'], 1)\n",
    "topic_ppls = tf.divide(topic_losses_recon, n_bow)\n",
    "topics_freq_bow_indices = tf.nn.top_k(topic_bow, 10, name='topic_freq_bow').indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "input_token_idxs = t_variables['input_token_idxs']\n",
    "batch_l = t_variables['batch_l']\n",
    "sent_l = t_variables['sent_l']\n",
    "max_sent_l = tf.reduce_max(sent_l)\n",
    "\n",
    "with tf.variable_scope('sent/enc', reuse=False):\n",
    "    # get word embedding\n",
    "    enc_input = tf.nn.embedding_lookup(embeddings, input_token_idxs)\n",
    "\n",
    "    # get sentence embedding\n",
    "    _, enc_state = dynamic_bi_rnn(enc_input, sent_l, config.dim_hidden, t_variables['keep_prob'])\n",
    "\n",
    "    # TODO House Holder flow\n",
    "    hidden_topic_infer =  tf.layers.Dense(units=config.dim_hidden, activation=tf.nn.relu, name='hidden_topic_infer')(enc_state)\n",
    "    prob_topic_infer = tf.layers.Dense(units=config.n_topic, activation=tf.nn.softmax, name='prob_topic_infer')(hidden_topic_infer)\n",
    "\n",
    "    w_mean_topic_infer = tf.get_variable('mean_topic_infer/kernel', [config.n_topic, enc_state.shape[-1], config.dim_latent], dtype=tf.float32)\n",
    "    b_mean_topic_infer = tf.get_variable('mean_topic_infer/bias', [1, config.n_topic, config.dim_latent], dtype=tf.float32)\n",
    "    means_topic_infer = tf.tensordot(enc_state, w_mean_topic_infer, axes=[[1], [1]]) + b_mean_topic_infer\n",
    "    \n",
    "    w_logvar_topic_infer = tf.get_variable('logvar_topic_infer/kernel', [config.n_topic, enc_state.shape[-1], config.dim_latent], dtype=tf.float32, initializer=tf.constant_initializer(0))\n",
    "    b_logvar_topic_infer = tf.get_variable('logvar_topic_infer/bias', [1, config.n_topic, config.dim_latent], dtype=tf.float32, initializer=tf.constant_initializer(0))\n",
    "    logvars_topic_infer = tf.tensordot(enc_state, w_logvar_topic_infer, axes=[[1], [1]]) + b_logvar_topic_infer\n",
    "    sigma_topic_infer = tf.exp(0.5 * logvars_topic_infer)\n",
    "    gauss_topic_infer = tfd.Normal(loc=means_topic_infer, scale=sigma_topic_infer)\n",
    "    \n",
    "    # latent vectors from each gaussian dist.\n",
    "    latents_topic_infer = sample_latents(means_topic_infer, logvars_topic_infer) \n",
    "    # latent vector from gaussian mixture\n",
    "    latents_input = tf.matmul(tf.expand_dims(prob_topic_infer, -1), latents_topic_infer, transpose_a=True)\n",
    "    \n",
    "    # for beam search\n",
    "    means_input = tf.matmul(tf.expand_dims(prob_topic_infer, -1), means_topic_infer, transpose_a=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for decoding\n",
    "dec_sent_l = tf.add(sent_l, 1)\n",
    "dec_input_idxs = t_variables['dec_input_idxs']\n",
    "dec_input = tf.nn.embedding_lookup(embeddings, dec_input_idxs)\n",
    "\n",
    "dec_latents_input = tf.tile(latents_input, [1, tf.shape(dec_input)[1], 1])\n",
    "dec_concat_input = tf.concat([dec_input, dec_latents_input], -1)\n",
    "\n",
    "# decode for training\n",
    "with tf.variable_scope('sent/dec/rnn', initializer=tf.contrib.layers.xavier_initializer(), dtype = tf.float32, reuse=False):\n",
    "    dec_cell = tf.contrib.rnn.GRUCell(config.dim_hidden)\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, output_keep_prob = t_variables['keep_prob'])\n",
    "\n",
    "    dec_initial_state = tf.layers.Dense(units=config.dim_hidden, activation=tf.nn.relu, name='init_state')(tf.squeeze(latents_input, 1))\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_concat_input, sequence_length=dec_sent_l)\n",
    "\n",
    "    train_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        cell=dec_cell,\n",
    "        helper=helper,\n",
    "        initial_state=dec_initial_state)\n",
    "\n",
    "    dec_outputs, _, output_sent_l = tf.contrib.seq2seq.dynamic_decode(train_decoder)\n",
    "    \n",
    "    output_layer = tf.layers.Dense(config.n_vocab, use_bias=False, name='out')\n",
    "    output_logits = output_layer(dec_outputs.rnn_output)\n",
    "    \n",
    "    output_token_idxs = tf.argmax(output_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tokens = tf.fill([batch_l], config.BOS_IDX)\n",
    "end_token = config.EOS_IDX\n",
    "\n",
    "with tf.variable_scope('sent/dec/rnn', reuse=True):\n",
    "    infer_dec_initial_state = tf.layers.Dense(units=config.dim_hidden, activation=tf.nn.relu, name='init_state')(tf.squeeze(means_input, 1))\n",
    "    beam_dec_initial_state = tf.contrib.seq2seq.tile_batch(infer_dec_initial_state, multiplier=config.beam_width)\n",
    "    beam_latents_input = tf.contrib.seq2seq.tile_batch(tf.squeeze(means_input, 1), multiplier=config.beam_width) # added\n",
    "    \n",
    "    beam_decoder = BeamSearchDecoder(\n",
    "        cell=dec_cell,\n",
    "        embedding=embeddings,\n",
    "        start_tokens=start_tokens,\n",
    "        end_token=end_token,\n",
    "        initial_state=beam_dec_initial_state,\n",
    "        beam_width=config.beam_width, \n",
    "        output_layer=output_layer,\n",
    "        length_penalty_weight=config.length_penalty_weight,\n",
    "        latents_input=beam_latents_input)\n",
    "\n",
    "    beam_dec_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        beam_decoder,\n",
    "        maximum_iterations = config.maximum_iterations)\n",
    "\n",
    "    beam_output_token_idxs = beam_dec_outputs.predicted_ids[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('sent/dec/rnn', reuse=True):\n",
    "    inter_means_input = tf.placeholder(tf.float32, [None, config.dim_latent])\n",
    "    \n",
    "    inter_dec_initial_state = tf.layers.Dense(units=config.dim_hidden, activation=tf.nn.relu, name='init_state')(inter_means_input)\n",
    "    inter_beam_dec_initial_state = tf.contrib.seq2seq.tile_batch(inter_dec_initial_state, multiplier=config.beam_width)\n",
    "    inter_beam_latents_input = tf.contrib.seq2seq.tile_batch(inter_means_input, multiplier=config.beam_width) # added\n",
    "    \n",
    "    inter_beam_decoder = BeamSearchDecoder(\n",
    "        cell=dec_cell,\n",
    "        embedding=embeddings,\n",
    "        start_tokens=start_tokens,\n",
    "        end_token=end_token,\n",
    "        initial_state=inter_beam_dec_initial_state,\n",
    "        beam_width=config.beam_width, \n",
    "        output_layer=output_layer,\n",
    "        length_penalty_weight=config.length_penalty_weight,\n",
    "        latents_input=inter_beam_latents_input)\n",
    "\n",
    "    inter_beam_dec_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        inter_beam_decoder,\n",
    "        maximum_iterations = config.maximum_iterations)\n",
    "\n",
    "    inter_beam_output_token_idxs = inter_beam_dec_outputs.predicted_ids[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('sent/dec/rnn', reuse=True):\n",
    "    topic_dec_initial_state = tf.layers.Dense(units=config.dim_hidden, activation=tf.nn.relu, name='init_state')(means_topic)\n",
    "    topic_beam_dec_initial_state = tf.contrib.seq2seq.tile_batch(topic_dec_initial_state, multiplier=config.beam_width)\n",
    "    topic_beam_latents_input = tf.contrib.seq2seq.tile_batch(means_topic, multiplier=config.beam_width) # added\n",
    "    \n",
    "    topic_beam_decoder = BeamSearchDecoder(\n",
    "        cell=dec_cell,\n",
    "        embedding=embeddings,\n",
    "        start_tokens=start_tokens,\n",
    "        end_token=end_token,\n",
    "        initial_state=topic_beam_dec_initial_state,\n",
    "        beam_width=config.beam_width, \n",
    "        output_layer=output_layer,\n",
    "        length_penalty_weight=config.length_penalty_weight,\n",
    "        latents_input=topic_beam_latents_input)\n",
    "\n",
    "    topic_beam_dec_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        topic_beam_decoder,\n",
    "        maximum_iterations = config.maximum_iterations)\n",
    "\n",
    "    topic_beam_output_token_idxs = topic_beam_dec_outputs.predicted_ids[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## language modeling cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and mask\n",
    "dec_target_idxs = t_variables['dec_target_idxs']\n",
    "dec_mask_tokens = tf.sequence_mask(dec_sent_l, maxlen=max_sent_l+1, dtype=tf.float32)\n",
    "\n",
    "# nll for each token (averaged over batch & sentence)\n",
    "sent_loss_recon = tf.contrib.seq2seq.sequence_loss(output_logits, dec_target_idxs, dec_mask_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_l = t_variables['doc_l']\n",
    "mask_sents = tf.sequence_mask(doc_l)\n",
    "mask_sents_flatten = tf.reshape(mask_sents, [tf.shape(mask_sents)[0]*tf.shape(mask_sents)[1]])\n",
    "\n",
    "prob_topic_tiled = tf.tile(tf.expand_dims(prob_topic, 1), [1, tf.shape(mask_sents)[1], 1])\n",
    "prob_topic_flatten = tf.reshape(prob_topic_tiled, [tf.shape(mask_sents)[0]*tf.shape(mask_sents)[1], config.n_topic])\n",
    "prob_topic_sents = tf.boolean_mask(prob_topic_flatten, mask_sents_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferred mixture probabilities (computed for each sentence)\n",
    "categ_topic_infer = tfd.Categorical(probs=prob_topic_infer)\n",
    "\n",
    "# prior of mixture probabilities (computed for each document, tiled for each sentence)\n",
    "categ_topic = tfd.Categorical(probs=prob_topic_sents)\n",
    "\n",
    "sent_loss_kl_categ = tf.reduce_mean(tfd.kl_divergence(categ_topic_infer, categ_topic))\n",
    "\n",
    "# inference of each gaussian gaussribution (computed for each sentence)\n",
    "\n",
    "sent_loss_kl_gauss = tf.reduce_sum(tfd.kl_divergence(gauss_topic_infer, gauss_topic), -1)\n",
    "sent_loss_kl_gmm = tf.reduce_mean(tf.reduce_sum(tf.multiply(prob_topic_infer, sent_loss_kl_gauss), -1))\n",
    "\n",
    "sent_loss_kl = sent_loss_kl_categ + sent_loss_kl_gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m-isonuma/.pyenv/versions/anaconda2-5.3.0/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "tau = tf.cast(tf.divide(tf.mod(global_step, tf.constant(config.cycle_steps)), tf.constant(config.cycle_steps)), dtype=tf.float32)\n",
    "beta = tf.minimum(1., tau/config.r_cycle)\n",
    "\n",
    "sent_loss = sent_loss_recon + beta * sent_loss_kl\n",
    "\n",
    "topic_loss = topic_loss_recon + topic_loss_kl + config.reg * topic_loss_reg\n",
    "loss = topic_loss + sent_loss\n",
    "\n",
    "# define optimizer\n",
    "if config.opt == 'Adam':\n",
    "    optimizer = tf.train.AdamOptimizer(config.lr)\n",
    "elif config.opt == 'Adagrad':\n",
    "    optimizer = tf.train.AdagradOptimizer(config.lr)\n",
    "    \n",
    "grad_vars = optimizer.compute_gradients(loss)\n",
    "clipped_grad_vars = [(tf.clip_by_value(grad, -config.grad_clip, config.grad_clip), var) for grad, var in grad_vars]\n",
    "\n",
    "opt = optimizer.apply_gradients(clipped_grad_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxs_to_sents(token_idxs, config, idx_to_word):\n",
    "    sents = []\n",
    "    for sent_idxs in token_idxs:\n",
    "        tokens = []\n",
    "        for idx in sent_idxs:\n",
    "            if idx == config.EOS_IDX: break\n",
    "            tokens.append(idx_to_word[idx])\n",
    "        sent = ' '.join(tokens)\n",
    "        sents.append(sent)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(sess, batches):\n",
    "    losses = []\n",
    "    ppl_list = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_batch, sent_loss_batch, ppls_batch = sess.run([loss, topic_loss, sent_loss, topic_ppls], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_batch, sent_loss_batch]]\n",
    "        ppl_list += list(ppls_batch)\n",
    "    loss_mean, topic_loss_mean, sent_loss_mean = np.mean(losses, 0)\n",
    "    ppl_mean = np.exp(np.mean(ppl_list))\n",
    "    return loss_mean, topic_loss_mean, sent_loss_mean, ppl_mean\n",
    "\n",
    "def get_all_losses(sess, batches):\n",
    "    losses = []\n",
    "    for ct, batch in batches:\n",
    "        feed_dict = get_feed_dict(batch, mode='test')\n",
    "        loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, sent_loss_recon_batch, sent_loss_kl_batch = \\\n",
    "        sess.run([loss, topic_loss_recon, topic_loss_kl, sent_loss_recon, sent_loss_kl], feed_dict = feed_dict)\n",
    "        losses += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, sent_loss_recon_batch, sent_loss_kl_batch]]\n",
    "    print('LOSS %.2f | TM NLL: %.2f, KL: %.4f | LM NLL: %.2f, KL: %.4f' %  np.mean(losses, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(sample_batch):\n",
    "    feed_dict = get_feed_dict(sample_batch)\n",
    "    pred_token_idxs = sess.run(output_token_idxs, feed_dict = feed_dict)\n",
    "    true_token_idxs = [sent_idxs for instance in sample_batch for sent_idxs in instance.token_idxs]\n",
    "    \n",
    "    assert len(pred_token_idxs) == len(true_token_idxs)\n",
    "    \n",
    "    pred_sents = idxs_to_sents(pred_token_idxs, config, idx_to_word)\n",
    "    true_sents = idxs_to_sents(true_token_idxs, config, idx_to_word)\n",
    "    \n",
    "    for i, (true_sent, pred_sent) in enumerate(zip(true_sents, pred_sents)):        \n",
    "        print(i, 'True: %s' % true_sent)\n",
    "        print(i, 'Pred: %s' % pred_sent)\n",
    "\n",
    "def print_topic_sample():\n",
    "    pred_topics_freq_bow_indices, pred_topic_token_idxs = sess.run([topics_freq_bow_indices, topic_beam_output_token_idxs], \n",
    "                                                                                                           feed_dict={t_variables['batch_l']: config.n_topic, t_variables['keep_prob']: 1.,})\n",
    "    pred_topic_sents = idxs_to_sents(pred_topic_token_idxs, config, idx_to_word)\n",
    "    \n",
    "    topics_freq_bow_idxs = bow_idxs[pred_topics_freq_bow_indices]\n",
    "    \n",
    "    print('-----------Topic Samples-----------')\n",
    "    for i, (topic_freq_bow_idxs, pred_topic_sent) in enumerate(zip(topics_freq_bow_idxs, pred_topic_sents)):\n",
    "        print(i, ' bow:', ' '.join([idx_to_word[idx] for idx in topic_freq_bow_idxs]))\n",
    "        print(i, ' sent:', pred_topic_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'sess' in globals(): sess.close()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "logs = []\n",
    "losses_train = []\n",
    "ppls_train = []\n",
    "loss_min = np.inf\n",
    "beta_eval = 1.\n",
    "epoch = 0\n",
    "train_batches = get_batches(instances_train, config.batch_size, iterator=True)\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011[s], Ep: 00, Ct: 00000|TR LOSS: 324, PPL: 2661|TM NLL: 312, KL: 0.38, REG:0.90 | LM NLL: 10.34, KL: 1.19|DE LOSS: 348, PPL: 2656, TM: 337, LM: 10.34|BETA: 0.000069\n",
      "0 True: <unk> munch 's `` the scream , `` which sold for nearly $ # million at auction , will go on view at the museum of modern art in new york\n",
      "0 Pred: whistleblower lachey lachey outsource lachey lachey methyl methyl cave methyl saakashvili decorating decorating rainfall methyl cajun limited ruzicka cheri monsanto cheri cheri cheri caesarstone cheri picasso cheri methyl cheri decorating lachey cheri cajun lachey cheri baldwin\n",
      "1 True: the museum announced tuesday that the iconic image will be on display from oct. # to april #\n",
      "1 Pred: eog deception wpri uh uh missions lachey armenti uh deception armenti armenti lachey armenti lachey lachey lachey saudi lachey lachey lachey ( champlain mahn impairs resides armenti armenti lachey saudi forecasters lachey pet lachey saudi roommate\n",
      "2 True: the painting is the most expensive artwork ever sold at auction\n",
      "2 Pred: maintaining rajavi removed wrought testimony construction sherry wwj passmore bonding mislead kuster mislead unsuitable mislead leopards passmore jeremiah mislead dictator tutoring ploy driveway mislead aleppo overheated mislead leopards construction casualties mislead leopards partnerre westview bonding mislead\n",
      "3 True: it was purchased by an anonymous private collector at sotheby 's in may\n",
      "3 Pred: whistleblower dominique motives greenbelt shallow copper shallow motives shuh redeveloped copper marker shuh firstsource marik roots copper copper copper copper gearing copper copper mayers cities copper copper addictions redeveloped copper copper bowl misrepresentation redeveloped copper elsewhere\n",
      "4 True: munch created four versions of `` the scream `` between # and #\n",
      "4 Pred: baptism explorer relentless associates associates claude platinum tramonto tramonto ranks reaffirmed tramonto mexican reaffirmed tramonto wings rotated tramonto jails morgantown irrigation irrigation tramonto irrigation wings wyeth flooding tramonto irrigation tramonto irrigation tramonto irrigation gullickson irrigation bartels\n",
      "5 True: this is the only one in private hands\n",
      "5 Pred: perspectives cdt smallen ethylene cardinals ysidro homewood manages augustin smallen barbs place manages manages smallen manages manages manages manages manages porous manages repellant manages manages smallen manages erves manages manages tarrant manages manages manages manages manages\n",
      "6 True: the others are in norwegian museums\n",
      "6 Pred: nevaeh cypress corrections nonnative spanning architects dona architects gertrude impala wrapping wrapping architects tiara kalymon usd kalymon kalymon alvaro kalymon usd kalymon usd nonnative victoria kalymon kalymon captive airpark infections infections extremist developmentally savers voided qw\n",
      "7 True: <unk> director glenn lowry calls it `` a rare opportunity `` to see the artwork\n",
      "7 Pred: garbinski roderique equality temich complain walters meiburg goodman mangione vague lindsborg bowling vague complain complain lehmkuhle initiated complain lindsborg looming complain gilley usc complain guilford narragansett vehicle batesville unpredictable complain complain unpredictable lu unpredictable lehmkuhle unpredictable\n",
      "8 True: the image of a man holding his head and screaming under a streaked , blood red sky has become a modern symbol of human anxiety\n",
      "8 Pred: antidepressants bain fragments xr hubertus hard earhart theatrical trotsky edmunds riyadh earhart bucket trotsky marin marin theatrical vomiting vomiting slaughterhouse applicable walsh franks mel alakanuk slaughterhouse congregants accompany trade heater slaughterhouse slaughterhouse vomiting slaughterhouse slaughterhouse slaughterhouse\n",
      "9 True: the arizona senate has rejected an expansion of a school voucher program that allows students to use public funds to attend a private school because it lacked accountability standards\n",
      "9 Pred: vanblue conservationists conservationists commissioning bonding unsuitable unsuitable unsuitable bonding parrot unsuitable bonding unsuitable det decertification barnstable rent tackies unsuitable bonding acknowledge feb. electrocuted bonding unsuitable bonding crossroads seaton skandera subordinate rebate rent unsuitable stamped tremendous rebate\n",
      "10 True: sb # failed on a # vote thursday with a no vote from republican sponsor sen. barbara mcguire\n",
      "10 Pred: raley trapp niche implementation crops thoreson stagnant crops dibuonaventura crops some crops thoreson thoreson thoreson thoreson crops crops crops dibuonaventura crops crops dibuonaventura thoreson thoreson crops captive thoreson thoreson peralta crops thoreson captive crops captive dibuonaventura\n",
      "11 True: the house has previously approved the bill\n",
      "11 Pred: generators props brighton least residence residence erected erected erected fulghum least manufactures kadyrbayev least residence buyout least inoperable sufficient least previously inoperable inoperable least inoperable residence lundbeck biedrzycki stormwater previously inoperable inoperable inoperable terhark least recounts\n",
      "12 True: mcguire said she 'll bring the proposal back next year with a way to make sure students are held to standards\n",
      "12 Pred: spiritual spiritual wis christo affect marek jacoby elder solta vera incidents frostburg steinberg exploratory usa override overspending whip pants paperboard frostburg hardman override whip overspending frostburg frostburg frostburg fridley frostburg fiance reactor sinha cawley frostburg frostburg\n",
      "13 True: the program established in # was also expanded last year\n",
      "13 Pred: build como gena como washtenaw operates necas liquidation liquidation liquidation liquidation carmax mcleod mcleod mcleod lu celebratory washtenaw washtenaw celebratory celebratory toshiba farmer lu lu lu heidi hospitalized celebratory washtenaw mcleod lu toshiba toshiba washtenaw washtenaw\n",
      "14 True: only students with a disability , whose parents are in the military or attend very low performing schools qualify\n",
      "14 Pred: awarding uribe uribe alamogordo saranac humanitarian aretha scripture unable calmer aretha secular heated heated alamogordo aretha aretha aretha driveway aretha aretha humanitarian driveway disputes assemble aretha community khq bnsf calmer aretha disputes aretha secular unable chesnut\n",
      "15 True: the new bill added kindergartners and increased funding for students who leave charter schools for private schools\n",
      "15 Pred: horseshoe rounsaville augustus aviary dardis alvey aviary distribute suit disturbing alvey beams pallets alvey disturbing grouper disturbing milledgeville ambassador disturbing factories noticeable yw milledgeville tepid grouper botetourt botetourt submerged binding grouper grouper noticeable disturbing resolved grouper\n",
      "16 True: the legality of the voucher program is being challenged in court\n",
      "16 Pred: railways interns owning unscientific grouper exercised overcome harjo contemporary tulips elevator cravaack lemelle tipton bolted pitkin aubrey blairsville tulips diligently lemelle tulips lemelle place accidentally jurisdiction diligently blairsville haunted lemelle grouper oshkosh dinner diligently tulips xinhua\n",
      "17 True: nato says an afghan insurgent leader linked to the killing of two u.s. sailors in july has been captured in eastern afghanistan\n",
      "17 Pred: pitts aircrew administration brochin hollenbach aircrew admirers strickler fayette aircrew strickler fayette aircrew eileen eileen reside bennette pakistan strickler sync fayette kresge amador simi strickler purses strickler strickler strickler bennette fever amador amador fayette strickler strickler\n",
      "18 True: the coalition said tuesday that the man was captured with two of his associates in <unk> province near the pakistani border\n",
      "18 Pred: raceway integrity hunting prochaska yates burnsville connectivity connectivity connectivity morgans charts solso dan peg charts wayland dioceses fendler berry rowdy frankel lankster inaction inaction nationalities charts withdrawals charts adventures adventures vandals adventures wayland charts ecuador solso\n",
      "19 True: they say he was also responsible for planting bombs\n",
      "19 Pred: instability annamarie vigorous irritation linkedin lachaux buttes buttes buttes buttes frustrate buttes buttes buttes indecent buttes buttes buttes buttes buttes buttes buttes buttes buttes buttes frustrate buttes cleric undergoing buttes buttes lachaux buttes kroger buttes buttes\n",
      "20 True: the claims could not be immediately verified\n",
      "20 Pred: mar yes cypress marsteller marsteller marsteller gagged indoors marsteller never venia asu reporters asu hazel hazel gaynor asu asu meghan asu lessard asu burberry venia niocorp colendula rulers granbury hazel burberry lessard asu asu resurrection asu\n",
      "21 True: petty officer # rd class <unk> <unk> and petty officer # nd class justin <unk> were driving through a dangerous part of eastern afghanistan when they became involved in a fire fight on july #\n",
      "21 Pred: perspectives jeans description dion jeans rigoberto sens dion dion moi sens provider sens sens sens helff sens sens driveway buyout ranger provider pare sens rialto pare insider driveway ranger eisley driveway helff sens helff driveway eileen\n",
      "22 True: the bodies of both men were eventually recovered\n",
      "22 Pred: scores mustapha nominated saul timber sara sara sara ketamine kovc nominated sara ketamine sara particularly inciting security glynn sara alachua ketamine harvard genders brochures sara midazolam hardwood sara happiness sara hurled cheese manhattan kovc animals manhattan\n",
      "23 True: nato says monday 's arrest was accomplished without firing any weapons\n",
      "23 Pred: awarding awarding published 'em kroger pavement fasciitis kroger solicitor kroger reuters heaters kroger g. heaters submissions kroger kroger pavement heaters kroger uri kroger fulghum farmer kroger kroger kroger kroger kroger solicitor dnc kroger kroger dnc heaters\n",
      "24 True: authorities say homes in northeast oklahoma county have been evacuated because of a large , wind driven grass fire\n",
      "24 Pred: chang truancy w.va. w.va. madsen oncology pants oncology gear oncology oncology beltrami oncology safari oncology domino byproduct byproduct diagnostic lena beltrami exempting beltrami oncology oncology oncology ralston midstream oncology operates gravity landscaping landscaping tested fofana landscaping\n",
      "25 True: crews were notified about # p.m. tuesday of the blaze near interstate # in the luther area , northeast of oklahoma city\n",
      "25 Pred: romeyn romeyn elite coors elite elite admiral lachey lachey bust laboratory diverted lachey lachey lachey bust poker lachey tackled lachey lachey lachey snowbank jeffersonville emory tackled bust tackled coors tackled lachey lachey coors tackled tackled tackled\n",
      "26 True: oklahoma county emergency management director david barnes says several homes in the area were evacuated , but there were no reports of damage\n",
      "26 Pred: entity entity bonner modernize ramnarine degradation degradation degradation healthnet medallions viewed healthnet mississippians tevis ally ey cramer upright agribusiness viewed tevis lap ey harms stagger cramer sawyer tevis healthnet explains fleury harsher piano coo harsher bz\n",
      "27 True: barnes says there was an unconfirmed report of a firefighter sustaining a minor injury\n",
      "27 Pred: thrusters mainecare steak crutchfield tanya feeding flott bee belonged belonged wetter reese jackpots inhaled quintanilla eleven eleven garver inhaled natick jackpots coria coria albanians albanians garver garver albanians eleven reese sponsorship garver reese garver see albanians\n",
      "28 True: he says a fire burned in the same location monday\n",
      "28 Pred: messenger magraff nadia xm habitual establishes discourse sutherland a.c. xm grill esper establishes sackey sutherland sutherland tawney handcuff sutherland xm xm xm xm waterbury xm sutherland xm xm beeman sutherland bulgaria xm xm sutherland unreported a.c.\n",
      "29 True: lt. col. max moss says the oklahoma national guard sent a uh # blackhawk helicopter equipped with a # gallon bucket to drop water on the blaze after getting a call for assistance\n",
      "29 Pred: weisman romeyn bartmier devils devils devils devils devils weight pst final devils devils seaworld mackinac strength holdings reapply yacht reapply devils pst godbey duffly reapply duffly godbey pst pst flights portions pst pst ceo devils semitrailer\n",
      "30 True: barnes says dry conditions and brisk winds have made the fire hard to contain\n",
      "30 Pred: wlne migrant wlne biker buenos hermitage biker biker resource biker biker resource biker biker female detonate open cheese biker placing resource resource biker open resource laupahoehoe pride differently dizzy broke bahrain dizzy walt bahrain stolle bock\n",
      "31 True: the nebraska department of health and human services is moving its office in lexington\n",
      "31 Pred: clairmont lapse disabilities lowlands damaged damaged damaged damaged damaged damaged damaged damaged mckenna damaged bracelets bracelets damaged bracelets bracelets bracelets bracelets elementary bracelets hillside orth bracelets diede damaged dardenne bracelets hillside bracelets hillside gottlieb bracelets elementary\n",
      "32 True: state officials say they do n't expect any interruption in services when workers move to the new location on tuesday\n",
      "32 Pred: cardona murky update mathew calif calif broussard zero devito cabarrus zero zero zero salesmen departments zero lifted zero zero zero tran girl reconsideration veracruz salesmen wheelchair zero hardwick rory lifted lifted cabarrus girl les zero zero\n",
      "33 True: the move includes # child and family services workers , one child care licensure employee and others who work in developmental disabilities services\n",
      "33 Pred: earley support kuang milone kansans lone kansans ham kansans mater lone seminars ramras contact kansans woodford mater ham ramras contact seminars mater pose woodford leaned audition creamery kuang ham audition needing ham schoolyard submissions ham lone\n",
      "34 True: employees plan to staff both the current and new offices on the day of the move to respond to clients ' needs\n",
      "34 Pred: nettles nettles eckrote zay condensate washtenaw washtenaw wisuk washtenaw words condensate uniformed williamson undocumented condensate words lake pesticide washtenaw words pesticide starvation washtenaw peggy pesticide pesticide reuse previously pesticide ethical previously fil previously thrifty expunged lake\n",
      "35 True: the new office is located at # west # th st. , suite # , in lexington\n",
      "35 Pred: retaining austria beers beers beers beers terrorists contamination contamination beers terrorists words harvests realizing beers consuming contamination contamination consuming barousalian realizing harvests dispose realizing kulin plante sandra realizing impress beers realizing harvests domino harvests conditioning mastery\n",
      "36 True: the post office box and office phone number will remain the same\n",
      "36 Pred: opinions lynda visitors allstate visitors cooling treated judging reese demise ravaged ravaged darnell demise ravaged addiction demise ravaged percentages northfield ravaged hartzell delivered ravaged ravaged including ravaged demise budge bested specimens palcohol demise ravaged ravaged darnell\n",
      "37 True: online : nebraska department of health and human services , http :\n",
      "37 Pred: easton methamphetamines accommodate u.s.a. u.s.a. trolley vincent weare vincent t.w u.s.a. geographically evolved deliberation inflatable weekday weekday discharge reisch ropes staton clancy lamontagne vincent weekday evolved weekday vincent evolved dioceses geographically vincent t.w weekday vincent u.s.a.\n",
      "38 True: a texas panhandle anesthesiologist who for years skipped paying income taxes and hid money using his dead father 's name must serve nearly four years in prison\n",
      "38 Pred: prostitute steiner accusation accusation steiner accusation steiner steiner steiner steiner steiner projected projected rubinetti boyd jacket harn benders steiner personally odor steiner personally solta steiner armored projected steiner harn steiner steiner projected personally projected steiner steiner\n",
      "39 True: a federal judge in amarillo on thursday also ordered dr. edgar lockett jr. to pay more than $ # million in back taxes since #\n",
      "39 Pred: evo delusional lachey delusional lachey lachey surveyors moth propane pediatric moth lepage newscast barkus lachey pastors egleston surveyors jk plunkett consultant surveyors lamphere gainey jk loading lachey lachey newscast supplement supplement loading followill haggie pediatric lachey\n",
      "40 True: lockett in september was convicted of six counts of tax evasion\n",
      "40 Pred: aliens suggs roderique suggs uninhabited suggs suggs wichita intestinal beltrami stanislaw storming beltrami beltrami uninhabited beltrami stanislaw mcatee mcatee kl faye mcatee mcatee wishing aramony beltrami apalachicola wishing endless bnsf morgans beltrami faye beltrami bogalusa storming\n",
      "41 True: investigators say lockett is a self employed anesthesiologist in amarillo who formerly practiced in mineral wells and mcallen\n",
      "41 Pred: gator epps gluten northway flurries flurries pilot johnathan ls coleman ls pilot pilot pilot flurries laredo flurries swings linamar flurries egner achievement appears pilot thus pilot lutherville dave unveiling lutherville achievement appears vaccines disarm flurries flurries\n",
      "42 True: lockett did not file income tax returns since # , except for a joint return with his spouse for tax year #\n",
      "42 Pred: bennettsville million forget slept emory advisable chalk emory peevey peevey emory tackies landings safer peevey gleeson clerk echoes gleeson fluctuate sour peevey overheated jos landings mangione gleeson gleeson requiring unsuitable mayflower partnered gleeson peevey parris hormone\n",
      "43 True: investigators say lockett , who was sentenced to # months in prison , concealed his assets by putting the money in bank accounts used his deceased father 's name and social security number\n",
      "43 Pred: garbinski provisional member geology provisional cerza provisional hp insolvent tramonto boespflug alleyne tramonto tramonto insolvent insolvent insolvent geology sword tramonto tramonto outdated tramonto mauer member rinaldi tramonto tramonto fool disneyland tramonto rinaldi humanity yards provisional mcarthur\n",
      "44 True: attorney general eric holder says investigators at this point do n't have `` any credible information `` to determine which terrorist group was responsible for the attacks in paris\n",
      "44 Pred: dinners nearing cancerous gravel sebastian trapp interpol cancerous legg cancerous legg vallas legg legg cavender legg ivy legg legg legg hooters legg legg legg allotment semisouth legg hooters hooters legg legg hooters hilliker legg starkist kander\n",
      "45 True: al qaida 's branch in yemen has said it directed the attack by two brothers against a french satirical newspaper that <unk> islam and other religions\n",
      "45 Pred: sports rector waverly barbie cybercrime ethical egypt erratically waverly egypt ethical ethical marylanders ethical negotiator egypt tjx ethical ended ethical bulgaria ethical ethical middlesex barbie india lachey ethical barbie marylanders telecom egypt marylanders wellington damaged barbie\n",
      "46 True: and the gunman in the hostage taking at a kosher market is seen in a new video pledging allegiance to the islamic state group\n",
      "46 Pred: fundamental stakeholders paulina measures liquidation fla kansas meanwhile liquidation pickwick meanwhile please pickwick pickwick pickwick disciplines pickwick driven pickwick zet pickwick pickwick blasts blasts sobel disciplines recover pickwick boas rosemount liquidation sobel hertz pickwick pickwick blasts\n",
      "47 True: holder says both terrorist groups pose a threat to the united states and its allies\n",
      "47 Pred: interment interment interment therapeutics k wilbanks flurries flurries installation opening flurries zuhs escalate outbuilding sorting bonnie fennell sorting sorting flurries bites hired unsteady flurries flurries gpa kratz flurries gpa opening spahr kaibab opening laredo opening gpa\n",
      "48 True: the attorney general spoke in a series of interviews with the sunday morning news shows in washington\n",
      "48 Pred: align weekday passages mathew rainbowtique gross scorched xi jefferies lehmkuhle contact lehmkuhle mailing friberg realizing citibank kwame lehmkuhle detach rainbowtique jefferies lehmkuhle contact mailing active xr xr josephine contact lehmkuhle jefferies lehmkuhle invitations lehmkuhle jefferies skeptics\n",
      "49 True: holder was in paris , where he was attending a meeting on fighting terrorism\n",
      "49 Pred: bundle hayes kalman slay coors slay whichever whichever hospital whichever baxter whichever coors rigoberto stocked mangione stocked stocked mcbride stocked proposals conoco therrien whichever stocked vero proposals stocked stocked masonry derosier slay mangione sprenger vero teagan\n",
      "50 True: rush county authorities say winds that blew through lacrosse were strong enough to knock over train cars sitting at a <unk>\n",
      "50 Pred: draped unjustifiable starvation posse alpharetta burien burien susana unsuitable burien oversaw //is.gd/r chretien stocks characterizing oversaw schoon xm schoon curve starvation ferriday mislead schoon currier ahlquist ferriday ferriday ferriday naral ferriday ligambi ferriday sandcastle pikeville decoster\n",
      "51 True: the sheriff 's department says the strong winds wednesday night pushed over six empty train cars near main street in lacrosse\n",
      "51 Pred: weisman testimony ponding altos slabs pamphlet armistead mules leesville smarter tur leopards radioed bagarozzo zipper radioed krqe dad ponding swamped leesville sexually leesville volumes leesville copyright copyright fibers radioed glands intersection colon fibers livable glands leesville\n",
      "52 True: they were part of an empty train that stretched almost a mile into town\n",
      "52 Pred: alexandra gore weekly places pevehouse pevehouse mel associate associates earhart cluster earhart hooked install holes install conventions mel onorato mote mel associates associates mel gigabit cluster uco mel gigabit associates kaneohe westport martin install associates uco\n",
      "53 True: no injuries were reported and no highways or roads were closed\n",
      "53 Pred: chang lindholm coffers affiliations legged legged legged commemoration legged legged headlines legged place legged appointee filipino filipino molester legged redeem roesser altos structuring legged augusta molester headlines molester escamilla augusta legged structuring expulsion augusta expulsion legged\n",
      "54 True: kwch tv reports ( http : //bit.ly/ # <unk> ) winds were up to # mph when the derailment\n",
      "54 Pred: enyart bennettsville airshow just interment cleco icg rathje legged icg dolls pikeville albanians pikeville donadio legged donadio invasion rathje bludgeoned playful glen playful pew getaway consist pikeville pikeville headliner euro bludgeoned pikeville growling icg bludgeoned toss\n",
      "55 True: tourism officials are seeking proposals for a # room hotel at the gwinnett center complex , which already includes an arena , a museum , a theater and convention space\n",
      "55 Pred: lg lg budget motives hamblin damaged colin motives downsizing walt communities landlords apprehending ragley apprehending damaged rsv tnt hardwick whalen cam mountain sara hardwick landlords walt shallow sara gothenburg bracelets runways gothenburg apprehending sara rech gothenburg\n",
      "56 True: gwinnett center chief executive preston williams told the gwinnett daily post ( http : <unk> ) that tourism officials were ready to gauge interest in a hotel again after a stalled project in #\n",
      "56 Pred: bisexual potentially chellie mallory mallory mallory nj.com shoveling mallory radioed nj.com alberto coworker moscovics sauls suarez amazon.com alberto while concludes wbrc highlighting berry kouris griffiths //on.wsj.com/ oversaw tolliver alberto wbrc while infractions berry ranges alberto tolliver\n",
      "57 True: he said a hotel could bring new business because some conventions wo n't consider a facility without an on site hotel\n",
      "57 Pred: landscapes habitual habitual koplin koplin emissions firm croix croix croix firm firm firm wii firm emissions firm emissions pautz endymion firm firm firm croix croix metrojet croix emissions firm emissions endymion emissions abington firm emissions emissions\n",
      "58 True: officials would require the project to be financed by the developer without any funding from the county\n",
      "58 Pred: koh doxer doxer helfer heavyset doxer l'enfant doxer kiny mcleod l'enfant lack apex lohman dalton kiny cigarette settlements l'enfant l'enfant void arkansans l'enfant arkansans promoter siu void farr hulled arkansans l'enfant crick farr tampering promoter defined\n",
      "59 True: the proposals are due on jan. #\n",
      "59 Pred: superintendents constellation coberly coberly cheley transplants deliveryman breakthrough transplants poker asher psychoactive parsippany gillett manger resonate transplants mextorf cipriani super veronica breakthrough veronica rumford cornett misty breakthrough sih transplants lansdale lutheran togliatti super transplants ingalls breakthrough\n",
      "60 True: police say a man was killed and two women were injured when they were struck by an suv while waiting for a bus in the denver suburb of littleton\n",
      "60 Pred: hsbc debate obstruction aviary handled budgets aviary crediting obscene wear advertisers assert advertisers advertisers advertisers advertisers advertisers gustafson advertisers advertisers newscast advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers advertisers\n",
      "61 True: police say all three victims are believed to be visually impaired\n",
      "61 Pred: switching settles newberry matt budget hanks ollis burnsville burnsville casselton suck elimination burnsville suck hanks aiden burnsville calchi fireworks hanks suck viewing hanks hanks reads kardashian hanks dade swann boscarino hanks silt hanks reads boscarino hanks\n",
      "62 True: authorities say an suv driven by a # year old woman went out of control friday morning and struck the pedestrians\n",
      "62 Pred: trotter refinery explorer proving replaces explorer replaces elkins nearby elkins dunne kaufman avert dunne elkins lena depend elkins elkins elkins replaces replaces depend depend dunne cervone bolts cervone tens rocky chiesa pennington ravine allah rocky replaces\n",
      "63 True: no names have been released\n",
      "63 Pred: subik cicilline motives motives motives motives submissions gogebic motives motives grandparent honeymoon broad solta ncaa honeymoon solta ncaa honeymoon megawatt advertisers ncaa hamblin lavrov ncaa solta submissions submissions airliner honeymoon honeymoon ncaa ncaa hamblin honeymoon megawatt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Topic Samples-----------\n",
      "0  bow: strong private students train back hour program cars winds requested\n",
      "0  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint scrolls mcleroy attacked mennonite mennonite dey netanyahu scrolls tallman tallman tallman bearing px ridgefield ridgefield ridgefield ridgefield mae ridgefield dining mae cossette brelo\n",
      "1  bow: tax train hotel ' human years taxes investigators number income\n",
      "1  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint brat adjourn scrolls bloomberg earle inhabited uncle uncle common common common tsegaye does merchison merchison juliet beirut gosch flaming kwan lajoie handshake handshake\n",
      "2  bow: jason released p.m. participate reports companies thursday tax features hall\n",
      "2  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint brat adjourn scrolls bloomberg earle inhabited uncle uncle common common common tsegaye does merchison merchison juliet beirut gosch flaming kwan lajoie handshake handshake\n",
      "3  bow: winds tax taxes prison money tv years father investigators strong\n",
      "3  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint brat adjourn scrolls bloomberg earle inhabited uncle uncle common common common tsegaye does merchison merchison juliet beirut gosch flaming kwan lajoie handshake handshake\n",
      "4  bow: group general services attorney private video groups slaying chief taking\n",
      "4  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint brat adjourn scrolls bloomberg earle inhabited uncle uncle common common common tsegaye does merchison merchison juliet beirut gosch flaming kwan lajoie handshake handshake\n",
      "5  bow: hotel private http tourism museum move services attend office gang\n",
      "5  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint scrolls mcleroy attacked mennonite mennonite dey netanyahu scrolls scrolls exiting mccann\n",
      "6  bow: oklahoma northeast fire winds night management tuesday call dry yard\n",
      "6  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint scrolls mcleroy attacked mennonite mennonite dey netanyahu scrolls scrolls exiting mccann\n",
      "7  bow: oklahoma fire guard tuesday blaze office peace evacuated northeast wind\n",
      "7  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint brat adjourn scrolls bloomberg earle inhabited uncle uncle common common common tsegaye does merchison merchison juliet beirut gosch flaming kwan lajoie handshake handshake\n",
      "8  bow: july captured services afghanistan officer students eastern victims nebraska class\n",
      "8  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint brat adjourn scrolls bloomberg earle inhabited uncle uncle common common common tsegaye does merchison merchison juliet beirut gosch flaming kwan lajoie handshake handshake\n",
      "9  bow: tax project tells boys policy serve stable http quinn july\n",
      "9  sent: katz taxi strikes strikes claremont coari cline cline explorers special jurisdictions nazis perform stolworthy mennonite mennonite restraint scrolls mcleroy attacked mennonite mennonite dey netanyahu scrolls tallman tallman tallman bearing px ridgefield ridgefield ridgefield ridgefield mae ridgefield dining mae cossette brelo\n"
     ]
    }
   ],
   "source": [
    "if len(logs) == 0:\n",
    "    cmd_rm = 'rm -r %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_rm.split())\n",
    "\n",
    "    cmd_mk = 'mkdir %s' % config.modeldir\n",
    "    res = subprocess.call(cmd_mk.split())\n",
    "\n",
    "time_start = time.time()\n",
    "while epoch < config.epochs:\n",
    "    for ct, batch in train_batches:\n",
    "        feed_dict = get_feed_dict(batch)\n",
    "\n",
    "        _, loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, sent_loss_recon_batch, sent_loss_kl_batch, sent_loss_kl_categ_batch, sent_loss_kl_gmm_batch, ppls_batch = \\\n",
    "        sess.run([opt, loss, topic_loss_recon, topic_loss_kl, topic_loss_reg, sent_loss_recon, sent_loss_kl, sent_loss_kl_categ, sent_loss_kl_gmm, topic_ppls], feed_dict = feed_dict)\n",
    "   \n",
    "        if sent_loss_kl_batch == np.inf:\n",
    "            print('Nan occured')\n",
    "            ckpt = tf.train.get_checkpoint_state(config.modeldir)\n",
    "            model_checkpoint_path = ckpt.all_model_checkpoint_paths[-1]\n",
    "            saver.restore(sess, model_checkpoint_path)            \n",
    "            break\n",
    "            \n",
    "        losses_train += [[loss_batch, topic_loss_recon_batch, topic_loss_kl_batch, topic_loss_reg_batch, sent_loss_recon_batch, sent_loss_kl_batch]]\n",
    "        ppls_train += list(ppls_batch)\n",
    "\n",
    "        if ct%config.log_period==0:\n",
    "            loss_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train, sent_loss_recon_train, sent_loss_kl_train = np.mean(losses_train, 0)\n",
    "            ppl_train = np.exp(np.mean(ppls_train))\n",
    "            loss_dev, topic_loss_dev, sent_loss_dev, ppl_dev = get_loss(sess, dev_batches)\n",
    "\n",
    "            if config.warmup: beta_eval = beta.eval(session=sess)\n",
    "            global_step_log = sess.run(tf.train.get_global_step())            \n",
    "            \n",
    "#             if loss_dev < loss_min:\n",
    "#                 loss_min = loss_dev\n",
    "#                 saver.save(sess, config.modelpath, global_step=global_step_log)\n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            time_finish = time.time()\n",
    "            time_log = int(time_finish - time_start)\n",
    "            logs += [(time_log, epoch, ct, loss_train, ppl_train, topic_loss_recon_train, topic_loss_kl_train, topic_loss_reg_train, sent_loss_recon_train, sent_loss_kl_train, loss_dev, ppl_dev, topic_loss_dev, sent_loss_dev, beta_eval)]\n",
    "            for log in logs:\n",
    "                print('%03d[s], Ep: %02d, Ct: %05d|TR LOSS: %.0f, PPL: %.0f|TM NLL: %.0f, KL: %.2f, REG:%.2f | LM NLL: %.2f, KL: %.2f|DE LOSS: %.0f, PPL: %.0f, TM: %.0f, LM: %.2f|BETA: %.6f' %  log)\n",
    "\n",
    "            print_sample(batch)\n",
    "\n",
    "            time_start = time.time()\n",
    "            \n",
    "            print_topic_sample()\n",
    "                \n",
    "    epoch += 1\n",
    "    train_batches = get_batches(instances_train, config.batch_size, iterator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confirm variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prob_topic, _prob_topic_sents, _prob_topic_infer, _means_topic_infer = debug_value([prob_topic, prob_topic_sents, prob_topic_infer, means_topic_infer], return_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.2281889e-02, 6.7835855e-03, 2.0132679e-01, 1.1674699e-02,\n",
       "        6.5264981e-03, 1.1411838e-02, 6.9189700e-03, 2.8612482e-04,\n",
       "        7.4042326e-01, 2.3663496e-03], dtype=float32),\n",
       " array([0.09889801, 0.11335436, 0.12141278, 0.10027827, 0.13508864,\n",
       "        0.09455997, 0.0860846 , 0.08042429, 0.09635323, 0.07354581],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_i = 4\n",
    "_prob_topic_sents[batch_i], _prob_topic_infer[batch_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02824139, -0.22793637,  0.3788033 , -0.02814816],\n",
       "       [ 0.06249218, -0.08085692,  0.06756439,  0.2259818 ],\n",
       "       [-0.1377574 ,  0.28185233,  0.23656711, -0.3201025 ],\n",
       "       [-0.03711405,  0.16953555,  0.16389738, -0.16461828],\n",
       "       [ 0.27302447, -0.22462857,  0.37200606, -0.00549014],\n",
       "       [-0.16755986,  0.11964113,  0.17052333,  0.18083367],\n",
       "       [ 0.26351342, -0.33828875,  0.3920058 , -0.17029142],\n",
       "       [ 0.21033517, -0.1955087 ,  0.20963705, -0.24809986],\n",
       "       [ 0.01922028, -0.03185754,  0.28022933, -0.13928899],\n",
       "       [-0.26817918, -0.3364467 ,  0.36924574,  0.15818927]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_means_topic_infer[0][:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_means_topic, b_means_topic = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"topic/dec/mean_topic\")\n",
    "\n",
    "pred_topic_embeddings, pred_topic_bow, pred_means_topic, pred_logvars_topic, pred_token_idxs, _w_means_topic, _b_means_topic, _w_mean_topic_infer = \\\n",
    "                                sess.run([topic_embeddings, topic_bow, means_topic, logvars_topic, topic_beam_output_token_idxs, w_means_topic, b_means_topic, w_mean_topic_infer], \n",
    "                                         feed_dict={t_variables['batch_l']: config.n_topic, t_variables['keep_prob']: 1.,})\n",
    "\n",
    "pred_sents = idxs_to_sents(pred_token_idxs, config, idx_to_word)\n",
    "\n",
    "pred_topics_freq_bow_indices = np.argsort(pred_topic_bow, 1)[:, ::-1][:, :10]\n",
    "pred_topics_freq_bow_idxs = bow_idxs[pred_topics_freq_bow_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['million', 'http', 'years', 'tuesday', 'federal', 'u.s.', 'month', 'office', 'people', 'monday']\n",
      "['reports', 'department', 'thursday', 'court', 'time', 'u.s.', 'years', 'monday', 'tuesday', \"'\"]\n",
      "['school', 'public', 'u.s.', 'board', 'university', 'federal', 'president', 'program', 'health', 'students']\n",
      "['fire', 'found', 'authorities', 'hospital', 'home', 'a.m.', 'dead', 'investigation', 'chief', 'morning']\n",
      "['service', 'national', 'department', 'http', 'water', 'park', 'area', 'center', 'wednesday', 'weather']\n",
      "['percent', 'company', 'million', 'billion', 'shares', 'inc.', 'revenue', 'average', 'cents', 'price']\n",
      "['design', 'researchers', 'donations', 'prize', 'encourage', 'peak', 'awards', 'feature', 'chapter', 'affect']\n",
      "['court', 'arrested', 'charged', 'attorney', 'death', 'authorities', 'found', 'prison', 'shooting', 'woman']\n",
      "['bill', 'senate', 'house', 'republican', 'committee', 'public', 'board', 'approved', 'u.s.', 'law']\n",
      "['todd', 'rear', 'drowned', 'confronted', 'foul', 'transported', 'assaulted', 'loaded', 'defender', 'unidentified']\n"
     ]
    }
   ],
   "source": [
    "for idxs in pred_topics_freq_bow_idxs:\n",
    "    print([idx_to_word[idx] for idx in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09207956,  0.09077395,  0.06120839, -0.22176096,  0.19921999,\n",
       "        -0.05485373, -0.23069587,  0.05650459,  0.142239  , -0.17410392],\n",
       "       [ 0.29974467, -0.03281972,  0.25064805, -0.2893645 , -0.1312135 ,\n",
       "        -0.11136644,  0.02060958, -0.13598587,  0.24592783, -0.18463418],\n",
       "       [ 0.22819577,  0.14566512,  0.05597903, -0.1109414 , -0.00879419,\n",
       "        -0.1605561 ,  0.11445126,  0.00916692, -0.04847115, -0.0603605 ],\n",
       "       [ 0.3365141 , -0.06439152,  0.3631938 ,  0.14203475,  0.10052318,\n",
       "        -0.09119357, -0.08768138, -0.28562906,  0.3186355 , -0.08452626],\n",
       "       [ 0.26727033,  0.03540339,  0.28315246, -0.1286456 , -0.02444943,\n",
       "        -0.163507  , -0.02146725, -0.21729966,  0.26542294, -0.1589102 ],\n",
       "       [ 0.28826687, -0.18438952,  0.2760168 , -0.12692557,  0.05485712,\n",
       "         0.17983724,  0.14970489, -0.36168167,  0.30563408, -0.13128197],\n",
       "       [-0.32988435, -0.11005852, -0.27013943,  0.26166642, -0.3013388 ,\n",
       "        -0.2234488 ,  0.02287463,  0.20320751, -0.10510623,  0.28636736],\n",
       "       [ 0.37211177, -0.00585993,  0.2853141 , -0.05771174,  0.15170154,\n",
       "         0.05411884, -0.24091715, -0.01475959, -0.0408047 , -0.17167823],\n",
       "       [ 0.20512433,  0.18697639, -0.08326819,  0.03792854,  0.03214281,\n",
       "         0.05618311,  0.09544107,  0.03913466, -0.06514693, -0.04000437],\n",
       "       [-0.3745221 , -0.06385167, -0.29924905,  0.08158813, -0.28344202,\n",
       "        -0.01799835,  0.02471407,  0.408938  , -0.169172  ,  0.37273586]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_topic_embeddings[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0327697e-03, 4.6811462e-03, 1.7024261e-04, ..., 3.3795869e-04,\n",
       "        1.5871278e-04, 6.6570101e-05],\n",
       "       [5.9443718e-04, 7.4376534e-03, 2.0111131e-04, ..., 7.4048399e-04,\n",
       "        1.5028552e-04, 8.9953668e-05],\n",
       "       [8.5580017e-04, 2.8901210e-03, 1.6464434e-04, ..., 3.1770146e-04,\n",
       "        1.9349743e-04, 3.0012103e-04],\n",
       "       ...,\n",
       "       [1.3188391e-04, 2.6697975e-03, 2.3009101e-04, ..., 8.1575691e-04,\n",
       "        1.5104198e-04, 3.2140684e-05],\n",
       "       [3.8558390e-04, 4.0810513e-03, 1.4347673e-04, ..., 1.4157601e-04,\n",
       "        1.8342295e-04, 4.7484271e-05],\n",
       "       [7.1679087e-06, 2.9757638e-07, 1.8662996e-04, ..., 5.9841594e-05,\n",
       "        1.7972868e-04, 5.0798093e-04]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_topic_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09637171, -0.09069463,  0.09532599, ..., -0.02989542,\n",
       "        -0.02514938,  0.01415634],\n",
       "       [-0.02764424,  0.01254364,  0.03703775, ..., -0.01512817,\n",
       "         0.02590305,  0.01404281],\n",
       "       [-0.08408152, -0.00924051, -0.08365072, ...,  0.05623364,\n",
       "        -0.05008389,  0.0209127 ],\n",
       "       ...,\n",
       "       [-0.00629492, -0.05131948, -0.05206006, ..., -0.0955721 ,\n",
       "        -0.01980347, -0.02646225],\n",
       "       [-0.00839109, -0.05062511, -0.05731497, ...,  0.07618995,\n",
       "         0.03893617,  0.06835916],\n",
       "       [ 0.07883421, -0.02804748,  0.09326512, ..., -0.0734218 ,\n",
       "         0.0045918 , -0.10043538]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_w_means_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03207342, -0.08436021,  0.36105958, -0.02925379, -0.26779142,\n",
       "       -0.4809294 , -0.04713235, -0.6384421 ,  0.49655244, -0.18943405,\n",
       "        0.32139724,  0.00376519, -0.02733823,  0.06968141,  0.12723993,\n",
       "        0.17086434,  0.4321125 ,  0.2930171 ,  0.43750855, -0.32728267,\n",
       "       -0.29320472,  0.46633536,  0.03467208, -0.11661331,  0.02106199,\n",
       "        0.10828511,  0.14413024,  0.00801178, -0.16259423,  0.31461757,\n",
       "       -0.25328413,  0.11320477], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_b_means_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03563995, -0.3379975 ,  1.6953684 , -0.3394102 , -1.3313038 ,\n",
       "        -1.9561913 , -0.34439525, -3.1041431 ,  2.302101  , -0.80340064,\n",
       "         1.374892  ,  0.10505254,  0.13142577,  0.36230466,  0.5036737 ,\n",
       "         0.6154421 ,  1.8879794 ,  1.263777  ,  2.0281937 , -1.4289141 ,\n",
       "        -1.3110695 ,  2.0390706 ,  0.32288784, -0.39520237,  0.10320839,\n",
       "         0.35608286,  0.61754334, -0.1438482 , -0.74413097,  1.4731948 ,\n",
       "        -1.1249324 ,  0.33894244],\n",
       "       [ 0.03510073, -0.3374708 ,  1.6888778 , -0.3363807 , -1.3308815 ,\n",
       "        -1.9608293 , -0.34732953, -3.1081154 ,  2.3005512 , -0.80602133,\n",
       "         1.3695524 ,  0.10256523,  0.13283278,  0.36182955,  0.49822897,\n",
       "         0.6213894 ,  1.8883276 ,  1.266403  ,  2.023539  , -1.426166  ,\n",
       "        -1.3108103 ,  2.0448976 ,  0.32430837, -0.38903922,  0.10560946,\n",
       "         0.3596735 ,  0.6160856 , -0.14840832, -0.74532497,  1.4738762 ,\n",
       "        -1.1249926 ,  0.33331037],\n",
       "       [ 0.03490497, -0.33676392,  1.6840277 , -0.335459  , -1.3295547 ,\n",
       "        -1.95664   , -0.3462094 , -3.1003447 ,  2.296549  , -0.80408335,\n",
       "         1.367739  ,  0.10281808,  0.13425133,  0.36240244,  0.4972452 ,\n",
       "         0.6206323 ,  1.885982  ,  1.2645416 ,  2.0215812 , -1.4212072 ,\n",
       "        -1.3081043 ,  2.0386996 ,  0.32136053, -0.39039296,  0.1050597 ,\n",
       "         0.36023104,  0.6137113 , -0.15039542, -0.7433981 ,  1.4694595 ,\n",
       "        -1.1245916 ,  0.3360805 ],\n",
       "       [ 0.03728028, -0.33768234,  1.6832604 , -0.3353232 , -1.325423  ,\n",
       "        -1.9593027 , -0.34599763, -3.1006794 ,  2.2962196 , -0.80693865,\n",
       "         1.3678529 ,  0.10114851,  0.13371727,  0.36420822,  0.49783063,\n",
       "         0.62049437,  1.8832903 ,  1.2625886 ,  2.0200832 , -1.421174  ,\n",
       "        -1.3108637 ,  2.0388248 ,  0.32396334, -0.38813725,  0.10552703,\n",
       "         0.3586173 ,  0.6122677 , -0.15264365, -0.74335086,  1.468328  ,\n",
       "        -1.1214948 ,  0.337562  ],\n",
       "       [ 0.0355639 , -0.33673748,  1.6850188 , -0.334822  , -1.3297123 ,\n",
       "        -1.9579692 , -0.34517902, -3.0999303 ,  2.296747  , -0.8048171 ,\n",
       "         1.3683693 ,  0.10311563,  0.13507861,  0.36239594,  0.4968614 ,\n",
       "         0.61993766,  1.8848993 ,  1.2634866 ,  2.0213115 , -1.4220002 ,\n",
       "        -1.3081868 ,  2.0382977 ,  0.32180363, -0.39071375,  0.10513556,\n",
       "         0.35903966,  0.6132862 , -0.15032193, -0.74355686,  1.4703372 ,\n",
       "        -1.1240762 ,  0.3361809 ],\n",
       "       [ 0.03776056, -0.33906677,  1.6886759 , -0.33578348, -1.3277831 ,\n",
       "        -1.9574624 , -0.3511446 , -3.1008887 ,  2.298576  , -0.80058026,\n",
       "         1.3695161 ,  0.10116885,  0.13310117,  0.36374724,  0.49994904,\n",
       "         0.62002206,  1.8863395 ,  1.2639412 ,  2.0218256 , -1.4257591 ,\n",
       "        -1.3068638 ,  2.038707  ,  0.3251842 , -0.38946715,  0.10602362,\n",
       "         0.3615039 ,  0.6127277 , -0.15162012, -0.739843  ,  1.4696462 ,\n",
       "        -1.1235677 ,  0.34125343],\n",
       "       [ 0.03675649, -0.33748797,  1.6818695 , -0.3343631 , -1.3270382 ,\n",
       "        -1.9566132 , -0.34484407, -3.0962553 ,  2.2958052 , -0.8025343 ,\n",
       "         1.365838  ,  0.10129849,  0.13410446,  0.36187994,  0.49527365,\n",
       "         0.62073433,  1.8827194 ,  1.264018  ,  2.019868  , -1.4191431 ,\n",
       "        -1.3083122 ,  2.036423  ,  0.32277   , -0.38972613,  0.10532874,\n",
       "         0.36029965,  0.6137044 , -0.14923215, -0.7424054 ,  1.4679198 ,\n",
       "        -1.1228634 ,  0.33640632],\n",
       "       [ 0.03632384, -0.33631054,  1.6842166 , -0.33446336, -1.3275865 ,\n",
       "        -1.959459  , -0.34500512, -3.1014085 ,  2.2958436 , -0.804686  ,\n",
       "         1.3688817 ,  0.10245646,  0.13472772,  0.3634492 ,  0.49877107,\n",
       "         0.61891234,  1.8855013 ,  1.263787  ,  2.0223496 , -1.4211094 ,\n",
       "        -1.309351  ,  2.0364125 ,  0.32266062, -0.3891954 ,  0.10458721,\n",
       "         0.35922444,  0.61319816, -0.14912874, -0.7429457 ,  1.469351  ,\n",
       "        -1.1232082 ,  0.3378038 ],\n",
       "       [ 0.03574873, -0.3368752 ,  1.6819855 , -0.33521634, -1.3290966 ,\n",
       "        -1.9556532 , -0.34607896, -3.0987115 ,  2.2963123 , -0.80486095,\n",
       "         1.3669474 ,  0.10132913,  0.13473387,  0.36283588,  0.49758494,\n",
       "         0.6216788 ,  1.8858868 ,  1.2627757 ,  2.0219636 , -1.4208897 ,\n",
       "        -1.3082187 ,  2.0389626 ,  0.32159996, -0.39116064,  0.1062526 ,\n",
       "         0.35957128,  0.6122661 , -0.14942539, -0.74453473,  1.468337  ,\n",
       "        -1.123489  ,  0.33671775],\n",
       "       [ 0.03600421, -0.33810538,  1.6826388 , -0.33433414, -1.3267329 ,\n",
       "        -1.9560882 , -0.34396413, -3.096003  ,  2.2952938 , -0.8032101 ,\n",
       "         1.366725  ,  0.10274363,  0.13443008,  0.36315334,  0.4956261 ,\n",
       "         0.6213716 ,  1.882305  ,  1.2623034 ,  2.0204127 , -1.4200761 ,\n",
       "        -1.3082595 ,  2.034914  ,  0.32189733, -0.38998067,  0.10444504,\n",
       "         0.35928738,  0.6142209 , -0.1489011 , -0.74237704,  1.4684169 ,\n",
       "        -1.1216142 ,  0.3379858 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_means_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02438005, -0.02036242, -0.01039507,  0.00277665,  0.02350294,\n",
       "         0.01473409, -0.02157389,  0.02251465,  0.00814133,  0.01785252],\n",
       "       [ 0.00074128, -0.001453  , -0.01162554, -0.0014644 , -0.02097618,\n",
       "         0.00570552,  0.00674119, -0.01879225,  0.02161046,  0.01941887],\n",
       "       [ 0.01402811, -0.00613734, -0.0027943 , -0.01052572, -0.00041091,\n",
       "         0.0045091 , -0.01547336,  0.0194314 ,  0.00784631,  0.00505763],\n",
       "       [ 0.01655601, -0.02403533,  0.01607199, -0.01643238,  0.00686195,\n",
       "        -0.01788632,  0.01109112,  0.00087933,  0.00448566, -0.00823843],\n",
       "       [-0.00695892,  0.01631877,  0.01657149,  0.01772625,  0.02026216,\n",
       "         0.01811663,  0.02153757, -0.00020743, -0.02066918, -0.00025119],\n",
       "       [ 0.02195978,  0.00867016, -0.02278856,  0.0122384 , -0.02183604,\n",
       "         0.00798479,  0.00545774,  0.00923075,  0.01814621,  0.02018008],\n",
       "       [ 0.02242495, -0.00673729,  0.01447002,  0.02163557,  0.02312511,\n",
       "        -0.00920323, -0.01116639,  0.01708085, -0.01181559, -0.00763743],\n",
       "       [-0.01978129,  0.00916991, -0.00304236,  0.00106503,  0.00690803,\n",
       "        -0.01416942,  0.0063372 ,  0.00018093,  0.00393429, -0.00307162],\n",
       "       [-0.01821756,  0.01890057,  0.00228031, -0.01240117, -0.01108933,\n",
       "        -0.01674686, -0.01161283, -0.01693372,  0.00370204, -0.00271433],\n",
       "       [-0.0158878 ,  0.01951969, -0.01606018, -0.00457847,  0.00044555,\n",
       "        -0.0050344 , -0.0013686 ,  0.00539651,  0.02015766, -0.00510509]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_w_mean_topic_infer[:, :10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03922943,  0.46112132, -0.08166478, -0.06917454, -0.01617851,\n",
       "        0.18225916, -0.28025913, -0.06620797,  0.03231472, -0.02211766,\n",
       "       -0.38082743,  0.11382294,  0.39363608, -0.4168986 ,  1.1677127 ,\n",
       "        0.08979508,  0.03593519, -0.07863234,  0.12493958,  0.03175303,\n",
       "        0.13351525,  0.8176425 , -0.28750482,  0.37927672, -0.01720515,\n",
       "       -0.21228473, -0.05377329, -0.10451841, -0.24399954, -0.25936088,\n",
       "        0.0845396 ,  0.33591354], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_b_means_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_state_infer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ee7c3cd147b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_enc_state_infer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_means_topic_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menc_state_infer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_topic_infer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'enc_state_infer' is not defined"
     ]
    }
   ],
   "source": [
    "_enc_state_infer, _means_topic_infer = debug_value([enc_state_infer, means_topic_infer], return_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 10, 1024)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_state_infer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00],\n",
       "       [-4.4230181e-01, -8.2235533e-01, -3.9928532e-01,  3.3004081e-01,\n",
       "         1.2879696e+00,  2.5491878e-01,  5.9280634e+00,  1.8478313e-01,\n",
       "         1.1477946e-01,  1.1729380e+00, -3.8528564e+00, -1.1789608e+00,\n",
       "         9.1431034e-01, -1.7245387e+00, -2.9743382e-01,  1.0960317e+00,\n",
       "         5.1114732e-01,  8.8052756e-01,  5.0135303e-01,  8.0816686e-01,\n",
       "        -2.1616230e+00, -1.2552780e+00, -8.6165917e-01, -1.0416836e+00,\n",
       "         2.4590290e+00, -5.1620197e+00,  1.5814751e-03,  1.3141291e+00,\n",
       "        -6.7580324e-01,  2.8643382e+00, -2.3818936e+00, -2.5698123e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_means_topic_infer[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
