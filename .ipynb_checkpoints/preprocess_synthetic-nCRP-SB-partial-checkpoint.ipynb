{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "\n",
    "import re\n",
    "import pdb\n",
    "import _pickle as cPickle\n",
    "from collections import OrderedDict, defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from data_structure import Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('output_path', 'data/synthetic/instances_ncrp_part.pkl', 'path of output data')\n",
    "\n",
    "flags.DEFINE_integer('n_vocab', 900, 'size of vocab')\n",
    "flags.DEFINE_integer('n_doc', 11000, 'num of doc')\n",
    "flags.DEFINE_integer('doc_l', 100, 'size of doc')\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "config = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth(parent_idx=0, tree_depth = None, depth=1):\n",
    "    if tree_depth is None: tree_depth={0: depth}\n",
    "\n",
    "    child_idxs = tree_idxs[parent_idx]\n",
    "    depth +=1\n",
    "    for child_idx in child_idxs:\n",
    "        tree_depth[child_idx] = depth\n",
    "        if child_idx in tree_idxs: get_depth(child_idx, tree_depth, depth)\n",
    "    return tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_idxs = {0:[1, 2], \n",
    "             1:[11, 12], 2:[21]}\n",
    "tree_depth = get_depth()\n",
    "max_depth = max(get_depth().values())\n",
    "child_to_parent_idxs = {child_idx: parent_idx for parent_idx, child_idxs in tree_idxs.items() for child_idx in child_idxs}\n",
    "\n",
    "topic_idxs = [0] + [idx for child_idxs in tree_idxs.values() for idx in child_idxs]\n",
    "\n",
    "bow_idxs = np.arange(config.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(config.n_vocab//3)\n",
    "zeros = np.zeros(config.n_vocab//3)\n",
    "leaf_1 = np.concatenate([np.ones([config.n_vocab//90, config.n_vocab//90]), np.zeros([config.n_vocab//90, config.n_vocab//90]), np.zeros([config.n_vocab//90, config.n_vocab//90])], 1).flatten()\n",
    "leaf_2 = np.concatenate([np.zeros([config.n_vocab//90, config.n_vocab//90]), np.ones([config.n_vocab//90, config.n_vocab//90]), np.zeros([config.n_vocab//90, config.n_vocab//90])], 1).flatten()\n",
    "leaf_3 = np.concatenate([np.zeros([config.n_vocab//90, config.n_vocab//90]), np.zeros([config.n_vocab//90, config.n_vocab//90]), np.ones([config.n_vocab//90, config.n_vocab//90])], 1).flatten()\n",
    "# leaf_1 = np.concatenate([np.ones(config.n_vocab//9), np.zeros(config.n_vocab//9), np.zeros(config.n_vocab//9)])\n",
    "# leaf_2 = np.concatenate([np.zeros(config.n_vocab//9), np.ones(config.n_vocab//9), np.zeros(config.n_vocab//9)])\n",
    "# leaf_3 = np.concatenate([np.zeros(config.n_vocab//9), np.zeros(config.n_vocab//9), np.ones(config.n_vocab//9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_topic_bow_raw = {\n",
    "                0: np.concatenate([zeros, ones, zeros]).astype(np.float32),\n",
    "                1: np.concatenate([ones, zeros, zeros]).astype(np.float32),\n",
    "                2: np.concatenate([zeros, zeros, ones]).astype(np.float32),\n",
    "                11: np.concatenate([ones, zeros, zeros]).astype(np.float32).reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))).T.flatten(),\n",
    "                12: np.concatenate([zeros, ones, zeros]).astype(np.float32).reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))).T.flatten(),\n",
    "                21: np.concatenate([zeros, zeros, ones]).astype(np.float32).reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))).T.flatten(),\n",
    "}\n",
    "\n",
    "tree_topic_bow = {topic_idx: topic_bow_raw/np.sum(topic_bow_raw) for topic_idx, topic_bow_raw in tree_topic_bow_raw.items()}\n",
    "topic_bow = np.concatenate([tree_topic_bow[topic_idx][None, :] for topic_idx in topic_idxs], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAADPCAYAAABspOoRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAAsZJREFUeJzt3UFKA0EQQNEe4yGE3FQ3s4k3FbyETPYiakZI58f39iEN+dQmM13Ltm0Dah5mHwD2EC5JwiVJuCQJlyThkiRckoRLknBJepz1xW/j5Sb/sjuO0zL7DPzMxCVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkrTMej39Y11u8iGbw7p5yCbAxCVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJl6RpF4K8r8+zvvpbx9kH4FdMXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuSdMuBIG/MHFJEi5JwiVJuCQJlyThkjTtnTP3417XvS39NnFJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCS52PkTFzs3mLgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZI07VkFrutpfZ19hK+tp10fM3FJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCRZQk2SiUuScEkSLknCJUm4JAmXpNQS6mvcqbt3KfKt27OE+tL31Pb8PpZQ868IlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLkiXUJJm4JAmXJOGSJFyShEuScEmatoR6z1LkS126RHmMMQ7rdpdLqO+NiUuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JFlCTZKJS5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZJ0BqEsN7I9BlKiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import Normalize # Normalizeã‚’import\n",
    "\n",
    "plt.figure(figsize=(3, 4))\n",
    "plt.subplot(5,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(topic_bow[0].reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))), cmap='Wistia', norm=Normalize(vmin=0., vmax=np.max(topic_bow)))\n",
    "\n",
    "for i in range(1, len(topic_idxs)):\n",
    "    plt.subplot(5,2,i+2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(topic_bow[i].reshape(int(config.n_vocab**(1/2)), int(config.n_vocab**(1/2))), cmap='Wistia', norm=Normalize(vmin=0., vmax=np.max(topic_bow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCRP(tree_sticks_topic):\n",
    "    tree_prob_topic = {}\n",
    "    tree_prob_leaf = {}\n",
    "    # calculate topic probability and save\n",
    "    tree_prob_topic[0] = 1.\n",
    "    \n",
    "    for parent_idx, child_idxs in tree_idxs.items():\n",
    "        rest_prob_topic = tree_prob_topic[parent_idx]        \n",
    "        for child_idx in child_idxs:\n",
    "            stick_topic = tree_sticks_topic[child_idx]\n",
    "            if child_idx == child_idxs[-1]:\n",
    "                prob_topic = rest_prob_topic * 1.\n",
    "            else:\n",
    "                prob_topic = rest_prob_topic * stick_topic\n",
    "            \n",
    "            if not child_idx in tree_idxs: # leaf childs\n",
    "                tree_prob_leaf[child_idx] = prob_topic\n",
    "            else:\n",
    "                tree_prob_topic[child_idx] = prob_topic\n",
    "                \n",
    "            rest_prob_topic -= prob_topic\n",
    "            \n",
    "    return tree_prob_leaf\n",
    "\n",
    "def sbp(max_depth, gam):\n",
    "    prob_depth = []\n",
    "    rest_prob_topic = 1.\n",
    "    for depth in range(max_depth):\n",
    "        stick_topic = np.random.beta(1, gam, 1)[0]\n",
    "        if depth == max_depth -1:\n",
    "            prob_topic = rest_prob_topic * 1.\n",
    "        else:\n",
    "            prob_topic = rest_prob_topic * stick_topic\n",
    "        prob_depth.append(prob_topic)\n",
    "        rest_prob_topic -= prob_topic\n",
    "    \n",
    "    prob_depth = np.array(prob_depth, dtype=np.float32)\n",
    "    return prob_depth\n",
    "\n",
    "def get_ancestor_idxs(leaf_idx, ancestor_idxs = None):\n",
    "    if ancestor_idxs is None: ancestor_idxs = [leaf_idx]\n",
    "    \n",
    "    parent_idx = child_to_parent_idxs[leaf_idx]\n",
    "    ancestor_idxs += [parent_idx]\n",
    "    if parent_idx in child_to_parent_idxs: get_ancestor_idxs(parent_idx, ancestor_idxs)\n",
    "    return ancestor_idxs[::-1]\n",
    "\n",
    "def get_prob_topic(tree_prob_leaf, prob_depth):\n",
    "    tree_prob_topic = defaultdict(float)\n",
    "    \n",
    "    leaf_ancestor_idxs = {leaf_idx: get_ancestor_idxs(leaf_idx) for leaf_idx in tree_prob_leaf}\n",
    "    for leaf_idx, ancestor_idxs in leaf_ancestor_idxs.items():\n",
    "        prob_leaf = tree_prob_leaf[leaf_idx]\n",
    "        for i, ancestor_idx in enumerate(ancestor_idxs):\n",
    "            prob_ancestor = prob_leaf * prob_depth[i]\n",
    "            tree_prob_topic[ancestor_idx] += prob_ancestor\n",
    "    return tree_prob_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp = 2.\n",
    "lam = 1.\n",
    "gam = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "\n",
    "for idx_doc in range(config.n_doc):\n",
    "    if idx_doc%1000 == 0: print(idx_doc)\n",
    "    instance = Instance()\n",
    "    instance.idx = idx_doc\n",
    "    \n",
    "    tree_sticks_topic = {}\n",
    "    for topic_idx in topic_idxs:\n",
    "        depth = tree_depth[topic_idx]\n",
    "        tree_sticks_topic[topic_idx] = np.random.beta(1, alp*(lam**depth), 1)\n",
    "        \n",
    "    tree_prob_leaf = nCRP(tree_sticks_topic)\n",
    "    prob_depth = sbp(max_depth, gam)\n",
    "#     prob_depth = np.random.dirichlet(np.ones(max_depth, dtype=np.float32) * gam)\n",
    "    \n",
    "    tree_prob_topic = get_prob_topic(tree_prob_leaf, prob_depth)            \n",
    "    prob_topic = np.concatenate([tree_prob_topic[topic_idx] for topic_idx in topic_idxs])\n",
    "    \n",
    "    prob_bow = prob_topic.dot(topic_bow)\n",
    "    prob_bow /= np.sum(prob_bow)\n",
    "    \n",
    "    token_idxs = np.random.choice(config.n_vocab, config.doc_l, p=prob_bow)\n",
    "    bow = np.array([Counter(token_idxs)[bow_idx] for bow_idx in bow_idxs])\n",
    "    assert len(bow) == config.n_vocab\n",
    "    instance.bow = bow\n",
    "    \n",
    "    instances.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "prob_topics = []\n",
    "for idx_doc in range(config.n_doc):\n",
    "    if idx_doc%1000 == 0: print(idx_doc)\n",
    "    instance = Instance()\n",
    "    instance.idx = idx_doc\n",
    "    \n",
    "    tree_sticks_topic = {}\n",
    "    for topic_idx in topic_idxs:\n",
    "        depth = tree_depth[topic_idx]\n",
    "        tree_sticks_topic[topic_idx] = np.random.beta(1, alp*(lam**depth), 1)\n",
    "        \n",
    "    tree_prob_leaf = nCRP(tree_sticks_topic)\n",
    "#     prob_depth = np.random.dirichlet(np.ones(max_depth, dtype=np.float32) * gam)\n",
    "    prob_depth = sbp(max_depth, gam)\n",
    "    \n",
    "    tree_prob_topic = get_prob_topic(tree_prob_leaf, prob_depth)            \n",
    "    prob_topic = np.concatenate([tree_prob_topic[topic_idx] for topic_idx in topic_idxs])\n",
    "    \n",
    "    prob_topics.append(prob_topic)\n",
    "    \n",
    "prob_topic_mean = np.mean(prob_topics, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33358967, 0.11107112, 0.22358458, 0.03655657, 0.07333715,\n",
       "       0.22186091])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_topic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, instance in enumerate(instances[:50]):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(instance.bow.reshape(int(config.n_vocab**(1/2)),int(config.n_vocab**(1/2))), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train = instances[:10000]\n",
    "instances_valid = instances[10000:]\n",
    "instances_test = instances_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word = {bow_idx: str(10*(bow_idx//3+1) + bow_idx%3) for bow_idx in bow_idxs}\n",
    "word_to_idx = {word: idx for idx, word in idx_to_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessed instances...\n"
     ]
    }
   ],
   "source": [
    "print('saving preprocessed instances...')\n",
    "cPickle.dump((instances_train, instances_valid, instances_test, word_to_idx, idx_to_word, bow_idxs),open(config.output_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
